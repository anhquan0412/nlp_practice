{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/home/quantran/.fastai/data/viwiki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/quantran/.fastai/data/viwiki')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/quantran/.fastai/data/viwiki/docs')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path/'docs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/quantran/.fastai/data/viwiki/models\n"
     ]
    }
   ],
   "source": [
    "mdl_path = path/'models'\n",
    "print(mdl_path)\n",
    "mdl_path.mkdir(exist_ok=True)\n",
    "lm_fns = [f'vi_wt', f'vi_wt_vocab']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Prepare df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_lol(path): # make list of list containing file name and file content\n",
    "    name = path.stem\n",
    "    with open(path, 'r',encoding=\"utf-8\") as temp:\n",
    "        data = temp.read()\n",
    "    return [name,data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Công nghệ pháp lý\n",
      "\n",
      "Công nghệ pháp lý, còn được gọi là Legal Tech , đề cập đến việc sử dụng công nghệ và phần mềm nhằm cung cấp dịch vụ pháp lý. Các công ty Legal Tech nói chung là các công ty khởi nghiệp được thành lập với mục đích phá vỡ thị trường pháp lý bảo thủ theo truyền thống.\n",
      "\n",
      "Theo truyền thống, công nghệ pháp lý đề cập đến việc ứng dụng công nghệ và phần mềm để giúp các công ty luật quản lý nghiệp vụ, lưu trữ tài liệu, thanh toán, kế toán và khám phá điện tử. Từ năm 2011, Legal Tech đã phát triển để liên kết nhiều hơn với các công ty khởi nghiệp công nghệ phá vỡ việc thực hành pháp luật bằng cách cho mọi người truy cập vào phần mềm trực tuyến làm giảm hoặc trong một số trường hợp loại bỏ sự cần thiết phải hỏi ý kiến luật sư hoặc kết nối mọi người với luật sư hiệu quả hơn thông qua trực tuyến thị trường và các trang web phù hợp với luật sư.\n",
      "\n",
      "Ngành công nghiệp pháp lý được coi là bảo thủ và truyền thống, với Law Technology Today lưu ý rằng \"trong 50 năm, trải nghiệm của khách hàng tại hầu hết các công ty luật hầu như không thay đổi\". Lý do cho điều này bao gồm thực tế là các công ty luật phải đối mặt với các ưu đãi cắt giảm chi phí yếu hơn so với các ngành nghề khác (vì họ giao việc giải ngân trực tiếp cho khách hàng của họ) và được coi là không thích rủi ro (vì một lỗi công nghệ nhỏ có thể gây hậu quả tài chính đáng kể cho khách hàng).\n",
      "\n",
      "Tuy nhiên, sự tăng trưởng của việc thuê các doanh nghiệp tư vấn nội bộ và độ phức tạp ngày càng tăng của họ, cùng với sự phát triển của email, đã dẫn đến việc khách hàng đặt ra áp lực chi phí và thời gian ngày càng tăng lên cho luật sư của họ. Ngoài ra, ngày càng có nhiều khuyến khích để luật sư trở thành người có năng lực về công nghệ, với việc bỏ phiếu của Hiệp hội Luật sư Hoa Kỳ vào tháng 8 năm 2012 để sửa đổi Quy tắc ứng xử chuyên nghiệp để yêu cầu luật sư tuân thủ \"lợi ích và rủi ro liên quan đến công nghệ liên quan\", và sự bão hòa của thị trường khiến nhiều luật sư tìm kiếm những cách thức tiên tiến hơn để cạnh tranh. Sự tăng trưởng theo cấp số nhân của khối lượng tài liệu (chủ yếu là email) phải được xem xét cho các vụ kiện tụng đã thúc đẩy đáng kể việc áp dụng công nghệ được sử dụng trong Khám phá Điện tử, với các yếu tố của ngôn ngữ máy và trí tuệ nhân tạo được kết hợp và các dịch vụ đám mây đã được các công ty luật áp dụng.  \n",
      "\n",
      "Trường Luật Stanford đã thành lập CodeX, Trung tâm Tin học Pháp lý, một trung tâm nghiên cứu liên ngành, cũng bao gồm các công ty được bắt đầu bởi các sinh viên luật và các nhà khoa học máy tính. Một số công ty đã ra khỏi chương trình bao gồm Lex Machina và Legal.io.\n",
      "\n",
      "\n",
      "\n",
      "Tại Việt Nam, tuy LegalTech vẫn còn mới mẻ, nhưng Việt Nam cũng là một thị trường tiềm năng để phát triển ngành này đến từ sự phức tạp trong hệ thống quy định pháp luật, nhu cầu áp dụng luật của doanh nghiệp, sự phát triển của ngành tư vấn luật và tiềm năng sáng tạo của các startup.\n",
      "\n",
      "Việc áp dụng công nghệ không chỉ giúp doanh nghiệp dễ dàng tiếp cận, cập nhật được các chính sách mới mà còn giúp giảm thiểu việc ban hành trùng lặp, chồng chéo các chính sách.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = make_lol((path/'docs').ls()[2])\n",
    "print(temp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77456"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((path/'docs').ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = parallel(make_lol,(path/'docs').ls(),n_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(results,columns=['fname','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77451</th>\n",
       "      <td>Ronda Rousey</td>\n",
       "      <td>Ronda Rousey\\n\\nRonda Jean Rousey ( sinh ngày 1 tháng 2 năm 1987) là một nữ võ sĩ MMA, vận động viên judo, và diễn viên người Mỹ. Cô hiện đang tham gia WWE Raw.\\n\\nRousey là nữ vận động viên đầu tiên của Mỹ giành huy chương judo Olympic (huy chương đồng) ở Thế vận hội Mùa hè 2008. Cô là cựu quán quân UFC nữ hạng gà, cũng như là quán quân nữ hạng gà Strikeforce cuối cùng. Cô từng giành 12 chiến thắng MMA liên tiếp, trong đó có sáu chiến thắng ở Ultimate Fighting Championship (UFC), trước khi để thua trận đầu tiên trước Holly Holm vào tháng 11 năm 2015; cô thắng 11 trận trong hiệp 1, 9 trong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77452</th>\n",
       "      <td>Ngựa cỏ bùn</td>\n",
       "      <td>Ngựa cỏ bùn\\n\\nNgựa cỏ bùn hay Cǎonímǎ (chữ Hán: , phiên âm Hán-Việt: \"thảo nê mã\") là một Internet meme tại Trung Quốc được sử dụng rộng rãi như một dạng biểu tượng nhằm phản đối kiểm duyệt Internet tại Trung Quốc đang ngày càng tăng. Đây là lối chơi chữ với cum từ trong tiếng Trung phổ thông \"cào nǐ mā\" (chữ Hán: , phiên âm Hán-Việt: \"tháo nễ ma\"), nghĩa đen tức là \"địt mẹ mày\" (từ Cǎo/草 là từ \"cấu\" trong từ \"giao cấu\"; ní/泥, tức là từ \"nị\", chỉ ngôi thứ 2, là bạn, mày và từ mǎ/马 là từ \"ma\" hay \"ma ma\" có nghĩa là mẹ hay vú nuôi), và là một trong danh sách 10 sinh vật thần thoại được tạo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77453</th>\n",
       "      <td>Gettext</td>\n",
       "      <td>Gettext\\n\\nTrong điện toán, gettext là một hệ thống quốc tế hóa và bản địa hóa (i18n) thường dùng cho việc viết các ứng dụng đa ngôn ngữ trên các hệ điều hành tương tự Unix. Việc triển khai gettext thường được sử dụng phổ biến nhất là GNU gettext, phát hành bởi GNU Project năm 1995.\\n\\ngettext ban đầu được viết bởi Sun Microsystems vào đầu những năm 1990. GNU Project phát hành GNU gettext, một phần mềm tự do triển khai hệ thống vào năm 1995.\\n\\nMã nguồn được sửa đổi đầu tiên để sử dụng các lệnh gọi GNU gettext. Với phần lớn ngôn ngữ lập trình, việc này được thực hiện bằng cách bao các chuỗ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77454</th>\n",
       "      <td>Rosanna Pansino</td>\n",
       "      <td>Rosanna Pansino\\n\\nRosanna Pansino (sinh ngày 8 tháng 6 năm 1985) là một thợ làm bánh, nữ diễn viên, tác giả và nhân vật YouTube người Mỹ. Cô được biết đến nhiều nhất qua series nấu ăn \"Nerdy Nummies\", một trong những chương trình làm bánh nổi tiếng nhất trên YouTube. Cô cũng thủ vai Violet trong series hoạt hình trên YouTube \"Broken Quest\" và vai The Jet Setter trong series \"Escape the Night\" trên YouTube. Cô có tổ tiên là người Ý, Croatia, Đức và Ireland.\\n\\nPansino ban đầu muốn theo đuổi sự nghiệp làm diễn viên. Cô từng đóng những vai diễn nhỏ trong các tập của \"Parks and Recreation\" và...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77455</th>\n",
       "      <td>Hyperbol</td>\n",
       "      <td>Hyperbol\\n\\nTrong toán học, hyperbol hay hypecbol (từ tiếng Hy Lạp: ὑπερβολή, nghĩa đen là \"vượt quá\" hay \"thái quá\") là một kiểu Đường cô-nic, được định nghĩa là đường giao của một mặt nón với một mặt phẳng cắt cả hai nửa của hình nón.\\n\\nĐường hyperbol còn được định nghĩa là quỹ tích của những điểm trong mặt phẳng có giá trị tuyết đối của hiệu khoảng cách tới hai điểm cố định là một hằng số bằng 2\"a\". \"a\" đồng thời cũng bằng độ dài bán trục lớn của Hyberbol. Hai điểm cố định đó gọi là hai tiêu điểm của hyperbol. Đường thẳng đi qua hai tiêu điểm này được gọi là trục thực của hyberbol và t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 fname  \\\n",
       "77451     Ronda Rousey   \n",
       "77452      Ngựa cỏ bùn   \n",
       "77453          Gettext   \n",
       "77454  Rosanna Pansino   \n",
       "77455         Hyperbol   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          text  \n",
       "77451  Ronda Rousey\\n\\nRonda Jean Rousey ( sinh ngày 1 tháng 2 năm 1987) là một nữ võ sĩ MMA, vận động viên judo, và diễn viên người Mỹ. Cô hiện đang tham gia WWE Raw.\\n\\nRousey là nữ vận động viên đầu tiên của Mỹ giành huy chương judo Olympic (huy chương đồng) ở Thế vận hội Mùa hè 2008. Cô là cựu quán quân UFC nữ hạng gà, cũng như là quán quân nữ hạng gà Strikeforce cuối cùng. Cô từng giành 12 chiến thắng MMA liên tiếp, trong đó có sáu chiến thắng ở Ultimate Fighting Championship (UFC), trước khi để thua trận đầu tiên trước Holly Holm vào tháng 11 năm 2015; cô thắng 11 trận trong hiệp 1, 9 trong...  \n",
       "77452  Ngựa cỏ bùn\\n\\nNgựa cỏ bùn hay Cǎonímǎ (chữ Hán: , phiên âm Hán-Việt: \"thảo nê mã\") là một Internet meme tại Trung Quốc được sử dụng rộng rãi như một dạng biểu tượng nhằm phản đối kiểm duyệt Internet tại Trung Quốc đang ngày càng tăng. Đây là lối chơi chữ với cum từ trong tiếng Trung phổ thông \"cào nǐ mā\" (chữ Hán: , phiên âm Hán-Việt: \"tháo nễ ma\"), nghĩa đen tức là \"địt mẹ mày\" (từ Cǎo/草 là từ \"cấu\" trong từ \"giao cấu\"; ní/泥, tức là từ \"nị\", chỉ ngôi thứ 2, là bạn, mày và từ mǎ/马 là từ \"ma\" hay \"ma ma\" có nghĩa là mẹ hay vú nuôi), và là một trong danh sách 10 sinh vật thần thoại được tạo...  \n",
       "77453  Gettext\\n\\nTrong điện toán, gettext là một hệ thống quốc tế hóa và bản địa hóa (i18n) thường dùng cho việc viết các ứng dụng đa ngôn ngữ trên các hệ điều hành tương tự Unix. Việc triển khai gettext thường được sử dụng phổ biến nhất là GNU gettext, phát hành bởi GNU Project năm 1995.\\n\\ngettext ban đầu được viết bởi Sun Microsystems vào đầu những năm 1990. GNU Project phát hành GNU gettext, một phần mềm tự do triển khai hệ thống vào năm 1995.\\n\\nMã nguồn được sửa đổi đầu tiên để sử dụng các lệnh gọi GNU gettext. Với phần lớn ngôn ngữ lập trình, việc này được thực hiện bằng cách bao các chuỗ...  \n",
       "77454  Rosanna Pansino\\n\\nRosanna Pansino (sinh ngày 8 tháng 6 năm 1985) là một thợ làm bánh, nữ diễn viên, tác giả và nhân vật YouTube người Mỹ. Cô được biết đến nhiều nhất qua series nấu ăn \"Nerdy Nummies\", một trong những chương trình làm bánh nổi tiếng nhất trên YouTube. Cô cũng thủ vai Violet trong series hoạt hình trên YouTube \"Broken Quest\" và vai The Jet Setter trong series \"Escape the Night\" trên YouTube. Cô có tổ tiên là người Ý, Croatia, Đức và Ireland.\\n\\nPansino ban đầu muốn theo đuổi sự nghiệp làm diễn viên. Cô từng đóng những vai diễn nhỏ trong các tập của \"Parks and Recreation\" và...  \n",
       "77455  Hyperbol\\n\\nTrong toán học, hyperbol hay hypecbol (từ tiếng Hy Lạp: ὑπερβολή, nghĩa đen là \"vượt quá\" hay \"thái quá\") là một kiểu Đường cô-nic, được định nghĩa là đường giao của một mặt nón với một mặt phẳng cắt cả hai nửa của hình nón.\\n\\nĐường hyperbol còn được định nghĩa là quỹ tích của những điểm trong mặt phẳng có giá trị tuyết đối của hiệu khoảng cách tới hai điểm cố định là một hằng số bằng 2\"a\". \"a\" đồng thời cũng bằng độ dài bán trục lớn của Hyberbol. Hai điểm cố định đó gọi là hai tiêu điểm của hyperbol. Đường thẳng đi qua hai tiêu điểm này được gọi là trục thực của hyberbol và t...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# result_df.to_csv(path/'alltext.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build LM wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df = pd.read_csv(path/'alltext.csv',encoding='utf-8')\n",
    "result_df = pd.read_csv(path/'alltext.csv',encoding='utf-8',nrows=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnmese_lm = DataBlock(blocks=TextBlock.from_df('text', is_lm=True),\n",
    "                    get_x=ColReader('text'),\n",
    "                    splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs=64\n",
    "# bs=24\n",
    "bs=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = vnmese_lm.dataloaders(result_df, bs=bs, seq_len=72)\n",
    "# dls.show_batch(max_n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## TextBlock datablock summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai2.data.block.DataBlock"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vnmese_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting-up type transforms pipelines\n",
      "Collecting items from                                   fname  \\\n",
      "0     Hội chứng Alice ở xứ sở thần tiên   \n",
      "1                       Nicolas Sarkozy   \n",
      "2                     Công nghệ pháp lý   \n",
      "3                          TT (bài hát)   \n",
      "4                      Adolf von Glümer   \n",
      "...                                 ...   \n",
      "1995                         Mario Puzo   \n",
      "1996                          Vua Nepal   \n",
      "1997                 Thời kỳ quân phiệt   \n",
      "1998              Hồng Tiến, Kiến Xương   \n",
      "1999                      Kỹ thuật RFLP   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         text  \n",
      "0     Hội chứng Alice ở xứ sở thần tiên\\n\\nHội chứng Alice ở xứ sở thần tiên là một bệnh lý thần kinh bị mất phương hướng ảnh hưởng đến nhận thức của con người. Con người sẽ phải trải qua ảo giác về những biến dạng kích thước như micropsia, macropsia, pelopsia, hoặc teleopsia. Sự biến dạng kích thước này có thể xảy ra ở các phương thức cảm giác khác nhau.\\nNó thường liên quan đến chứng đau nửa đầu khi sử dụng các loại thuốc thần kinh. Nó cũng có thể là triệu chứng ban đầu của virus Epstein-Barr (xem mononucleosis).\\n\\nDấu hiệu của Hội chứng Alice ở xứ sở thần tiên (AIWS) là chứng đau nửa đầu, và...  \n",
      "1     Nicolas Sarkozy\\n\\nNicolas Sarkozy (IPA: nikɔˈla saʁkɔˈzi - ), sinh ngày 28 tháng 1 năm 1955 với tên Nicolas Paul Stéphane Sarközy de Nagy-Bocsa, là cựu tổng thống Pháp. Sarkozy kế nhiệm Jacques Chirac vào ngày 16 tháng 5 năm 2007. Ông thường được những người ủng hộ lẫn chống đối đặt cho biệt hiệu là Sarko.\\n\\nNgày 6 tháng 5 năm 2007, Sarkozy đắc cử tổng thống sau khi đánh bại đối thủ thuộc Đảng Xã hội, Ségolène Royal, trong cuộc tổng tuyển cử năm 2007. Sarkozy giành được 53,4% trong khi đối thủ của ông chỉ nhận được 46,6% phiếu bầu. Số cử tri đi bầu đạt 85,5%, mức cao nhất kể từ năm 1981 ...  \n",
      "2     Công nghệ pháp lý\\n\\nCông nghệ pháp lý, còn được gọi là Legal Tech , đề cập đến việc sử dụng công nghệ và phần mềm nhằm cung cấp dịch vụ pháp lý. Các công ty Legal Tech nói chung là các công ty khởi nghiệp được thành lập với mục đích phá vỡ thị trường pháp lý bảo thủ theo truyền thống.\\n\\nTheo truyền thống, công nghệ pháp lý đề cập đến việc ứng dụng công nghệ và phần mềm để giúp các công ty luật quản lý nghiệp vụ, lưu trữ tài liệu, thanh toán, kế toán và khám phá điện tử. Từ năm 2011, Legal Tech đã phát triển để liên kết nhiều hơn với các công ty khởi nghiệp công nghệ phá vỡ việc thực hành...  \n",
      "3     TT (bài hát)\\n\\nTT là một bài hát được thu âm bởi nhóm nhạc nữ Hàn Quốc Twice, là ca khúc chủ đề của EP thứ ba . Bài hát được phát hành vào ngày 24 tháng 10 năm 2016 bởi JYP Entertainment và được phân phối bởi KT Music. Bài hát được viết lời và sáng tác bởi Sam Lewis và Black Eyed Pilseung. Tiêu đề \"TT\" đề cập đến biểu tượng cảm xúc được sử dụng để thể hiện khóc hoặc buồn.\\n\\nPhiên bản tiếng Nhật của \"TT\" đã được phát hành dưới dạng đĩa đơn đầu tiên cho album tổng hợp tiếng Nhật đầu tiên của nhóm, #Twice. MV tiếng nhật kèm theo đã được phát hành vào ngày 21 tháng 6 năm 2017.\\n\\nVào ngày 10...  \n",
      "4     Adolf von Glümer\\n\\nHeinrich Karl Ludwig Adolf von Glümer (5 tháng 6 năm 1814 tại Lengefeld – 3 tháng 1 năm 1896 tại Freiburg im Breisgau) là một sĩ quan quân đội Phổ, được thăng đến cấp Thượng tướng Bộ binh. Ông đã tham gia chỉ huy các lực lượng Phổ - Đức trong cuộc Chiến tranh Áo-Phổ (1866) và Chiến tranh Pháp-Đức (1870 – 1871).\\n\\nGlümer đã nhập ngũ trong Trung đoàn Bộ binh số 26 vào năm 1831 và học tại Học viện Quân sự Phổ. Từ năm 1842 cho đến năm 1843, ông tham gia trong Lữ đoàn Pháo binh Cận vệ, và sau đó là cục trưởng cục đo đạc địa hình của Bộ Tổng tham mưu. Tiếp theo đó, từ năm 18...  \n",
      "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...  \n",
      "1995  Mario Puzo\\n\\nMario Gianluigi Puzo (15 tháng 10 năm 1920 – 2 tháng 7 năm 1999) là một nhà văn, nhà biên kịch người Mỹ, được biết đến với những tiểu thuyết về Mafia, đặc biệt là \"Bố già\" (1969), mà sau này ông đồng chuyển thể thành một bộ phim cùng với Francis Ford Coppola. Ông đã giành được Giải Oscar cho kịch bản chuyển thể xuất sắc nhất vào giữa những năm 1972 và 1974. Dù là một nhà văn được cưng chiều của Hollywood nhưng ông vẫn luôn cảm thấy thất vọng về kinh đô điện ảnh của Mỹ.\\n\\nPuzo sinh ra trong một gia đình nghèo của người xứ Napoli nhập cư sống ở khu phố Hell's Kitchen của thành...  \n",
      "1996  Vua Nepal\\n\\nVua Nepal, theo truyền thống được gọi là Mahārājādhirāja (), là nguyên thủ quốc gia và là vua của Nepal từ năm 1768 đến 2008. Ông từng là người đứng đầu nền quân chủ cũ của Nepal—Triều đại Shah. Chế độ quân chủ được thành lập năm 1768 và bị Quốc hội Lập hiến Nepal bãi bỏ vào ngày 28 tháng 5 năm 2008. Các tiểu vương địa phương ở Mustang, Bajhang, Salyan và Jajarkot cũng được bãi bỏ vào tháng 10 cùng năm.\\n\\nVương quốc Nepal do Prithvi Narayan Shah thành lập vào ngày 25 tháng 9 năm 1768, xuất thân là một vị vua Gorkha đã thành công trong cuộc chiến thống nhất các vương quốc Kath...  \n",
      "1997  Thời kỳ quân phiệt\\n\\nThời kỳ quân phiệt (, Quân phiệt thời đại) là giai đoạn trong lịch sử Trung Hoa Dân Quốc từ năm 1916 đến 1928 khi mà quân phiệt Trung Quốc chia nhau cai trị tại các khu vực Tứ Xuyên, Sơn Tây, Thanh Hải, Ninh Hạ, Quảng Đông, Quảng Tây, Vân Nam, Cam Túc và Tân Cương.\\n\\nThời kỳ quân phiệt kéo dài từ khi Viên Thế Khải chết năm 1916 cho đến năm 1928, khi cuộc Bắc phạt kết thúc với sự tái thống nhất Trung Quốc và bắt đầu \"thập niên Nam Kinh\"; tuy nhiên khi các quân phiệt cũ như Ngô Bội Phu và Tôn Truyền Phương bị hạ bệ thì lại nổi lên một số quân phiệt nhỏ trong thập niên ...  \n",
      "1998  Hồng Tiến, Kiến Xương\\n\\nHồng Tiến là xã thuộc huyện Kiến Xương, tỉnh Thái Bình, Việt Nam.\\n\\nXã nằm trên một vùng đất bồi của hạ lưu tả ngạn sông Hồng, được thành lập năm 1963 trên cơ sở tách ra khỏi xã Bình Thanh gồm một phần thôn Khả Cảnh và các làng Khả Lễ, làng Khả Cửu.\\n\\nXã Hồng Tiến nay được phân thành 6 thôn gồm: Khả Cảnh, Tân Thành, Đông Tiến, Nam Hòa, Nam Tiến và Cao Bình.\\n\\nVùng đất này xưa kia do cụ Đào Khắc Tuân dẫn 10 nhân đinh của 5 họ (Đào, Đỗ, Vũ, Bùi, Nguyễn - thường gọi là Ngũ tộc) từ làng Khả Phú ra quai đê lập làng Cơ Chỉ vào năm Canh Dần 1820.\\n\\nThôn Đông Tiến trướ...  \n",
      "1999  Kỹ thuật RFLP\\n\\nTrong sinh học phân tử, đa hình chiều dài đoạn cắt giới hạn, hay là RFLP (thường đọc là \"rif-lip\"), là kỹ thuật khai thác những khác biệt trong trình tự DNA. Trong phân tích RFLP, DNA mẫu được cắt thành các đoạn nhỏ bằng cách sử dụng các enzyme cắt giới hạn, và sau đó các đoạn DNA nhỏ tạo thành được phân tách dựa theo kích thước bằng kỹ thuật điện di trên gel. Mặc dù ngày nay kỹ thuật này đã trở nên lỗi thời do bị thay thế bởi công nghệ giải trình tự, RFLP là công nghệ nghiên cứu đa hình DNA đầu tiên đủ rẻ để có thể được ứng dụng một cách rộng rãi. RFLP là công cụ quan trọ...  \n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "Found 2000 items\n",
      "2 datasets of sizes 1600,400\n",
      "Setting up Pipeline: ColReader -> Tokenizer -> Numericalize\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building one sample\n",
      "  Pipeline: ColReader -> Tokenizer -> Numericalize\n",
      "    starting from\n",
      "      fname                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Lâm Tế Nghĩa Huyền\n",
      "text           [xxbos, xxmaj, lâm, xxup, tế, xxmaj, nghĩa, xxmaj, huyền, \\n\\n, xxmaj, lâm, xxup, tế, xxmaj, nghĩa, xxmaj, huyền, (, zh, ., \", línjì, yìxuán, \", /, \", lin, -, chi, i, -, hsüan, \", 臨濟義玄, ,, ja, ., \", rinzai, gigen, \", ), ,, ?, -866, /, 867, ,, là, một, vị, xxmaj, thiền, sư, xxmaj, trung, xxmaj, quốc, ,, là, xxup, tổ, khai, dòng, thiền, xxmaj, lâm, xxup, tế, ., xxup, sư, là, môn, đệ, xuất, sắc, nhất, của, xxmaj, thiền, sư, xxmaj, hoàng, xxup, bá, xxmaj, hi, xxmaj, vận, ., xxmaj, môn, đệ, đắc, pháp, danh, tiếng, của, ...]\n",
      "text_length                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1083\n",
      "Name: 842, dtype: object\n",
      "    applying ColReader gives\n",
      "      (#1083) ['xxbos','xxmaj','lâm','xxup','tế','xxmaj','nghĩa','xxmaj','huyền','\\n\\n'...]\n",
      "    applying Tokenizer gives\n",
      "      (#1083) ['xxbos','xxmaj','lâm','xxup','tế','xxmaj','nghĩa','xxmaj','huyền','\\n\\n'...]\n",
      "    applying Numericalize gives\n",
      "      TensorText of size 1083\n",
      "\n",
      "Final sample: (TensorText([  2,   8, 685,  ...,   8, 917,  10]),)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up after_item: Pipeline: ToTensor\n",
      "Setting up before_batch: Pipeline: \n",
      "Setting up after_batch: Pipeline: \n",
      "\n",
      "Building one batch\n",
      "Applying item_tfms to the first sample:\n",
      "  Pipeline: ToTensor\n",
      "    starting from\n",
      "      (TensorText of size 1083)\n",
      "    applying ToTensor gives\n",
      "      (TensorText of size 1083)\n",
      "\n",
      "Adding the next 1 samples\n",
      "\n",
      "No before_batch transform to apply\n",
      "\n",
      "Collating items in a batch\n",
      "Error! It's not possible to collate your items in a batch\n",
      "Could not collate the 0-th members of your tuples because got the following shapes\n",
      "torch.Size([1083]),torch.Size([1403])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1083] at entry 0 and [1403] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-ef893dd1ebd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvnmese_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/kwon/nlp/fastai2_nlp/fastai2/data/block.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, source, bs, show_batch, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mwhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_fail_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Make sure all parts of your samples are tensors of the same size\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwhy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mwhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'noop'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kwon/nlp/fastai2_nlp/fastai2/data/block.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, source, bs, show_batch, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nCollating items in a batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretain_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kwon/nlp/fastai2_nlp/fastai2/data/load.py\u001b[0m in \u001b[0;36mcreate_batch\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mretain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0mretain_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfa_collate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfa_convert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprebatched\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kwon/nlp/fastai2_nlp/fastai2/data/load.py\u001b[0m in \u001b[0;36mfa_collate\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     return (default_collate(t) if isinstance(b, _collate_types)\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32melse\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfa_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             else default_collate(t))\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kwon/nlp/fastai2_nlp/fastai2/data/load.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     return (default_collate(t) if isinstance(b, _collate_types)\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32melse\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfa_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             else default_collate(t))\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kwon/nlp/fastai2_nlp/fastai2/data/load.py\u001b[0m in \u001b[0;36mfa_collate\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfa_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     return (default_collate(t) if isinstance(b, _collate_types)\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfa_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             else default_collate(t))\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1083] at entry 0 and [1403] at entry 1"
     ]
    }
   ],
   "source": [
    "# vnmese_lm.summary(result_df, bs=2)\n",
    "# TODO: in LM, for some reason the sequences in a batch aren’t padded to be of equal length \n",
    "# while making a LM. I know they are made equal when building the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Study LM dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai2.data.core.DataLoaders"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16880"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xxunk', 'xxpad', 'xxbos', 'xxeos', 'xxfld', 'xxrep', 'xxwrep', 'xxup', 'xxmaj', ',', '.', 'và', 'của', '\"', 'là', 'được', 'các', 'một', '\\n\\n', 'trong', 'có', 'năm', 'đã', ')', '(', 'với', 'cho', 'người', 'vào', 'ở', 'không', 'thành', 'từ', 'những', 'khi', 'công', 'tháng', 'đến', '-', 'này', 'ngày', 'tại', 'sau', 'quân', 'đó', 'quốc', 'để', 'ông', 'đầu', 'sự', 'ra', 'thể', 'chính', 'bị', 'về', 'như', 'số', 'nam', 'trên', 'trung', 'lại', 'gia', 'cũng', 'nhà', 'chiến', 'làm', 'đại', 'học', 'động', 'bộ', 'dân', 'theo', 'nhiều', 'nhất', ':', 'việt', 'nước', 'hiện', 'hai', '3', 'phát', 'việc', 'thời', 'thế', 'nhân', 'hành', 'chỉ', 'anh', 'do', 'pháp', 'khác', 'cùng', 'định', 'đồng', 'nó', 'quan', 'bản', 'con', 'hội', 'cuộc']\n"
     ]
    }
   ],
   "source": [
    "print(dls.vocab[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malas', 'donepezil', 'cholinesterase', 'żurakowski', '好', 'き', 'で', 'す', 'takumi', '-photphoryl', 'trochiliformes', 'cypselomorphae', 'blust', 'gujarat', '1.450', 'mxml', 'fayette', 'rocn', 'meeker', 'spitz', 'tatopoulos', 'cnestidium', 'plantes', 'haüy', 'buffon', 'mlền', 'gambiez', 'linarès', 'đă', 'hadhramaut', 'cdc', 'lidia', 'sundar', '嘉順宮', 'l3', 'autosomal', 'engebi', 'veldarad', 'veldt', 'bounnhang', 'vorachith', 'có:<br', 'vnukovo', 'nordaustlandet', 'hopen', 'grumant', 'schengen', 'beloved', 'invisibles', 'baste', 'powter', 'furtado', 'timberlake', 'flexjet', 'eternalblue', 'aiesecer', 'gv', 'youthspeak', 'shindong', 'goong', 'moeyan', 'peleus', 'priam', 'inu', 'monoxide', 'hbco', 'u-110', 'lettera', 'pbdos', 'pence', 'scara', 'toys', 'sketrobo', 'ngõa', 'eustatius', 'saba', 'tncmđch', 'vázquez', 'ayllón', 'spartina', 'nps', 'programmer', 'squeaker', 'ély', 'nolting', 'maneli', 'karnow', 'rattigan', 'iwamoto', 'komi', 'tocantins', 'beginnings', 'starmen.net', 'xxfake', 'xxfake', 'xxfake', 'xxfake', 'xxfake', 'xxfake', 'xxfake']\n"
     ]
    }
   ],
   "source": [
    "print(dls.vocab[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<fastai2.text.data.LMDataLoader at 0x7f36d0ac8190>,\n",
       " <fastai2.text.data.LMDataLoader at 0x7f363a0d0b90>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.train,dls.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y = dls.train.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 72])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape # (bs,bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LMTensorText([[   2,    8, 1018,  ..., 1365,    9,   16],\n",
       "        [ 482,   15,  195,  ...,  295,   31,    9],\n",
       "        [  78,   45,   61,  ...,   35,   93,    8],\n",
       "        ...,\n",
       "        [  58,  627,  599,  ...,  369,   11, 3755],\n",
       "        [   8, 5229,    8,  ..., 1103,    8,   59],\n",
       "        [ 132,   20,  251,  ...,  633,  937,  262]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x # LMTensorText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(fastai2.text.data.LMTensorText, 'torch.cuda.LongTensor')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x),x.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   8, 1018,   48,  ...,    9,   16,    7],\n",
       "        [  15,  195,   14,  ...,   31,    9,    8],\n",
       "        [  45,   61,   91,  ...,   93,    8, 8130],\n",
       "        ...,\n",
       "        [ 627,  599, 1001,  ...,   11, 3755,  544],\n",
       "        [5229,    8,  290,  ...,    8,   59,    8],\n",
       "        [  20,  251,  554,  ...,  937,  262,   37]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y # move each row of x to the right by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai2.text.data.LMDataLoader"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dls.train) #inherit TfmdDL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "check bptt (seq_len) size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp_i = iter(dls.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 72]) torch.Size([128, 72])\n"
     ]
    }
   ],
   "source": [
    "temp_x,temp_y = next(temp_i)\n",
    "print(temp_x.shape,temp_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 72]) torch.Size([128, 72])\n"
     ]
    }
   ],
   "source": [
    "temp_x,temp_y = next(temp_i)\n",
    "print(temp_x.shape,temp_y.shape)\n",
    "# bptt not changing during LM model.\n",
    "# though there might be a param somewhere to set up variable bptt length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj phong trào xxmaj cần xxmaj vương \\n\\n xxmaj phong trào xxmaj cần xxmaj vương ( chữ xxmaj nôm : xxunk ) nổ ra vào cuối thế kỷ 19 do đại thần nhà xxmaj nguyễn là xxmaj tôn xxmaj thất xxmaj thuyết nhân danh vị hoàng đế trẻ tuổi vua xxmaj hàm xxmaj nghi đề xướng trước nạn xâm lược của thực dân xxmaj pháp . \\n\\n xxmaj tại triều đình</td>\n",
       "      <td>xxmaj phong trào xxmaj cần xxmaj vương \\n\\n xxmaj phong trào xxmaj cần xxmaj vương ( chữ xxmaj nôm : xxunk ) nổ ra vào cuối thế kỷ 19 do đại thần nhà xxmaj nguyễn là xxmaj tôn xxmaj thất xxmaj thuyết nhân danh vị hoàng đế trẻ tuổi vua xxmaj hàm xxmaj nghi đề xướng trước nạn xâm lược của thực dân xxmaj pháp . \\n\\n xxmaj tại triều đình xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tế ban đầu đặt tiêu chuẩn cho tên miền chấp nhận . xxmaj quốc tế hóa tên miền là một giải pháp kỹ thuật để dịch các tên được viết bằng các tập lệnh gốc ngôn ngữ thành biểu diễn văn bản xxup ascii tương thích với xxup hệ thống tên miền . xxmaj tên miền quốc tế hóa chỉ có thể được sử dụng với các ứng dụng được thiết kế</td>\n",
       "      <td>ban đầu đặt tiêu chuẩn cho tên miền chấp nhận . xxmaj quốc tế hóa tên miền là một giải pháp kỹ thuật để dịch các tên được viết bằng các tập lệnh gốc ngôn ngữ thành biểu diễn văn bản xxup ascii tương thích với xxup hệ thống tên miền . xxmaj tên miền quốc tế hóa chỉ có thể được sử dụng với các ứng dụng được thiết kế riêng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vắn \" , \" kim xxmaj tiền \" , \" long xxup hổ xxmaj hội \" . ông nội ông là xxmaj trần xxmaj quang xxmaj diệm ( năm xxmaj diệm ) , cha ông là xxmaj trần xxmaj quang xxmaj chiêu ( bảy xxmaj triều ) , cô là xxmaj trần xxmaj ngọc xxmaj viện ( tức xxmaj ba xxmaj viện , người đã sáng lập gánh cải lương đồng xxup</td>\n",
       "      <td>\" , \" kim xxmaj tiền \" , \" long xxup hổ xxmaj hội \" . ông nội ông là xxmaj trần xxmaj quang xxmaj diệm ( năm xxmaj diệm ) , cha ông là xxmaj trần xxmaj quang xxmaj chiêu ( bảy xxmaj triều ) , cô là xxmaj trần xxmaj ngọc xxmaj viện ( tức xxmaj ba xxmaj viện , người đã sáng lập gánh cải lương đồng xxup nữ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxmaj thứ sử . \\n\\n đời đường xxmaj cao tông , ông được đổi thành xxup tả vệ đại tướng quân . xxmaj khoảng năm 655 - 657 , ông lĩnh chức xxmaj hành quân tổng quản , dẫn binh xuất chinh xxmaj tây đột xxmaj quyết . xxmaj tuy nhiên , trong quá trình hành quân , quân đường tàn sát thường dân , người đột xxmaj quyết phẫn nộ ,</td>\n",
       "      <td>thứ sử . \\n\\n đời đường xxmaj cao tông , ông được đổi thành xxup tả vệ đại tướng quân . xxmaj khoảng năm 655 - 657 , ông lĩnh chức xxmaj hành quân tổng quản , dẫn binh xuất chinh xxmaj tây đột xxmaj quyết . xxmaj tuy nhiên , trong quá trình hành quân , quân đường tàn sát thường dân , người đột xxmaj quyết phẫn nộ , quyết</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.train.show_batch(max_n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Datablock tfms \n",
    "\n",
    "block tfms to be added at the end of  X dataset pipeline  +  after_item pipeline +  after_batch pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vnmese_lm.type_tfms) # only 1 type tfms for X \n",
    "# since 'blocks' param provide only 1: blocks=TextBlock.from_df('text', is_lm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer: (str,object) -> encodes\n",
       "(Path,object) -> encodes (object,object) -> decodes"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnmese_lm.type_tfms[0][0] # Tokenizer transform. Will be in X pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Numericalize: (object,object) -> encodes (object,object) -> decodes"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnmese_lm.type_tfms[0][1] # Numericalize transform. Will be in X pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [ToTensor: (PILMask,object) -> encodes\n",
       "(PILBase,object) -> encodes ]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnmese_lm.default_item_tfms #default item tfm (for dataloaders' after_item pipeline) for PILBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#0) []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnmese_lm.default_batch_tfms #default batch item tfm (for dataloaders' after_batch pipeline\n",
    "# normall it will be IntToFloatTensor, but token should be int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#1) [ToTensor: (PILMask,object) -> encodes\n",
       " (PILBase,object) -> encodes ],\n",
       " (#0) [])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnmese_lm.item_tfms,vnmese_lm.batch_tfms \n",
    "# nothing different from default_item_tfms and default_batch_tfms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Dataset and its tfms (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 1600)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.valid.dataset),len(dls.train.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dsets = dls.train.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, 1)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dsets[0]),len(dsets[0]) # tuple of 1 since there's no label y yet (LM model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1958])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_ds = dls.train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_ds = dls.valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, fastai2.data.core.TfmdLists)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds.tls),type(train_ds.tls[0]) # 1 tfmdlist for train, again because no label y yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: ColReader -> Tokenizer -> Numericalize"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0].tfms # or train_ds.tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: ColReader -> Tokenizer -> Numericalize"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds.tls[0].tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0x7f3623e8f750', '0x7f3623e8fd50')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(id(train_ds.tls[0].tfms)),hex(id(val_ds.tls[0].tfms)) # 2 different pipelines though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>Vân Trục</td>\n",
       "      <td>[xxbos, xxmaj, vân, xxmaj, trục, \\n\\n, xxmaj, vân, xxmaj, trục, là, một, xã, thuộc, huyện, xxmaj, lập, xxmaj, thạch, ,, tỉnh, xxmaj, vĩnh, xxmaj, phúc, ,, xxmaj, việt, xxmaj, nam, ., \\n\\n, xxup, xã, có, diện, tích, 12,25,  , km², ,, dân, số, năm, 2013, là, 4630, người, ,, mật, độ, dân, số, đạt, 379người, /, km², ., \\n\\n, 1, ., xxmaj, tên, gọi, ,, vị, trí, địa, lý, :, \\n\\n, 1.1, ., xxmaj, tên, gọi, ,, lịch, sử, hình, thành, :, \\n\\n, -, xxmaj, trước, cách, mạng, tháng, 8, năm, 1945, ,, địa, phận, xã, xxmaj, vân, xxmaj, trục, ...]</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>Mạc (họ)</td>\n",
       "      <td>[xxbos, xxmaj, mạc, (, họ, ), \\n\\n, xxmaj, mạc, là, một, họ, của, người, ,, có, ở, các, quốc, gia, á, đông, như, xxmaj, trung, xxmaj, quốc, ,, xxmaj, việt, xxmaj, nam, …, xxmaj, riêng, ở, xxmaj, việt, xxmaj, nam, ,, có, cả, một, triều, đại, phong, kiến, do, những, ông, trị, vì, ,, đó, là, nhà, xxmaj, mạc, ., xxmaj, ngoài, ra, ,, trong, lịch, sử, xxmaj, việt, xxmaj, nam, ,, còn, có, một, gốc, xxmaj, hoa, ,, mà, người, đầu, tiên, là, xxmaj, mạc, xxmaj, cửu, ,, có, công, cai, quản, và, khai, khẩn, xxmaj, miền, xxmaj, tây, ...]</td>\n",
       "      <td>1145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>[xxbos, xxmaj, los, xxmaj, angeles, \\n\\n, xxmaj, los, xxmaj, angeles, (, viết, tắt, xxup, la, ;, phát, âm, tiếng, xxmaj, anh, :, ;, phiên, âm, xxmaj, lốt, xxmaj, an, -, giơ, -, lét, ;, xxmaj, tiếng, xxmaj, tây, xxmaj, ban, xxmaj, nha, :, \", los, ángeles, \", ), là, thành, phố, lớn, nhất, tiểu, bang, xxmaj, california, và, lớn, thứ, nhì, tại, xxmaj, hoa, xxup, kỳ, ,, thuộc, về, xxmaj, quận, xxmaj, los, xxmaj, angeles, ., xxmaj, thành, phố, còn, được, gọi, tắt, là, xxmaj, los, (, \", lốt, \", ), bởi, những, người, xxmaj, việt, ở, những, vùng, lân, ...]</td>\n",
       "      <td>3686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>Safi Faye</td>\n",
       "      <td>[xxbos, xxmaj, safi, xxmaj, faye, \\n\\n, xxmaj, safi, xxmaj, faye, (, sinh, ngày, 22, xxmaj, tháng, 11, năm, 1943, ), là, một, đạo, diễn, phim, và, nhà, dân, tộc, học, người, xxmaj, senegal, ., xxup, bà, là, người, phụ, nữ, châu, xxmaj, phi, xxup, hạ, xxmaj, sahara, đầu, tiên, đạo, diễn, một, bộ, phim, được, phát, hành, thương, mại, vào, năm, 1975, ,, \", kaddu, xxmaj, beykat, \", ., xxup, bà, đã, làm, đạo, diễn, cho, một, số, bộ, phim, tài, liệu, và, viễn, tưởng, tập, trung, vào, cuộc, sống, nông, thôn, ở, xxmaj, sénégal, ., \\n\\n, xxmaj, safi, xxmaj, ...]</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>Cụm tập đoàn quân (Đức Quốc Xã)</td>\n",
       "      <td>[xxbos, xxmaj, cụm, tập, đoàn, quân, (, đức, xxmaj, quốc, xxup, xã, ), \\n\\n, xxmaj, cụm, tập, đoàn, quân, (, tiếng, đức, :, \", heeresgruppe, \", ), là, tổ, chức, tác, chiến, cấp, chiến, lược, cao, nhất, của, xxmaj, quân, đội, đức, xxmaj, quốc, xã, ,, trên, cấp, xxmaj, tập, đoàn, quân, ., xxmaj, cũng, giống, như, biên, chế, phương, diện, quân, của, xxmaj, liên, xxup, xô, ,, cụm, tập, đoàn, quân, là, tổ, chức, đơn, vị, binh, chủng, hợp, thành, ,, thường, gồm, bộ, binh, ,, kỵ, binh, cơ, giới, ,, xe, tăng, ,, pháo, binh, ,, công, binh, ...]</td>\n",
       "      <td>1351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>Ngô Xán</td>\n",
       "      <td>[xxbos, xxmaj, ngô, xxmaj, xán, \\n\\n, xxmaj, ngô, xxmaj, xán, (;, ?, -, 245, ), ,, tự, xxmaj, khổng, xxmaj, hưu, (, 道言, ), ,, là, quan, viên, ,, tướng, lĩnh, đông, xxmaj, ngô, thời, xxmaj, tam, xxmaj, quốc, trong, lịch, sử, xxmaj, trung, xxmaj, quốc, ., \\n\\n, xxmaj, ngô, xxmaj, xán, quê, ở, huyện, ô, xxmaj, trình, ,, quận, xxmaj, ngô, xxmaj, khi, còn, nhỏ, ,, có, một, phụ, nhân, thấy, xxmaj, ngô, xxmaj, xán, ,, nói, với, mẹ, của, xxmaj, xán, rằng, :, \", thằng, bé, này, có, cốt, cách, của, khanh, tướng, ., \", \\n\\n, xxmaj, ngô, ...]</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Hoàng Đế</td>\n",
       "      <td>[xxbos, xxmaj, hoàng, đế, \\n\\n, xxmaj, hoàng, đế, (, trung, phồn, thể, :, 黃帝, ,, xxmaj, trung, giản, thể, :, 黄帝, ,, bính, âm, :, huángdì, ), ,, còn, gọi, là, xxmaj, hiên, xxmaj, viên, xxmaj, hoàng, đế, (, 轩辕黃帝, ), ,, là, một, vị, quân, chủ, huyền, thoại, và, là, anh, hùng, văn, hoá, của, xxmaj, văn, minh, xxmaj, trung, xxmaj, hoa, ,, được, coi, là, thuỷ, tổ, của, mọi, người, xxmaj, hán, ., xxmaj, chữ, \", hoàng, \", (, 黃, ), ở, đây, hàm, nghĩa, sắc, vàng, ,, là, màu, biểu, trưng, cho, hành, xxmaj, thổ, ., xxmaj, ...]</td>\n",
       "      <td>2442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>Khí đồng hành</td>\n",
       "      <td>[xxbos, xxmaj, khí, đồng, hành, \\n\\n, xxmaj, khí, đồng, hành, (, tiếng, xxmaj, anh, :, \", associated, gas, \", ), là, khí, tự, nhiên, được, tìm, thấy, cùng, dầu, thô, ,, có, thể, ở, dạng, hoà, lẫn, với, dầu, thô, hoặc, tạo, thành, không, gian, phía, trên, lớp, dầu, thô, trong, mỏ, dầu, ., \\n\\n, xxmaj, khí, đồng, hành, khi, được, tách, khỏi, dầu, thô, là, hỗn, hợp, chủ, yếu, gồm, etan, (, ch, ), ,, propan, (, ch, ), ,, butan, (, ch, ), và, pentan, (, ch, ), ., xxmaj, ngoài, ra, còn, những, tạp, chất, không, mong, ...]</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>Hoàng Phài</td>\n",
       "      <td>[xxbos, xxmaj, hoàng, xxmaj, phài, \\n\\n, xxmaj, hoàng, xxmaj, phài, là, một, thôn, nằm, tại, xã, xxmaj, cốc, đán, ,, huyện, xxmaj, ngân, xxmaj, sơn, ,, tỉnh, xxmaj, bắc, xxmaj, kạn, \\n\\n, xxmaj, ngày, 31, /, 10, /, 2011, ,, xxup, bộ, xxmaj, văn, hóa, ,, xxmaj, thể, thao, và, xxmaj, du, lịch, đã, chính, thức, công, nhận, và, xếp, hạng, di, tích, lịch, sử, “, địa, điểm, xxmaj, lưu, niệm, nơi, xxmaj, bác, xxup, hồ, dừng, chân, trên, đường, từ, xxmaj, pác, xxup, bó, về, xxmaj, tân, xxmaj, trào, tháng, 5, năm, 1945, ”, tại, thôn, xxmaj, hoàng, xxmaj, ...]</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>American Life (bài hát)</td>\n",
       "      <td>[xxbos, xxmaj, american, xxmaj, life, (, bài, hát, ), \\n\\n, \", american, xxmaj, life, \", (, tạm, dịch, :, \", lối, sống, xxmaj, hoa, xxup, kỳ, \", ), là, một, bài, hát, của, ca, sĩ, người, xxup, mỹ, xxmaj, madonna, nằm, trong, album, phòng, thu, thứ, 9, cùng, tên, của, cô, (, 2003, ), ., xxup, nó, được, phát, hành, làm, đĩa, đơn, đầu, tiên, trích, từ, album, vào, ngày, 8, tháng, 4, năm, 2003, bởi, xxmaj, maverick, xxmaj, records, ., xxmaj, bài, hát, do, xxmaj, madonna, và, xxmaj, mirwais, xxmaj, ahmadzaï, sáng, tác, và, sản, xuất, ,, với, nội, ...]</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                fname  \\\n",
       "1927                         Vân Trục   \n",
       "1747                         Mạc (họ)   \n",
       "1751                      Los Angeles   \n",
       "695                         Safi Faye   \n",
       "1838  Cụm tập đoàn quân (Đức Quốc Xã)   \n",
       "...                               ...   \n",
       "869                           Ngô Xán   \n",
       "368                          Hoàng Đế   \n",
       "973                     Khí đồng hành   \n",
       "1169                       Hoàng Phài   \n",
       "1495          American Life (bài hát)   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text  \\\n",
       "1927                            [xxbos, xxmaj, vân, xxmaj, trục, \\n\\n, xxmaj, vân, xxmaj, trục, là, một, xã, thuộc, huyện, xxmaj, lập, xxmaj, thạch, ,, tỉnh, xxmaj, vĩnh, xxmaj, phúc, ,, xxmaj, việt, xxmaj, nam, ., \\n\\n, xxup, xã, có, diện, tích, 12,25,  , km², ,, dân, số, năm, 2013, là, 4630, người, ,, mật, độ, dân, số, đạt, 379người, /, km², ., \\n\\n, 1, ., xxmaj, tên, gọi, ,, vị, trí, địa, lý, :, \\n\\n, 1.1, ., xxmaj, tên, gọi, ,, lịch, sử, hình, thành, :, \\n\\n, -, xxmaj, trước, cách, mạng, tháng, 8, năm, 1945, ,, địa, phận, xã, xxmaj, vân, xxmaj, trục, ...]   \n",
       "1747                                [xxbos, xxmaj, mạc, (, họ, ), \\n\\n, xxmaj, mạc, là, một, họ, của, người, ,, có, ở, các, quốc, gia, á, đông, như, xxmaj, trung, xxmaj, quốc, ,, xxmaj, việt, xxmaj, nam, …, xxmaj, riêng, ở, xxmaj, việt, xxmaj, nam, ,, có, cả, một, triều, đại, phong, kiến, do, những, ông, trị, vì, ,, đó, là, nhà, xxmaj, mạc, ., xxmaj, ngoài, ra, ,, trong, lịch, sử, xxmaj, việt, xxmaj, nam, ,, còn, có, một, gốc, xxmaj, hoa, ,, mà, người, đầu, tiên, là, xxmaj, mạc, xxmaj, cửu, ,, có, công, cai, quản, và, khai, khẩn, xxmaj, miền, xxmaj, tây, ...]   \n",
       "1751        [xxbos, xxmaj, los, xxmaj, angeles, \\n\\n, xxmaj, los, xxmaj, angeles, (, viết, tắt, xxup, la, ;, phát, âm, tiếng, xxmaj, anh, :, ;, phiên, âm, xxmaj, lốt, xxmaj, an, -, giơ, -, lét, ;, xxmaj, tiếng, xxmaj, tây, xxmaj, ban, xxmaj, nha, :, \", los, ángeles, \", ), là, thành, phố, lớn, nhất, tiểu, bang, xxmaj, california, và, lớn, thứ, nhì, tại, xxmaj, hoa, xxup, kỳ, ,, thuộc, về, xxmaj, quận, xxmaj, los, xxmaj, angeles, ., xxmaj, thành, phố, còn, được, gọi, tắt, là, xxmaj, los, (, \", lốt, \", ), bởi, những, người, xxmaj, việt, ở, những, vùng, lân, ...]   \n",
       "695   [xxbos, xxmaj, safi, xxmaj, faye, \\n\\n, xxmaj, safi, xxmaj, faye, (, sinh, ngày, 22, xxmaj, tháng, 11, năm, 1943, ), là, một, đạo, diễn, phim, và, nhà, dân, tộc, học, người, xxmaj, senegal, ., xxup, bà, là, người, phụ, nữ, châu, xxmaj, phi, xxup, hạ, xxmaj, sahara, đầu, tiên, đạo, diễn, một, bộ, phim, được, phát, hành, thương, mại, vào, năm, 1975, ,, \", kaddu, xxmaj, beykat, \", ., xxup, bà, đã, làm, đạo, diễn, cho, một, số, bộ, phim, tài, liệu, và, viễn, tưởng, tập, trung, vào, cuộc, sống, nông, thôn, ở, xxmaj, sénégal, ., \\n\\n, xxmaj, safi, xxmaj, ...]   \n",
       "1838                    [xxbos, xxmaj, cụm, tập, đoàn, quân, (, đức, xxmaj, quốc, xxup, xã, ), \\n\\n, xxmaj, cụm, tập, đoàn, quân, (, tiếng, đức, :, \", heeresgruppe, \", ), là, tổ, chức, tác, chiến, cấp, chiến, lược, cao, nhất, của, xxmaj, quân, đội, đức, xxmaj, quốc, xã, ,, trên, cấp, xxmaj, tập, đoàn, quân, ., xxmaj, cũng, giống, như, biên, chế, phương, diện, quân, của, xxmaj, liên, xxup, xô, ,, cụm, tập, đoàn, quân, là, tổ, chức, đơn, vị, binh, chủng, hợp, thành, ,, thường, gồm, bộ, binh, ,, kỵ, binh, cơ, giới, ,, xe, tăng, ,, pháo, binh, ,, công, binh, ...]   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ...   \n",
       "869                          [xxbos, xxmaj, ngô, xxmaj, xán, \\n\\n, xxmaj, ngô, xxmaj, xán, (;, ?, -, 245, ), ,, tự, xxmaj, khổng, xxmaj, hưu, (, 道言, ), ,, là, quan, viên, ,, tướng, lĩnh, đông, xxmaj, ngô, thời, xxmaj, tam, xxmaj, quốc, trong, lịch, sử, xxmaj, trung, xxmaj, quốc, ., \\n\\n, xxmaj, ngô, xxmaj, xán, quê, ở, huyện, ô, xxmaj, trình, ,, quận, xxmaj, ngô, xxmaj, khi, còn, nhỏ, ,, có, một, phụ, nhân, thấy, xxmaj, ngô, xxmaj, xán, ,, nói, với, mẹ, của, xxmaj, xán, rằng, :, \", thằng, bé, này, có, cốt, cách, của, khanh, tướng, ., \", \\n\\n, xxmaj, ngô, ...]   \n",
       "368                                          [xxbos, xxmaj, hoàng, đế, \\n\\n, xxmaj, hoàng, đế, (, trung, phồn, thể, :, 黃帝, ,, xxmaj, trung, giản, thể, :, 黄帝, ,, bính, âm, :, huángdì, ), ,, còn, gọi, là, xxmaj, hiên, xxmaj, viên, xxmaj, hoàng, đế, (, 轩辕黃帝, ), ,, là, một, vị, quân, chủ, huyền, thoại, và, là, anh, hùng, văn, hoá, của, xxmaj, văn, minh, xxmaj, trung, xxmaj, hoa, ,, được, coi, là, thuỷ, tổ, của, mọi, người, xxmaj, hán, ., xxmaj, chữ, \", hoàng, \", (, 黃, ), ở, đây, hàm, nghĩa, sắc, vàng, ,, là, màu, biểu, trưng, cho, hành, xxmaj, thổ, ., xxmaj, ...]   \n",
       "973                                         [xxbos, xxmaj, khí, đồng, hành, \\n\\n, xxmaj, khí, đồng, hành, (, tiếng, xxmaj, anh, :, \", associated, gas, \", ), là, khí, tự, nhiên, được, tìm, thấy, cùng, dầu, thô, ,, có, thể, ở, dạng, hoà, lẫn, với, dầu, thô, hoặc, tạo, thành, không, gian, phía, trên, lớp, dầu, thô, trong, mỏ, dầu, ., \\n\\n, xxmaj, khí, đồng, hành, khi, được, tách, khỏi, dầu, thô, là, hỗn, hợp, chủ, yếu, gồm, etan, (, ch, ), ,, propan, (, ch, ), ,, butan, (, ch, ), và, pentan, (, ch, ), ., xxmaj, ngoài, ra, còn, những, tạp, chất, không, mong, ...]   \n",
       "1169     [xxbos, xxmaj, hoàng, xxmaj, phài, \\n\\n, xxmaj, hoàng, xxmaj, phài, là, một, thôn, nằm, tại, xã, xxmaj, cốc, đán, ,, huyện, xxmaj, ngân, xxmaj, sơn, ,, tỉnh, xxmaj, bắc, xxmaj, kạn, \\n\\n, xxmaj, ngày, 31, /, 10, /, 2011, ,, xxup, bộ, xxmaj, văn, hóa, ,, xxmaj, thể, thao, và, xxmaj, du, lịch, đã, chính, thức, công, nhận, và, xếp, hạng, di, tích, lịch, sử, “, địa, điểm, xxmaj, lưu, niệm, nơi, xxmaj, bác, xxup, hồ, dừng, chân, trên, đường, từ, xxmaj, pác, xxup, bó, về, xxmaj, tân, xxmaj, trào, tháng, 5, năm, 1945, ”, tại, thôn, xxmaj, hoàng, xxmaj, ...]   \n",
       "1495         [xxbos, xxmaj, american, xxmaj, life, (, bài, hát, ), \\n\\n, \", american, xxmaj, life, \", (, tạm, dịch, :, \", lối, sống, xxmaj, hoa, xxup, kỳ, \", ), là, một, bài, hát, của, ca, sĩ, người, xxup, mỹ, xxmaj, madonna, nằm, trong, album, phòng, thu, thứ, 9, cùng, tên, của, cô, (, 2003, ), ., xxup, nó, được, phát, hành, làm, đĩa, đơn, đầu, tiên, trích, từ, album, vào, ngày, 8, tháng, 4, năm, 2003, bởi, xxmaj, maverick, xxmaj, records, ., xxmaj, bài, hát, do, xxmaj, madonna, và, xxmaj, mirwais, xxmaj, ahmadzaï, sáng, tác, và, sản, xuất, ,, với, nội, ...]   \n",
       "\n",
       "      text_length  \n",
       "1927         1958  \n",
       "1747         1145  \n",
       "1751         3686  \n",
       "695           808  \n",
       "1838         1351  \n",
       "...           ...  \n",
       "869           642  \n",
       "368          2442  \n",
       "973           605  \n",
       "1169         1182  \n",
       "1495          504  \n",
       "\n",
       "[1600 rows x 3 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0].items \n",
    "# no transform applied yet, but note that texts have already been 'ColReader' and 'Tokenizer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorText([   2,    8, 1179,  ...,   38, 1433,   23]), 1958)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0][0],len(train_ds.tls[0][0]) # when indexed, tfms are applied (last one: Numericalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorText([   2,    8,  882,  ...,  111, 6466,   10]), 1145)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0][1],len(train_ds.tls[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxpad'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in train_ds.tls[0][1]:\n",
    "    if i == train_ds.vocab[1]: \n",
    "        print('there is padding')\n",
    "        break\n",
    "        \n",
    "# print nothing => no padding apply yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Found 2000 items\n",
    "# 2 datasets of sizes 1600,400\n",
    "# Setting up Pipeline: ColReader -> Tokenizer -> Numericalize\n",
    "\n",
    "# Building one sample\n",
    "#   Pipeline: ColReader -> Tokenizer -> Numericalize\n",
    "#     starting from\n",
    "#       fname                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Lâm Tế Nghĩa Huyền\n",
    "# text           [xxbos, xxmaj, lâm, xxup, tế, xxmaj, nghĩa, xxmaj, huyền, \\n\\n, xxmaj, lâm, xxup, tế, xxmaj, nghĩa, xxmaj, huyền, (, zh, ., \", línjì, yìxuán, \", /, \", lin, -, chi, i, -, hsüan, \", 臨濟義玄, ,, ja, ., \", rinzai, gigen, \", ), ,, ?, -866, /, 867, ,, là, một, vị, xxmaj, thiền, sư, xxmaj, trung, xxmaj, quốc, ,, là, xxup, tổ, khai, dòng, thiền, xxmaj, lâm, xxup, tế, ., xxup, sư, là, môn, đệ, xuất, sắc, nhất, của, xxmaj, thiền, sư, xxmaj, hoàng, xxup, bá, xxmaj, hi, xxmaj, vận, ., xxmaj, môn, đệ, đắc, pháp, danh, tiếng, của, ...]\n",
    "# text_length                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1083\n",
    "# Name: 842, dtype: object\n",
    "#     applying ColReader gives\n",
    "#       (#1083) ['xxbos','xxmaj','lâm','xxup','tế','xxmaj','nghĩa','xxmaj','huyền','\\n\\n'...]\n",
    "#     applying Tokenizer gives\n",
    "#       (#1083) ['xxbos','xxmaj','lâm','xxup','tế','xxmaj','nghĩa','xxmaj','huyền','\\n\\n'...]\n",
    "#     applying Numericalize gives\n",
    "#       TensorText of size 1083\n",
    "\n",
    "# Final sample: (TensorText([  2,   8, 685,  ...,   8, 917,  10]),)\n",
    "\n",
    "\n",
    "# Setting up after_item: Pipeline: ToTensor\n",
    "# Setting up before_batch: Pipeline: \n",
    "# Setting up after_batch: Pipeline: \n",
    "\n",
    "# Building one batch\n",
    "# Applying item_tfms to the first sample:\n",
    "#   Pipeline: ToTensor\n",
    "#     starting from\n",
    "#       (TensorText of size 1083)\n",
    "#     applying ToTensor gives\n",
    "#       (TensorText of size 1083)\n",
    "\n",
    "# Adding the next 1 samples\n",
    "\n",
    "# No before_batch transform to apply\n",
    "\n",
    "# Collating items in a batch\n",
    "# Error! It's not possible to collate your items in a batch\n",
    "# Could not collate the 0-th members of your tuples because got the following shapes\n",
    "# torch.Size([1083]),torch.Size([1403])\n",
    "\n",
    "# TODO: in LM, for some reason the sequences in a batch aren’t padded to be of equal length \n",
    "# while making a LM. I know they are made equal when building the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LM learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### define learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(dls, \n",
    "                               AWD_LSTM, \n",
    "                               metrics=[accuracy, Perplexity()],\n",
    "                               drop_mult=1.0,\n",
    "                               pretrained=False,\n",
    "                               path=path).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026666666666666665"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "lr *= bs/48\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(fastai2.text.learner.LMLearner, fastai2.text.models.core.SequentialRNN)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(learn),type(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AWD_LSTM(\n",
       "   (encoder): Embedding(16880, 400, padding_idx=1)\n",
       "   (encoder_dp): EmbeddingDropout(\n",
       "     (emb): Embedding(16880, 400, padding_idx=1)\n",
       "   )\n",
       "   (rnns): ModuleList(\n",
       "     (0): WeightDropout(\n",
       "       (module): LSTM(400, 1152, batch_first=True)\n",
       "     )\n",
       "     (1): WeightDropout(\n",
       "       (module): LSTM(1152, 1152, batch_first=True)\n",
       "     )\n",
       "     (2): WeightDropout(\n",
       "       (module): LSTM(1152, 400, batch_first=True)\n",
       "     )\n",
       "   )\n",
       "   (input_dp): RNNDropout()\n",
       "   (hidden_dps): ModuleList(\n",
       "     (0): RNNDropout()\n",
       "     (1): RNNDropout()\n",
       "     (2): RNNDropout()\n",
       "   )\n",
       " ),\n",
       " LinearDecoder(\n",
       "   (decoder): Linear(in_features=400, out_features=16880, bias=True)\n",
       "   (output_dp): RNNDropout()\n",
       " ))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[0],learn.model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze() # == learn.opt.freeze_to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai2.optimizer.Optimizer"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(learn.opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': [{},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {'do_wd': False}],\n",
       " 'hypers': (#4) [{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05},{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05},{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05},{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05}]}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.opt.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Param groups and weight shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn.opt.param_lists) # 4 layers total, for discriminative fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['torch.Size([4608, 1152]): True',\n",
       " 'torch.Size([4608, 400]): True',\n",
       " 'torch.Size([4608]): True',\n",
       " 'torch.Size([4608]): True',\n",
       " 'torch.Size([4608, 1152]): True',\n",
       " 'torch.Size([4608, 1152]): True',\n",
       " 'torch.Size([4608]): True',\n",
       " 'torch.Size([4608]): True',\n",
       " 'torch.Size([1600, 400]): True',\n",
       " 'torch.Size([1600, 1152]): True',\n",
       " 'torch.Size([1600]): True',\n",
       " 'torch.Size([1600]): True',\n",
       " 'torch.Size([16880, 400]): True',\n",
       " 'torch.Size([16880]): True']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"{getattr(i,'shape')}: {i.requires_grad}\" for l in learn.opt.param_lists for i in l]\n",
    "# all requires_grad true b/c unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn.model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.encoder.weight: torch.Size([16880, 400])',\n",
       " '0.encoder_dp.emb.weight: torch.Size([16880, 400])',\n",
       " '0.rnns.0.weight_hh_l0_raw: torch.Size([4608, 1152])',\n",
       " '0.rnns.0.module.weight_ih_l0: torch.Size([4608, 400])',\n",
       " '0.rnns.0.module.bias_ih_l0: torch.Size([4608])',\n",
       " '0.rnns.0.module.bias_hh_l0: torch.Size([4608])',\n",
       " '0.rnns.1.weight_hh_l0_raw: torch.Size([4608, 1152])',\n",
       " '0.rnns.1.module.weight_ih_l0: torch.Size([4608, 1152])',\n",
       " '0.rnns.1.module.bias_ih_l0: torch.Size([4608])',\n",
       " '0.rnns.1.module.bias_hh_l0: torch.Size([4608])',\n",
       " '0.rnns.2.weight_hh_l0_raw: torch.Size([1600, 400])',\n",
       " '0.rnns.2.module.weight_ih_l0: torch.Size([1600, 1152])',\n",
       " '0.rnns.2.module.bias_ih_l0: torch.Size([1600])',\n",
       " '0.rnns.2.module.bias_hh_l0: torch.Size([1600])',\n",
       " '1.decoder.weight: torch.Size([16880, 400])',\n",
       " '1.decoder.bias: torch.Size([16880])']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{k}: {v.shape}' for k,v in learn.model.state_dict().items()]\n",
    "# for some reason state_dict includes encoder (embedding) weight, but opt.param_lists or model.parameters don't\n",
    "# because weighs of embedding (encoder) and weight of last linear layer is the same\n",
    "# because of 'tie_weights': look at awdlstm.py, in awd_lstm_lm_config 'tie_weights' is True\n",
    "# For language model, tie_weights will make embedding weight == last layer linear weight\n",
    "# Why? More efficient training. This is mentioned in AWD LSTM paper by Stephen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0188,  0.0143,  0.0664,  ...,  0.0572,  0.0979, -0.0883],\n",
       "        [ 0.0886, -0.0824,  0.0024,  ...,  0.0121, -0.0513, -0.0572],\n",
       "        [ 0.0262, -0.0667,  0.0044,  ...,  0.0031,  0.0521, -0.0231],\n",
       "        ...,\n",
       "        [ 0.0502, -0.0522, -0.0105,  ..., -0.0584,  0.0650,  0.0326],\n",
       "        [-0.0859,  0.0849, -0.0026,  ..., -0.0770,  0.0981,  0.0587],\n",
       "        [ 0.0428,  0.0166,  0.0893,  ...,  0.0448,  0.0556,  0.0442]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[0].encoder.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0188,  0.0143,  0.0664,  ...,  0.0572,  0.0979, -0.0883],\n",
       "        [ 0.0886, -0.0824,  0.0024,  ...,  0.0121, -0.0513, -0.0572],\n",
       "        [ 0.0262, -0.0667,  0.0044,  ...,  0.0031,  0.0521, -0.0231],\n",
       "        ...,\n",
       "        [ 0.0502, -0.0522, -0.0105,  ..., -0.0584,  0.0650,  0.0326],\n",
       "        [-0.0859,  0.0849, -0.0026,  ..., -0.0770,  0.0981,  0.0587],\n",
       "        [ 0.0428,  0.0166,  0.0893,  ...,  0.0448,  0.0556,  0.0442]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model.state_dict()['0.encoder.weight'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_equal(learn.model.state_dict()['0.encoder.weight'].data, learn.model[0].encoder.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0188,  0.0143,  0.0664,  ...,  0.0572,  0.0979, -0.0883],\n",
       "        [ 0.0886, -0.0824,  0.0024,  ...,  0.0121, -0.0513, -0.0572],\n",
       "        [ 0.0262, -0.0667,  0.0044,  ...,  0.0031,  0.0521, -0.0231],\n",
       "        ...,\n",
       "        [ 0.0502, -0.0522, -0.0105,  ..., -0.0584,  0.0650,  0.0326],\n",
       "        [-0.0859,  0.0849, -0.0026,  ..., -0.0770,  0.0981,  0.0587],\n",
       "        [ 0.0428,  0.0166,  0.0893,  ...,  0.0448,  0.0556,  0.0442]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[1].decoder.weight.data # last layer linear weight\n",
    "# same as embedding weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_equal(learn.model.state_dict()['0.encoder.weight'].data, learn.model[1].decoder.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x7f1a096dbc30'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(id(learn.model[0].encoder.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x7f1a096dbc30'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(id(learn.model[1].decoder.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([16880, 400]), torch.Size([16880])]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[getattr(i,'shape') for i in learn.opt.param_lists[3]] \n",
    "# matrix weight + bias of last linear layer (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([4608, 1152]),\n",
       " torch.Size([4608, 400]),\n",
       " torch.Size([4608]),\n",
       " torch.Size([4608])]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (0): WeightDropout(\n",
    "#        (module): LSTM(400, 1152, batch_first=True)\n",
    "#      )\n",
    "\n",
    "[getattr(i,'shape') for i in learn.opt.param_lists[0]] # 1st LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Weights of an LSTM unidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = nn.LSTM(400, 1152, bias=True, bidirectional=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0154, -0.0289, -0.0189,  ..., -0.0088,  0.0129, -0.0005],\n",
       "         [ 0.0147,  0.0234, -0.0261,  ...,  0.0021, -0.0199, -0.0066],\n",
       "         [ 0.0122, -0.0047,  0.0102,  ..., -0.0054,  0.0280,  0.0257],\n",
       "         ...,\n",
       "         [-0.0137,  0.0106,  0.0207,  ..., -0.0227,  0.0077,  0.0251],\n",
       "         [ 0.0158,  0.0088,  0.0237,  ...,  0.0218, -0.0261, -0.0080],\n",
       "         [ 0.0017,  0.0107, -0.0004,  ..., -0.0087,  0.0027, -0.0047]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0095,  0.0015, -0.0041,  ..., -0.0149, -0.0061,  0.0075],\n",
       "         [-0.0145, -0.0124, -0.0137,  ..., -0.0154,  0.0172,  0.0203],\n",
       "         [-0.0255, -0.0040,  0.0278,  ..., -0.0156, -0.0256, -0.0002],\n",
       "         ...,\n",
       "         [ 0.0093,  0.0231, -0.0046,  ...,  0.0017, -0.0092, -0.0159],\n",
       "         [ 0.0188, -0.0189, -0.0195,  ..., -0.0237, -0.0179,  0.0262],\n",
       "         [ 0.0191, -0.0118, -0.0157,  ..., -0.0025, -0.0293, -0.0082]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0160,  0.0267,  0.0284,  ...,  0.0209, -0.0049,  0.0090],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0094,  0.0098, -0.0009,  ...,  0.0104,  0.0169,  0.0030],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(temp.parameters()) #weight_ih_l0, weight hh_l0 and two biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4608, 1152]), torch.Size([4608, 400]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.weight_hh_l0.shape, temp.weight_ih_l0.shape \n",
    "\n",
    "# ~LSTM.weight_ih_l[k] – the learnable input-hidden weights of the \\text{k}^{th}k \n",
    "# th\n",
    "#   layer (W_ii|W_if|W_ig|W_io), of shape (4*hidden_size, input_size) for k = 0. Otherwise, the shape is (4*hidden_size, num_directions * hidden_size)\n",
    "\n",
    "# ~LSTM.weight_hh_l[k] – the learnable hidden-hidden weights of the \\text{k}^{th}k \n",
    "# th\n",
    "#   layer (W_hi|W_hf|W_hg|W_ho), of shape (4*hidden_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4608"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4*1152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([4608, 1152]),\n",
       " torch.Size([4608, 1152]),\n",
       " torch.Size([4608]),\n",
       " torch.Size([4608])]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[getattr(i,'shape') for i in learn.opt.param_lists[1]] # 2nd LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1600, 400]),\n",
       " torch.Size([1600, 1152]),\n",
       " torch.Size([1600]),\n",
       " torch.Size([1600])]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[getattr(i,'shape') for i in learn.opt.param_lists[2]] # 3rd LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#4) [{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05},{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05},{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05},{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.opt.hypers # list of hyperparams for each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### quick review on slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice(None, 1, None)\n",
      "slice(None, 1, None)\n",
      "slice(1, None, None)\n",
      "slice(1, 2, None)\n",
      "slice(1, 2, 3)\n",
      "slice(None, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "# slice(start, stop, step)\n",
    "print(slice(1))\n",
    "print(slice(None,1))\n",
    "print(slice(1,None))\n",
    "print(slice(1,2))\n",
    "print(slice(1,2,3))\n",
    "print(slice(None,2,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(range(10))[slice(None)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [0],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2, 3],\n",
       " [0, 1, 2, 3, 4],\n",
       " [0, 1, 2, 3, 4, 5],\n",
       " [0, 1, 2, 3, 4, 5, 6],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8]]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(range(10))[slice(i)] for i in range(10)] # [:0],[:1],[:2]..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [3, 4, 5, 6, 7, 8, 9],\n",
       " [4, 5, 6, 7, 8, 9],\n",
       " [5, 6, 7, 8, 9],\n",
       " [6, 7, 8, 9],\n",
       " [7, 8, 9],\n",
       " [8, 9],\n",
       " [9]]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(range(10))[slice(i,None)] for i in range(10)] # [0:],[1:],[2:] ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9]]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(range(10))[slice(i,i+2)] for i in range(10)] # [0:2],[1:3], ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10))[slice(0,7,2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.169965</td>\n",
       "      <td>6.045080</td>\n",
       "      <td>0.118188</td>\n",
       "      <td>422.031403</td>\n",
       "      <td>02:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# learn.fit_one_cycle(1, lr, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.153887</td>\n",
       "      <td>5.969858</td>\n",
       "      <td>0.119671</td>\n",
       "      <td>391.450165</td>\n",
       "      <td>02:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.682713</td>\n",
       "      <td>4.455638</td>\n",
       "      <td>0.261569</td>\n",
       "      <td>86.111069</td>\n",
       "      <td>02:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.234314</td>\n",
       "      <td>4.185904</td>\n",
       "      <td>0.289397</td>\n",
       "      <td>65.752914</td>\n",
       "      <td>02:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "learn.fit_one_cycle(3, lr, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Re-check learnable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# learn.opt.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn.opt.state_dict()['state']) # save grad_avg and sqr_avg?? for each learnable params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0414,  0.0972,  0.1735,  ...,  0.0482,  0.2040, -0.1077],\n",
       "        [ 0.0446, -0.1130, -0.0317,  ...,  0.0368,  0.0045, -0.0316],\n",
       "        [ 0.7861,  0.0180, -0.0094,  ..., -0.0839,  0.3047, -0.1075],\n",
       "        ...,\n",
       "        [ 0.0302, -0.1054, -0.0251,  ..., -0.0073,  0.1326,  0.0775],\n",
       "        [-0.1252,  0.0521, -0.0341,  ..., -0.0532,  0.1394,  0.0756],\n",
       "        [-0.0021, -0.0180,  0.0514,  ...,  0.0674,  0.1087,  0.0644]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[0].encoder.weight.data # weight is updated everywhere. Good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.to_fp32().save(mdl_path/lm_fns[0], with_opt=False) \n",
    "# save the state_dict (all possible learnable parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(mdl_path/(lm_fns[1] + '.pkl')):\n",
    "    os.remove(mdl_path/(lm_fns[1] + '.pkl'))\n",
    "#     print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(mdl_path/(lm_fns[1] + '.pkl'), 'wb') as f:\n",
    "    pickle.dump(learn.dls.vocab, f) # save list of strings, which are vocabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### try drop_mult 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.453883</td>\n",
       "      <td>6.472377</td>\n",
       "      <td>0.101275</td>\n",
       "      <td>647.020081</td>\n",
       "      <td>02:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = language_model_learner(dls, \n",
    "                               AWD_LSTM, \n",
    "                               metrics=[accuracy, Perplexity()],\n",
    "                               drop_mult=0.5,\n",
    "                               pretrained=False,\n",
    "                               path=path).to_fp16()\n",
    "\n",
    "lr = 1e-2\n",
    "lr *= bs/48\n",
    "lr\n",
    "\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(1, lr, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/quantran/.fastai/data/viwiki/models\n"
     ]
    }
   ],
   "source": [
    "mdl_path = path/'models'\n",
    "print(mdl_path)\n",
    "mdl_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lm_fns = [f'vi_wt', f'vi_wt_vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# learn.to_fp32().save(mdl_path/lm_fns[0], with_opt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# learn.dls.vocab.save(mdl_path/(lm_fns[1] + '.pkl'))\n",
    "# with open(mdl_path/(lm_fns[1] + '.pkl'), 'wb') as f:\n",
    "#     pickle.dump(learn.dls.vocab, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### try original wikitext param training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "config = awd_lstm_lm_config.copy()\n",
    "config.update({'input_p': 0.6, 'output_p': 0.4, 'weight_p': 0.5, 'embed_p': 0.1, 'hidden_p': 0.2})\n",
    "model = get_language_model(AWD_LSTM, len(dls.vocab), config=config)\n",
    "opt_func = partial(Adam, wd=0.1, eps=1e-7)\n",
    "cbs = [MixedPrecision(clip=0.1), ModelResetter, RNNRegularizer(alpha=2, beta=1)]\n",
    "learn = Learner(dls, model, \n",
    "                loss_func=CrossEntropyLossFlat(), \n",
    "                opt_func=opt_func, \n",
    "                cbs=cbs, metrics=[accuracy, Perplexity()]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>202909.375000</td>\n",
       "      <td>9.725590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16740.558594</td>\n",
       "      <td>03:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 5e-03, moms=(0.8,0.7,0.8), div=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Finetuning LM with sentiment analysis data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## prepare datablock and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df.loc[pd.isna(train_df.comment),'comment']='NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_df.loc[pd.isna(test_df.comment),'comment']='NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_000000</td>\n",
       "      <td>Dung dc sp tot cam on \\nshop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_000001</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_000002</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_000003</td>\n",
       "      <td>:(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_000004</td>\n",
       "      <td>Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý :((</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  \\\n",
       "0  train_000000   \n",
       "1  train_000001   \n",
       "2  train_000002   \n",
       "3  train_000003   \n",
       "4  train_000004   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  comment  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                       Dung dc sp tot cam on \\nshop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                       Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                 Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất   \n",
       "3  :(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                  Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý :((   \n",
       "\n",
       "   label  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    1.0  \n",
       "4    1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([train_df,test_df], sort=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>test_010976</td>\n",
       "      <td>Thời gian giao hàng rất nhanh.ngon.mà cay quá... Chất lượng sản phẩm tuyệt vời</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>test_010977</td>\n",
       "      <td>Sản phẩm hơi cũ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>test_010978</td>\n",
       "      <td>Sản phẩm chắc chắn nhưng k bóng bằng trong hình</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>test_010979</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời có mùi thơm rất dễ chịu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10980</th>\n",
       "      <td>test_010980</td>\n",
       "      <td>như quảng cáo. sim rất tốt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  \\\n",
       "10976  test_010976   \n",
       "10977  test_010977   \n",
       "10978  test_010978   \n",
       "10979  test_010979   \n",
       "10980  test_010980   \n",
       "\n",
       "                                                                               comment  \\\n",
       "10976   Thời gian giao hàng rất nhanh.ngon.mà cay quá... Chất lượng sản phẩm tuyệt vời   \n",
       "10977                                                                  Sản phẩm hơi cũ   \n",
       "10978                                  Sản phẩm chắc chắn nhưng k bóng bằng trong hình   \n",
       "10979                            Chất lượng sản phẩm tuyệt vời có mùi thơm rất dễ chịu   \n",
       "10980                                                       như quảng cáo. sim rất tốt   \n",
       "\n",
       "       label  \n",
       "10976    NaN  \n",
       "10977    NaN  \n",
       "10978    NaN  \n",
       "10979    NaN  \n",
       "10980    NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_sen = TextDataLoaders.from_df(df, path=path, text_col='comment', \n",
    "                                  is_lm=True, \n",
    "                                  valid_pct=0.1,\n",
    "                                  seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj giày đẹp nhưng chắc đi nhanh hỏng xxrep 3 😂 xxbos xxmaj bảo hỗn hợp nhưng toàn là xxunk kẹo dâu chắc được tầm chục cái @@ xxbos xxmaj nhấn tần vài lần là bọt tung xxunk thích ơi là thích xxbos xxmaj chất lượng sản phẩm rất kém . xxmaj rất không đáng tiền xxbos xxmaj giao hàng rất nhanh lần này gà hơi bị vụng cơm cháy nát</td>\n",
       "      <td>xxmaj giày đẹp nhưng chắc đi nhanh hỏng xxrep 3 😂 xxbos xxmaj bảo hỗn hợp nhưng toàn là xxunk kẹo dâu chắc được tầm chục cái @@ xxbos xxmaj nhấn tần vài lần là bọt tung xxunk thích ơi là thích xxbos xxmaj chất lượng sản phẩm rất kém . xxmaj rất không đáng tiền xxbos xxmaj giao hàng rất nhanh lần này gà hơi bị vụng cơm cháy nát và</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxmaj shop phục vụ rất kém mình đặt 4 bộ thì 1 bộ giao sai mẫu 1 bộ giao thiếu mũ . xxmaj liên hệ với shop nói mình đồng ý nhận bộ sai xxunk chỉ yêu cầu shop gửi mũ cho mình chứ mình không trả hàng lại xxunk đọc tin nhắn rồi i m lặng không đáng bao nhiêu tiền nhưng làm ăn mất uy tín quá xxbos đóng gói</td>\n",
       "      <td>shop phục vụ rất kém mình đặt 4 bộ thì 1 bộ giao sai mẫu 1 bộ giao thiếu mũ . xxmaj liên hệ với shop nói mình đồng ý nhận bộ sai xxunk chỉ yêu cầu shop gửi mũ cho mình chứ mình không trả hàng lại xxunk đọc tin nhắn rồi i m lặng không đáng bao nhiêu tiền nhưng làm ăn mất uy tín quá xxbos đóng gói sản</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxbos xxmaj mình đặt giao ngày thứ 3 vừa rồi thì thấy thiếu postcard và lịch nên liên hệ cho tiki ngay thế mà nói xem lại rồi xxunk ba ngày vẫn chưa thấy gọi lại ! xxmaj mong tiki khắc phục sự cố này xxbos xxmaj good product quality \\n▁ xxmaj excellent service by seller \\n▁ xxmaj fast delivery xxbos xxmaj xấu . xxmaj toàn dính vào đi mấy ngày là</td>\n",
       "      <td>xxmaj mình đặt giao ngày thứ 3 vừa rồi thì thấy thiếu postcard và lịch nên liên hệ cho tiki ngay thế mà nói xem lại rồi xxunk ba ngày vẫn chưa thấy gọi lại ! xxmaj mong tiki khắc phục sự cố này xxbos xxmaj good product quality \\n▁ xxmaj excellent service by seller \\n▁ xxmaj fast delivery xxbos xxmaj xấu . xxmaj toàn dính vào đi mấy ngày là bung</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_sen.show_batch(max_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vi_wt', 'vi_wt_vocab']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_fns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Load params and vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('/home/quantran/.fastai/data/viwiki/models/vi_wt.pth'),\n",
       " Path('/home/quantran/.fastai/data/viwiki/models/vi_wt_vocab.pkl')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[mdl_path/(lm_fns[0]+'.pth'),mdl_path/(lm_fns[1] + '.pkl')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Recreating def load_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wgts = torch.load(mdl_path/(lm_fns[0]+'.pth'), map_location = lambda storage,loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16880, 400]), torch.Size([4608, 1152]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgts['0.encoder.weight'].shape,wgts['0.rnns.0.weight_hh_l0_raw'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn_sen = language_model_learner(dls_sen, \n",
    "                               AWD_LSTM, \n",
    "                               metrics=[accuracy, Perplexity()],\n",
    "                               drop_mult=1.0,\n",
    "                               pretrained_fnames=lm_fns,\n",
    "                               path=path).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# bs=64\n",
    "# bs=24\n",
    "bs=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "lr *= bs/48."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5128"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls_sen.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(5128, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(5128, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=5128, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_sen.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['torch.Size([4608, 1152]): False',\n",
       " 'torch.Size([4608, 400]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([4608, 1152]): False',\n",
       " 'torch.Size([4608, 1152]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([1600, 400]): False',\n",
       " 'torch.Size([1600, 1152]): False',\n",
       " 'torch.Size([1600]): False',\n",
       " 'torch.Size([1600]): False',\n",
       " 'torch.Size([5128, 400]): True',\n",
       " 'torch.Size([5128]): True']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"{getattr(i,'shape')}: {i.requires_grad}\" for l in learn_sen.opt.param_lists for i in l]\n",
    "# all requires_grad true b/c unfreeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.629779</td>\n",
       "      <td>4.114153</td>\n",
       "      <td>0.319868</td>\n",
       "      <td>61.200378</td>\n",
       "      <td>00:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.226692</td>\n",
       "      <td>3.956623</td>\n",
       "      <td>0.331434</td>\n",
       "      <td>52.280468</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.043056</td>\n",
       "      <td>3.915927</td>\n",
       "      <td>0.335153</td>\n",
       "      <td>50.195576</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_sen.fit_one_cycle(3, lr*10, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.970504</td>\n",
       "      <td>3.848961</td>\n",
       "      <td>0.341873</td>\n",
       "      <td>46.944244</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.876658</td>\n",
       "      <td>3.764037</td>\n",
       "      <td>0.350300</td>\n",
       "      <td>43.122166</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.775550</td>\n",
       "      <td>3.710275</td>\n",
       "      <td>0.355639</td>\n",
       "      <td>40.865040</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.702173</td>\n",
       "      <td>3.653225</td>\n",
       "      <td>0.362710</td>\n",
       "      <td>38.598965</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.634814</td>\n",
       "      <td>3.627688</td>\n",
       "      <td>0.365209</td>\n",
       "      <td>37.625713</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.563126</td>\n",
       "      <td>3.611554</td>\n",
       "      <td>0.367025</td>\n",
       "      <td>37.023540</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.509881</td>\n",
       "      <td>3.606653</td>\n",
       "      <td>0.367896</td>\n",
       "      <td>36.842525</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.499975</td>\n",
       "      <td>3.606580</td>\n",
       "      <td>0.367998</td>\n",
       "      <td>36.839863</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_sen.unfreeze()\n",
    "learn_sen.fit_one_cycle(8, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn_sen.save_encoder('finetuned_sen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Check how word embedding and hidden state are loaded to sentiment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or this https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-10-422d87c3340c\n",
    "# https://nlp.fast.ai/\n",
    "# watch https://www.youtube.com/watch?v=vnOpEwmtFJ8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## prepare text clas datablock and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# bs=64\n",
    "# bs=24\n",
    "bs=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df.loc[pd.isna(train_df.comment),'comment']='NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_000000</td>\n",
       "      <td>Dung dc sp tot cam on \\nshop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_000001</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_000002</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_000003</td>\n",
       "      <td>:(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_000004</td>\n",
       "      <td>Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý :((</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  \\\n",
       "0  train_000000   \n",
       "1  train_000001   \n",
       "2  train_000002   \n",
       "3  train_000003   \n",
       "4  train_000004   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  comment  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                       Dung dc sp tot cam on \\nshop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                       Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                 Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất   \n",
       "3  :(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                  Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý :((   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.576863\n",
       "1    0.423137\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sen_db = DataBlock(blocks=(TextBlock.from_df('comment', seq_len=72, vocab=dls_sen.vocab), CategoryBlock),\n",
    "                      get_x=ColReader('text'), # fixed value\n",
    "                      get_y=ColReader('label'),\n",
    "                      splitter=RandomSplitter(valid_pct=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting-up type transforms pipelines\n",
      "Collecting items from                  id  \\\n",
      "0      train_000000   \n",
      "1      train_000001   \n",
      "2      train_000002   \n",
      "3      train_000003   \n",
      "4      train_000004   \n",
      "...             ...   \n",
      "16082  train_016082   \n",
      "16083  train_016083   \n",
      "16084  train_016084   \n",
      "16085  train_016085   \n",
      "16086  train_016086   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       comment  \\\n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Dung dc sp tot cam on \\nshop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời   \n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh   \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất   \n",
      "3                                                                                                                       :(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...   \n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý :((   \n",
      "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ...   \n",
      "16082                                                                                                                                                                                                                                                                                                                                                                                                       Chẳng biết là Shop có biết đọc hay không mua ốp có mỗi 3 mầu xanh - đen - đỏ. Ngta đã inbox hỏi rõ là còn hàng không kêu có mà đặt 2 cái 1 đen 1 xanh ghi chú rõ xong gửi 1 đỏ 1 xanh chán đời - về học lại chữ đi   \n",
      "16083  Cuốn này mỏng. Đọc một buổi sáng là hết. Thú thật nó làm tôi hơi thất vọng có thể vì tôi đã kì vọng hơi cao vào tác phẩm Hàn Quốc đầu tiên trong đời. Nhưng thôi tôi sẽ cố gắng nhận xét khách quan nhất có thể.\\nTuy đặt vào tình huống đau buồn - sau sự ra đi của một cậu học sinh mới mười sáu tuổi - nhưng Tôi đã chết vào một ngày nào đó không quá u ám nặng nề. Thay vì khai thác tột cùng nỗi đau và mất mát, tác giả cố gắng xoa dịu nó, hàn gắn nó bằng những kí ức tươi đẹp, những suy tư giản dị, gần gũi và những tình cảm chân thành. Truyện kể theo lời nhân vật Yoo Mi - bạn thân nhất của cậu bé đ...   \n",
      "16084                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Mang êm chân. Đẹp    \n",
      "16085                                                 Tôi đã nhận đc hàng.Sau đây là vài lời muốn nói.\\nMã code để check hàng chính hãng không tồn tại trên trang web của hãng. Mặc dù chính tôi cào nó ra. Có dấu hiệu đã bị mở hộp, vỏ ngoài lem lem.\\nTôi đã tin tưởng vào mã code, vì nhiều lần mua hàng của digiworl, nhưng đến hôm nay tikitrading đã làm mất hình ảnh đó.\\nMón đồ không quá đắt đỏ mua được sự gian dối của tikitrading quá là hời cho tôi.\\nNếu đây là món hàng vài chục triệu thì sao ?\\nTất nhiên tôi sẽ làm sáng toả mọi chuyện trên các diễn đàn công nghệ.\\nOK xem như tôi đặt niềm tin nhầm chỗ.   \n",
      "16086                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Hình vậy mà túi xấu qá kém chất lg qá   \n",
      "\n",
      "       label  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          1  \n",
      "4          1  \n",
      "...      ...  \n",
      "16082      1  \n",
      "16083      1  \n",
      "16084      0  \n",
      "16085      1  \n",
      "16086      1  \n",
      "\n",
      "[16087 rows x 3 columns]\n",
      "Found 16087 items\n",
      "2 datasets of sizes 14479,1608\n",
      "Setting up Pipeline: ColReader -> Tokenizer -> Numericalize\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Pipeline: ColReader -> Categorize\n",
      "\n",
      "Building one sample\n",
      "  Pipeline: ColReader -> Tokenizer -> Numericalize\n",
      "    starting from\n",
      "      id                                                                                                                  train_003187\n",
      "label                                                                                                                          0\n",
      "text           [xxbos, xxmaj, shop, phục, vụ, rất, tốt, đây, là, lần, thứ, 2, mua, hàng, ở, shop, r, và, sẽ, ủng, hộ, shop, dài]\n",
      "text_length                                                                                                                   23\n",
      "Name: 3187, dtype: object\n",
      "    applying ColReader gives\n",
      "      (#23) ['xxbos','xxmaj','shop','phục','vụ','rất','tốt','đây','là','lần'...]\n",
      "    applying Tokenizer gives\n",
      "      (#23) ['xxbos','xxmaj','shop','phục','vụ','rất','tốt','đây','là','lần'...]\n",
      "    applying Numericalize gives\n",
      "      TensorText of size 23\n",
      "  Pipeline: ColReader -> Categorize\n",
      "    starting from\n",
      "      id                                                                                                                  train_003187\n",
      "label                                                                                                                          0\n",
      "text           [xxbos, xxmaj, shop, phục, vụ, rất, tốt, đây, là, lần, thứ, 2, mua, hàng, ở, shop, r, và, sẽ, ủng, hộ, shop, dài]\n",
      "text_length                                                                                                                   23\n",
      "Name: 3187, dtype: object\n",
      "    applying ColReader gives\n",
      "      0\n",
      "    applying Categorize gives\n",
      "      TensorCategory(0)\n",
      "\n",
      "Final sample: (TensorText([  2,   8,  14,  48,  45,  10,  32, 237,  33,  69, 267,  70,  25,  13,\n",
      "        153,  14, 558,  19,  72,  98,  95,  14, 121]), TensorCategory(0))\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up after_item: Pipeline: ToTensor\n",
      "Setting up before_batch: Pipeline: partial\n",
      "Setting up after_batch: Pipeline: \n",
      "\n",
      "Building one batch\n",
      "Applying item_tfms to the first sample:\n",
      "  Pipeline: ToTensor\n",
      "    starting from\n",
      "      (TensorText of size 23, TensorCategory(0))\n",
      "    applying ToTensor gives\n",
      "      (TensorText of size 23, TensorCategory(0))\n",
      "\n",
      "Adding the next 1 samples\n",
      "\n",
      "Applying before_batch to the list of samples\n",
      "  Pipeline: partial\n",
      "    starting from\n",
      "      [(TensorText of size 23, TensorCategory(0)), (TensorText of size 107, TensorCategory(1))]\n",
      "    applying partial gives\n",
      "      [(TensorText of size 107, TensorCategory(0)), (TensorText of size 107, TensorCategory(1))]\n",
      "\n",
      "Collating items in a batch\n",
      "\n",
      "No batch_tfms to apply\n"
     ]
    }
   ],
   "source": [
    "sen_db.summary(train_df,bs=2)\n",
    "# note: there is before_batch (partial func) that probably does the padding and make sure \n",
    "# tensor size is equal among batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_clas = sen_db.dataloaders(train_df, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: partial"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls_clas.before_batch # maybe in text dataloader definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dls_clas = TextDataLoaders.from_df(train_df, path=path, text_col='comment', \n",
    "#                                    text_vocab = dls_sen.vocab,\n",
    "#                                    label_col='label',\n",
    "#                                   valid_pct=0.1,\n",
    "#                                   seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj cuốn này mỏng . đọc một buổi sáng là hết . xxmaj thú thật nó làm tôi hơi thất vọng có thể vì tôi đã kì vọng hơi cao vào tác phẩm xxmaj hàn xxmaj quốc đầu tiên trong đời . xxmaj nhưng thôi tôi sẽ cố gắng nhận xét khách quan nhất có thể . \\n xxmaj tuy đặt vào tình huống đau buồn - sau sự ra đi của một cậu học sinh mới mười sáu tuổi - nhưng xxmaj tôi đã chết vào một ngày nào đó không quá u ám nặng nề . xxmaj thay vì khai thác tột cùng nỗi đau và mất mát , tác giả cố gắng xxunk dịu nó , hàn gắn nó bằng những kí ức tươi đẹp , những suy tư giản dị , gần gũi và những tình cảm chân thành . xxmaj truyện kể theo lời</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_clas.show_batch(max_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## study dataloaders and tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " 'xxup',\n",
       " 'xxmaj',\n",
       " '.']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls_clas.vocab[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [0,1]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls_clas.vocab[1] # y labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp_i = iter(dls_clas.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y = next(temp_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 741]), torch.Size([128]))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorText([[   2,    8,  262,  ..., 1022,   44,    9],\n",
       "        [   1,    1,    1,  ...,    1,    1,    1],\n",
       "        [   1,    1,    1,  ...,    1,    1,    1],\n",
       "        ...,\n",
       "        [   1,    1,    1,  ...,    1,    1,    1],\n",
       "        [   1,    1,    1,  ...,    1,    1,    1],\n",
       "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note: how padding works: https://dev.fast.ai/text.data#Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj cuốn này mỏng . đọc một buổi sáng là hết . xxmaj thú thật nó làm tôi hơi thất vọng có thể vì tôi đã kì vọng hơi cao vào tác phẩm xxmaj hàn xxmaj quốc đầu tiên trong đời . xxmaj nhưng thôi tôi sẽ cố gắng nhận xét khách quan nhất có thể . \\n xxmaj tuy đặt vào tình huống đau buồn - sau sự ra đi của một cậu học sinh mới mười sáu tuổi - nhưng xxmaj tôi đã chết vào một ngày nào đó không quá u ám nặng nề . xxmaj thay vì khai thác tột cùng nỗi đau và mất mát , tác giả cố gắng xxunk dịu nó , hàn gắn nó bằng những kí ức tươi đẹp , những suy tư giản dị , gần gũi và những tình cảm chân thành . xxmaj truyện kể theo lời nhân vật xxmaj yoo xxmaj mi - bạn thân nhất của cậu bé đã chết - nên từng kí ức lại càng xxunk xxunk , từng tiếng cười lại càng giòn tan đến nao lòng . \\n đúng như lời giới thiệu , truyện mở đầu bằng bi kịch nhưng không kết thúc trong đau thương , mà ngược lại gieo vào lòng ta những hi vọng . xxmaj cái chết mang lại cho ta nhiều hơn những gì ta tưởng . xxmaj ta biết yêu cuộc sống hơn . xxmaj ta biết trân trọng những người xung quanh ta hơn . xxmaj ta nhận ra sự tồn tại của ta không hề vô nghĩa . xxup và ta cũng thấy được thế giới này có ý nghĩa lớn lao với ta thế nào . \\n xxmaj bởi vì , chẳng phải cậu xxmaj jae xxmaj joon đã từng giả chết để được sống tốt hơn đó sao ? \\n\\n đọc truyện , đôi lúc tôi thấy giật mình bởi những chi tiết mà có lẽ chính tác giả khi viết còn chẳng buồn để ý đến . xxmaj jae xxmaj joon đã học lớp tám rồi mà vẫn trong sáng đến kì xxunk . xxup cô giáo chủ nhiệm lớp tám sa sả những lời chẳng ra gì vào mặt xxmaj yoo xxmaj mi . xxmaj yoo xxmaj mi lớn lên cách biệt , mặc cảm , nổi loạn vì cha mẹ ly dị , và rằng xung quanh cô bé chẳng có ai phải trải qua điều đó cả . xxmaj hay mẹ của xxmaj jae xxmaj joon dễ dàng phát bệnh mỗi khi cậu làm bài kiểm tra không tốt … xxmaj tôi chưa từng thực sự tiếp xúc với con người xxmaj hàn xxmaj quốc bao giờ , nên không thể hiểu được họ . xxmaj xxunk xxmaj xxunk \" \" nâng cấp \" \" những chi tiết đó thì không nói làm gì , nhưng nếu tất cả đều là thực tế ở quốc gia đông á kia ? xxmaj phải chăng tôi đã thoáng thấy một đất nước có kinh tế phát triển quá nhanh , nhanh đến mức xã hội không xxunk theo nổi , và hệ xxunk là sinh ra những con người cô đơn , yếu đuối trở nên bi quan một cách dễ dàng , vẫn mang đầy những tư tưởng định kiến ? đáng nói hơn , những điều đó được viết ra bằng một giọng văn xxunk nhiên như thể tất cả đều rất bình thường , là chuyện đương nhiên , trong hoàn cảnh như vậy lẽ tất yếu con người phải cư xử như vậy , không bàn cãi … xxup và tôi tự hỏi , đó là bước tiến hay bước lùi trong việc bảo vệ con người ? \\n\\n xxup có hai điểm khiến tôi chưa hài lòng về cuốn sách này . \\n xxmaj thứ nhất là , xây dựng nhân vật thiên về kể lể nhiều hơn là để nhân vật tự xxunk lộ bản thân , nên cảm giác các nhân vật cứ nhàn nhạt , không tạo ấn tượng sâu sắc . \\n xxmaj thứ hai là , truyện không bắt được người đọc phải suy ngẫm , gấp cuốn sách lại nội dung truyện cứ thế trôi xxunk tuột , không đọng lại gì nhiều . \\n xxmaj nhưng đối với một tác phẩm dành cho thiếu niên như vậy cũng đủ để nhận những lời khen xứng đáng .'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([dls_clas.vocab[0][i] for i in x[0].cpu().data.numpy()]) # no padding here at 1st item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxbos xxmaj cuốn sách này của xxup tờ xxmaj pi mình không mua mà đọc được nó khi một người bạn giới thiệu và cho mượn .khi đọc xong cuốn sách này thì mình cảm thấy một điều là chưa đủ . \\n xxmaj tác giả chưa đủ trải , câu chuyện chưa đủ ngấm . xxmaj các bạn trẻ khi đọc vào có thể cảm thấy , ừ tác phẩm này rất đời , rất thực ấy chứ . xxmaj nhưng với mình như thế vẫn là chưa đủ cho một tác phẩm mang tính phản ánh xã hội . xxmaj khi mà tác giả mượn những câu chuyện thường ngày , mượn những điều gần gũi , chân thực với mỗi chúng ta để xxunk lộ , cắt lát nhiều khía cạnh cuộc sống thì mình thấy tác giả phải đủ trải hay ít nhất là đủ hiểu về những điều ấy đã . xxmaj những câu chuyện này , những cảm xúc này tác giả kể lại chỉ với một cách nhìn của người ngoài cuộc , điều đó là lẽ dĩ nhiên . xxmaj mình không nói viết văn là phải viết những thứ bản thân đã trải nghiệm nhưng xxunk chốt là thực sự cảm hóa được những gì mình viết ra . xxmaj nhưng ở đây tác giả chưa làm được điều đó , hoặc là mình chưa thể cảm nhận được điều đó . xxmaj cách nhìn trung lập y như khi bạn buôn bán một câu chuyện của người nào đó xung quanh mình . xxup nó chưa đủ sức gợi cũng chưa thể bật lên những cảm xúc cần thiết phải có , ta thấy như tác giả chỉ là kể lại một câu chuyện thường ngày , hay một câu chuyện quen mà chúng ta vẫn hay nghe đó thôi . \\n xxmaj chính vì những câu chuyện này chỉ mang tính kể nên có bạn nhận xét là nó xxup trào xxup phúng thì mình không đồng ý . xxup nó chưa đủ thấm chưa đủ sâu để được gọi là trào phúng . xxmaj khi nào mà ta đọc những câu chuyện kể thường ngày tưởng chứng chẳng thể hiện ra được cái gì nhưng ngay từ bản chất nó đã là một sự lên án , tố cáo những mặt xấu xã hội đó mới gọi là trào phúng . xxmaj giống như khi bạn đọc xxup số đỏ , xxmaj lão xxmaj xxunk , xxmaj chí xxmaj xxunk , … đấy cũng chỉ là câu chuyện bình thường , con người bình thường của cả cái xã hội thời ấy nhưng tin chắc bạn thấm được nhiều hơn những điều bình thường ấy . \\n đó cũng là lý giải cho tại sao những tác phẩm ấy có một sức sống lâu bền cùng năm tháng . \\n xxmaj nói chung thì mình vẫn ủng hộ và mong xxup tờ xxmaj pi có thể viết tiếp và trau dồi bản thân hơn để có những tác phẩm đời hơn nữa . ! xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([dls_clas.vocab[0][i] for i in x[1].cpu().data.numpy()]) # padding starts at 2nd item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 5])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(temp_i)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   2, 1133,  264,  118,   66],\n",
       "         [   2,   20,  659,  976, 3590],\n",
       "         [   2, 2849,  693,  538,  591],\n",
       "         [   2,   40,  680,   38, 1160],\n",
       "         [   2,    8,   13,  118,   66]], device='cuda:0'),\n",
       " tensor([[   2,    0,    1,    1,    1],\n",
       "         [   2,   38,    1,    1,    1],\n",
       "         [   2, 1026,    1,    1,    1],\n",
       "         [   2, 1299,    1,    1,    1],\n",
       "         [   2, 4384,    1,    1,    1]], device='cuda:0'))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5],x[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos giay kg giống hình'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([dls_clas.vocab[0][i] for i in x[0].cpu().data.numpy()]) # no padding here at 1st item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos được xxpad xxpad xxpad'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([dls_clas.vocab[0][i] for i in x[-4].cpu().data.numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SortedDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai2.text.data.SortedDL"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dls_clas.train) #inherit TfmdDL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataLoader that goes throught the item in the order given by sort_func\n",
    "\n",
    "res is the result of sort_func applied on all elements of the dataset. You can pass it if available to make the init faster by avoiding an initial pass over the whole dataset. If shuffle is True, this will shuffle a bit the results of the sort **to have items of roughly the same size in batches**, but not in the exact sorted order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: partial"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls_clas.before_batch # this is pad_input_chunk function\n",
    "\n",
    "# 'before_batch': partial(pad_input_chunk, seq_len=seq_len)\n",
    "# https://dev.fast.ai/text.data#SortedDL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## datablock tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai2.data.block.DataBlock"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vnmese_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sen_db = DataBlock(blocks=(TextBlock.from_df('comment', seq_len=72, vocab=dls_sen.vocab), CategoryBlock),\n",
    "#                       get_x=ColReader('text'), # fixed value\n",
    "#                       get_y=ColReader('label'),\n",
    "#                       splitter=RandomSplitter(valid_pct=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sen_db.type_tfms) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Tokenizer: (str,object) -> encodes\n",
       "(Path,object) -> encodes (object,object) -> decodes,Numericalize: (object,object) -> encodes (object,object) -> decodes]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_db.type_tfms[0] # tokenizer and numerialize tfms for X pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [Categorize: (object,object) -> encodes (object,object) -> decodes]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_db.type_tfms[1] # categorize for y pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [ToTensor: (PILMask,object) -> encodes\n",
       "(PILBase,object) -> encodes ]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_db.default_item_tfms #default item tfm (for dataloaders' after_item pipeline) for PILBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#0) []"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_db.default_batch_tfms #default batch item tfm (for dataloaders' after_batch pipeline\n",
    "# normall it will be IntToFloatTensor, but token should be int so nothing is here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#1) [ToTensor: (PILMask,object) -> encodes\n",
       " (PILBase,object) -> encodes ],\n",
       " (#0) [])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_db.item_tfms,sen_db.batch_tfms \n",
    "# nothing different from default_item_tfms and default_batch_tfms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## datasets and its tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1608, 14479)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls_clas.valid.dataset),len(dls_clas.train.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dsets = dls_clas.train.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, 2)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dsets[0]),len(dsets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_ds = dls_clas.train_ds\n",
    "\n",
    "val_ds = dls_clas.valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, fastai2.data.core.TfmdLists, fastai2.data.core.TfmdLists)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds.tls),type(train_ds.tls[0]),type(train_ds.tls[1]) # 2 tfmdlist, 1 for X train, 1 for y train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Pipeline: ColReader -> Tokenizer -> Numericalize,\n",
       " Pipeline: ColReader -> Tokenizer -> Numericalize)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0].tfms,val_ds.tls[0].tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Pipeline: ColReader -> Categorize, Pipeline: ColReader -> Categorize)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[1].tfms,val_ds.tls[1].tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8903</th>\n",
       "      <td>train_008903</td>\n",
       "      <td>1</td>\n",
       "      <td>[xxbos, xxmaj, trả, tiền, nhưng, ko, giao, hàng]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>train_002526</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, xxmaj, rất, đẹp, và, chắc, chắn, .]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>train_000191</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, xxmaj, chất, lượng, sản, phẩm, tuyệt, vời, \\n\\n ▁, đóng, gói, sản, phẩm, rất, đẹp, và, chắc, chắn, \\n , đóng, gói, sản, phẩm, rất, đẹp, và, chắc, chắn]</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>train_009999</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, xxmaj, giao, hàng, rất, nhanh, (, chỉ, sau, 1, ngày, )]</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3447</th>\n",
       "      <td>train_003447</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, xxmaj, hỏi, shop, có, hủ, ko, xxrep, 3, ?, xxmaj, shop, nói, có, và, cho, mình, 1, cái, bịch, túi, zip, to, chà, bá, :, xxrep, 5, )]</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>train_005110</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, xxmaj, gởi, ko, đúng, màu]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8418</th>\n",
       "      <td>train_008418</td>\n",
       "      <td>1</td>\n",
       "      <td>[xxbos, xxmaj, mua, 3, cái, áo, cùng, là, size, m, mà, lại, có, 3, cỡ, khác, nhau, ., xxmaj, mọi, người, mua, hàng, lưu, ý, size, không, đúng, thực, tế, xíu, nào, cả, nha, ., xxmaj, shop, phục, vụ, rất, kém, xxmaj, rất, không, đáng, tiền]</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6051</th>\n",
       "      <td>train_006051</td>\n",
       "      <td>1</td>\n",
       "      <td>[xxbos, xxmaj, máy, ko, sạc, được, chỉ, chạy, được, khi, bỏ, bin, thôi]</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>train_001267</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, xxmaj, ok, nazz]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11303</th>\n",
       "      <td>train_011303</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, ăn, ngon, ,, xxmaj, chất, lượng, sản, phẩm, tuyệt, vời, \\n, xxmaj, shop, phục, vụ, tốt]</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14479 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  label  \\\n",
       "8903   train_008903      1   \n",
       "2526   train_002526      0   \n",
       "191    train_000191      0   \n",
       "9999   train_009999      0   \n",
       "3447   train_003447      0   \n",
       "...             ...    ...   \n",
       "5110   train_005110      0   \n",
       "8418   train_008418      1   \n",
       "6051   train_006051      1   \n",
       "1267   train_001267      0   \n",
       "11303  train_011303      0   \n",
       "\n",
       "                                                                                                                                                                                                                                                 text  \\\n",
       "8903                                                                                                                                                                                                 [xxbos, xxmaj, trả, tiền, nhưng, ko, giao, hàng]   \n",
       "2526                                                                                                                                                                                                      [xxbos, xxmaj, rất, đẹp, và, chắc, chắn, .]   \n",
       "191                                                                                   [xxbos, xxmaj, chất, lượng, sản, phẩm, tuyệt, vời, \\n\\n ▁, đóng, gói, sản, phẩm, rất, đẹp, và, chắc, chắn, \\n , đóng, gói, sản, phẩm, rất, đẹp, và, chắc, chắn]   \n",
       "9999                                                                                                                                                                                  [xxbos, xxmaj, giao, hàng, rất, nhanh, (, chỉ, sau, 1, ngày, )]   \n",
       "3447                                                                                                     [xxbos, xxmaj, hỏi, shop, có, hủ, ko, xxrep, 3, ?, xxmaj, shop, nói, có, và, cho, mình, 1, cái, bịch, túi, zip, to, chà, bá, :, xxrep, 5, )]   \n",
       "...                                                                                                                                                                                                                                               ...   \n",
       "5110                                                                                                                                                                                                               [xxbos, xxmaj, gởi, ko, đúng, màu]   \n",
       "8418   [xxbos, xxmaj, mua, 3, cái, áo, cùng, là, size, m, mà, lại, có, 3, cỡ, khác, nhau, ., xxmaj, mọi, người, mua, hàng, lưu, ý, size, không, đúng, thực, tế, xíu, nào, cả, nha, ., xxmaj, shop, phục, vụ, rất, kém, xxmaj, rất, không, đáng, tiền]   \n",
       "6051                                                                                                                                                                          [xxbos, xxmaj, máy, ko, sạc, được, chỉ, chạy, được, khi, bỏ, bin, thôi]   \n",
       "1267                                                                                                                                                                                                                         [xxbos, xxmaj, ok, nazz]   \n",
       "11303                                                                                                                                                 [xxbos, ăn, ngon, ,, xxmaj, chất, lượng, sản, phẩm, tuyệt, vời, \\n, xxmaj, shop, phục, vụ, tốt]   \n",
       "\n",
       "       text_length  \n",
       "8903             8  \n",
       "2526             8  \n",
       "191             28  \n",
       "9999            12  \n",
       "3447            29  \n",
       "...            ...  \n",
       "5110             6  \n",
       "8418            46  \n",
       "6051            13  \n",
       "1267             4  \n",
       "11303           17  \n",
       "\n",
       "[14479 rows x 4 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0].items \n",
    "# no transform applied yet, but note that texts have already been 'ColReader' and 'Tokenizer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorText([  2,   8, 114,  36,  34,  28,  17,  13]), 8)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0][0],len(train_ds.tls[0][0]) # when indexed, tfms are applied (last one: Numericalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxbos', 'xxmaj', 'trả', 'tiền', 'nhưng', 'ko', 'giao', 'hàng']"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[train_ds.vocab[0][i] for i in train_ds.tls[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define sentiment clas learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.5, \n",
    "                                     metrics=[accuracy,F1Score()],\n",
    "                                    seq_len=72,\n",
    "                                    path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/quantran/.fastai/data/viwiki')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_clas.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas = learn_clas.load_encoder('finetuned_sen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05333333333333333"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=2e-2\n",
    "lr *= bs/48\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(fastai2.text.learner.TextLearner, fastai2.text.models.core.SequentialRNN, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(learn_clas),type(learn_clas.model),len(learn_clas.model) # no more LMLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceEncoder(\n",
       "  (module): AWD_LSTM(\n",
       "    (encoder): Embedding(5128, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(5128, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_clas.model[0] # same as LMLearner model\n",
    "\n",
    "# The model uses a SentenceEncoder, \n",
    "# which means the texts are passed seq_len tokens at a time, \n",
    "# and WILL ONLY COMPUTE THE GRADIENTS on the last max_len steps (default to 1440)\n",
    "\n",
    "# This will take care of the question: some reviews are long, how to know we have \n",
    "# fetched an entire review before gradient can be computed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoolingLinearClassifier(\n",
       "  (layers): Sequential(\n",
       "    (0): LinBnDrop(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): LinBnDrop(\n",
       "      (0): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=50, out_features=2, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_clas.model[1] # not linear decoder\n",
    "# 1200 is 400*3, or (the size of hidden state activation of last LSTM) * 3\n",
    "# which includes: [last_hidden, max_pool, avg_pool]\n",
    "# learn how that is calculated: http://dev.fast.ai/text.models.core#masked_concat_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### param groups and weight shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn_clas.opt.param_lists) # 5 layers total for discriminative fine tuning\n",
    "# since no longer doing 'tie_weight': the word embedding weight is now separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5128"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls_clas.vocab[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5128, 400])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_clas.opt.param_lists[0][0].shape # the word embedding weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['torch.Size([5128, 400]): False',\n",
       " 'torch.Size([4608, 1152]): False',\n",
       " 'torch.Size([4608, 400]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([4608, 1152]): False',\n",
       " 'torch.Size([4608, 1152]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([1600, 400]): False',\n",
       " 'torch.Size([1600, 1152]): False',\n",
       " 'torch.Size([1600]): False',\n",
       " 'torch.Size([1600]): False',\n",
       " 'torch.Size([1200]): True',\n",
       " 'torch.Size([1200]): True',\n",
       " 'torch.Size([50, 1200]): True',\n",
       " 'torch.Size([50]): True',\n",
       " 'torch.Size([50]): True',\n",
       " 'torch.Size([2, 50]): True']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"{getattr(i,'shape')}: {i.requires_grad}\" for l in learn_clas.opt.param_lists for i in l]\n",
    "# all requires_grad true b/c unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn_clas.model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.module.encoder.weight: torch.Size([5128, 400])',\n",
       " '0.module.encoder_dp.emb.weight: torch.Size([5128, 400])',\n",
       " '0.module.rnns.0.weight_hh_l0_raw: torch.Size([4608, 1152])',\n",
       " '0.module.rnns.0.module.weight_ih_l0: torch.Size([4608, 400])',\n",
       " '0.module.rnns.0.module.bias_ih_l0: torch.Size([4608])',\n",
       " '0.module.rnns.0.module.bias_hh_l0: torch.Size([4608])',\n",
       " '0.module.rnns.1.weight_hh_l0_raw: torch.Size([4608, 1152])',\n",
       " '0.module.rnns.1.module.weight_ih_l0: torch.Size([4608, 1152])',\n",
       " '0.module.rnns.1.module.bias_ih_l0: torch.Size([4608])',\n",
       " '0.module.rnns.1.module.bias_hh_l0: torch.Size([4608])',\n",
       " '0.module.rnns.2.weight_hh_l0_raw: torch.Size([1600, 400])',\n",
       " '0.module.rnns.2.module.weight_ih_l0: torch.Size([1600, 1152])',\n",
       " '0.module.rnns.2.module.bias_ih_l0: torch.Size([1600])',\n",
       " '0.module.rnns.2.module.bias_hh_l0: torch.Size([1600])',\n",
       " '1.layers.0.0.weight: torch.Size([1200])',\n",
       " '1.layers.0.0.bias: torch.Size([1200])',\n",
       " '1.layers.0.0.running_mean: torch.Size([1200])',\n",
       " '1.layers.0.0.running_var: torch.Size([1200])',\n",
       " '1.layers.0.0.num_batches_tracked: torch.Size([])',\n",
       " '1.layers.0.2.weight: torch.Size([50, 1200])',\n",
       " '1.layers.1.0.weight: torch.Size([50])',\n",
       " '1.layers.1.0.bias: torch.Size([50])',\n",
       " '1.layers.1.0.running_mean: torch.Size([50])',\n",
       " '1.layers.1.0.running_var: torch.Size([50])',\n",
       " '1.layers.1.0.num_batches_tracked: torch.Size([])',\n",
       " '1.layers.1.2.weight: torch.Size([2, 50])']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{k}: {v.shape}' for k,v in learn_clas.model.state_dict().items()]\n",
    "# for some reason state_dict includes encoder (embedding) weight, but opt.param_lists or model.parameters don't\n",
    "# because weighs of embedding (encoder) and weight of last linear layer is the same\n",
    "# because of 'tie_weights': look at awdlstm.py, in awd_lstm_lm_config 'tie_weights' is True\n",
    "# For language model, tie_weights will make embedding weight == last layer linear weight\n",
    "# Why? More efficient training. This is mentioned in AWD LSTM paper by Stephen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.389166</td>\n",
       "      <td>0.272311</td>\n",
       "      <td>0.876244</td>\n",
       "      <td>0.867067</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.361879</td>\n",
       "      <td>0.259818</td>\n",
       "      <td>0.891169</td>\n",
       "      <td>0.881195</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.373139</td>\n",
       "      <td>0.248702</td>\n",
       "      <td>0.896144</td>\n",
       "      <td>0.883947</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.fit_one_cycle(3, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.save(f'vi_clas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.332855</td>\n",
       "      <td>0.263983</td>\n",
       "      <td>0.878731</td>\n",
       "      <td>0.852608</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.236296</td>\n",
       "      <td>0.214972</td>\n",
       "      <td>0.909826</td>\n",
       "      <td>0.896650</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.freeze_to(-2)\n",
    "learn_clas.fit_one_cycle(2, slice(lr/(2.6**4),lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.259469</td>\n",
       "      <td>0.235889</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.900690</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.201866</td>\n",
       "      <td>0.244321</td>\n",
       "      <td>0.913557</td>\n",
       "      <td>0.903001</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.freeze_to(-3)\n",
    "learn_clas.fit_one_cycle(2, slice(lr/2/(2.6**4),lr/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.save(f'vi_clas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.161196</td>\n",
       "      <td>0.448453</td>\n",
       "      <td>0.907960</td>\n",
       "      <td>0.896648</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.unfreeze()\n",
    "learn_clas.fit_one_cycle(1, slice(lr/10/(2.6**4),lr/10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('fastai2': conda)",
   "language": "python",
   "name": "python37664bitfastai2conda023d9f2c3b894be385b0b3b80e252fc1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
