{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/home/quantran/.fastai/data/viwiki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/quantran/.fastai/data/viwiki')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/quantran/.fastai/data/viwiki/docs')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path/'docs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Prepare df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_lol(path): # make list of list containing file name and file content\n",
    "    name = path.stem\n",
    "    with open(path, 'r',encoding=\"utf-8\") as temp:\n",
    "        data = temp.read()\n",
    "    return [name,data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Công nghệ pháp lý\n",
      "\n",
      "Công nghệ pháp lý, còn được gọi là Legal Tech , đề cập đến việc sử dụng công nghệ và phần mềm nhằm cung cấp dịch vụ pháp lý. Các công ty Legal Tech nói chung là các công ty khởi nghiệp được thành lập với mục đích phá vỡ thị trường pháp lý bảo thủ theo truyền thống.\n",
      "\n",
      "Theo truyền thống, công nghệ pháp lý đề cập đến việc ứng dụng công nghệ và phần mềm để giúp các công ty luật quản lý nghiệp vụ, lưu trữ tài liệu, thanh toán, kế toán và khám phá điện tử. Từ năm 2011, Legal Tech đã phát triển để liên kết nhiều hơn với các công ty khởi nghiệp công nghệ phá vỡ việc thực hành pháp luật bằng cách cho mọi người truy cập vào phần mềm trực tuyến làm giảm hoặc trong một số trường hợp loại bỏ sự cần thiết phải hỏi ý kiến luật sư hoặc kết nối mọi người với luật sư hiệu quả hơn thông qua trực tuyến thị trường và các trang web phù hợp với luật sư.\n",
      "\n",
      "Ngành công nghiệp pháp lý được coi là bảo thủ và truyền thống, với Law Technology Today lưu ý rằng \"trong 50 năm, trải nghiệm của khách hàng tại hầu hết các công ty luật hầu như không thay đổi\". Lý do cho điều này bao gồm thực tế là các công ty luật phải đối mặt với các ưu đãi cắt giảm chi phí yếu hơn so với các ngành nghề khác (vì họ giao việc giải ngân trực tiếp cho khách hàng của họ) và được coi là không thích rủi ro (vì một lỗi công nghệ nhỏ có thể gây hậu quả tài chính đáng kể cho khách hàng).\n",
      "\n",
      "Tuy nhiên, sự tăng trưởng của việc thuê các doanh nghiệp tư vấn nội bộ và độ phức tạp ngày càng tăng của họ, cùng với sự phát triển của email, đã dẫn đến việc khách hàng đặt ra áp lực chi phí và thời gian ngày càng tăng lên cho luật sư của họ. Ngoài ra, ngày càng có nhiều khuyến khích để luật sư trở thành người có năng lực về công nghệ, với việc bỏ phiếu của Hiệp hội Luật sư Hoa Kỳ vào tháng 8 năm 2012 để sửa đổi Quy tắc ứng xử chuyên nghiệp để yêu cầu luật sư tuân thủ \"lợi ích và rủi ro liên quan đến công nghệ liên quan\", và sự bão hòa của thị trường khiến nhiều luật sư tìm kiếm những cách thức tiên tiến hơn để cạnh tranh. Sự tăng trưởng theo cấp số nhân của khối lượng tài liệu (chủ yếu là email) phải được xem xét cho các vụ kiện tụng đã thúc đẩy đáng kể việc áp dụng công nghệ được sử dụng trong Khám phá Điện tử, với các yếu tố của ngôn ngữ máy và trí tuệ nhân tạo được kết hợp và các dịch vụ đám mây đã được các công ty luật áp dụng.  \n",
      "\n",
      "Trường Luật Stanford đã thành lập CodeX, Trung tâm Tin học Pháp lý, một trung tâm nghiên cứu liên ngành, cũng bao gồm các công ty được bắt đầu bởi các sinh viên luật và các nhà khoa học máy tính. Một số công ty đã ra khỏi chương trình bao gồm Lex Machina và Legal.io.\n",
      "\n",
      "\n",
      "\n",
      "Tại Việt Nam, tuy LegalTech vẫn còn mới mẻ, nhưng Việt Nam cũng là một thị trường tiềm năng để phát triển ngành này đến từ sự phức tạp trong hệ thống quy định pháp luật, nhu cầu áp dụng luật của doanh nghiệp, sự phát triển của ngành tư vấn luật và tiềm năng sáng tạo của các startup.\n",
      "\n",
      "Việc áp dụng công nghệ không chỉ giúp doanh nghiệp dễ dàng tiếp cận, cập nhật được các chính sách mới mà còn giúp giảm thiểu việc ban hành trùng lặp, chồng chéo các chính sách.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = make_lol((path/'docs').ls()[2])\n",
    "print(temp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77456"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((path/'docs').ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = parallel(make_lol,(path/'docs').ls(),n_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(results,columns=['fname','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77451</th>\n",
       "      <td>Ronda Rousey</td>\n",
       "      <td>Ronda Rousey\\n\\nRonda Jean Rousey ( sinh ngày 1 tháng 2 năm 1987) là một nữ võ sĩ MMA, vận động viên judo, và diễn viên người Mỹ. Cô hiện đang tham gia WWE Raw.\\n\\nRousey là nữ vận động viên đầu tiên của Mỹ giành huy chương judo Olympic (huy chương đồng) ở Thế vận hội Mùa hè 2008. Cô là cựu quán quân UFC nữ hạng gà, cũng như là quán quân nữ hạng gà Strikeforce cuối cùng. Cô từng giành 12 chiến thắng MMA liên tiếp, trong đó có sáu chiến thắng ở Ultimate Fighting Championship (UFC), trước khi để thua trận đầu tiên trước Holly Holm vào tháng 11 năm 2015; cô thắng 11 trận trong hiệp 1, 9 trong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77452</th>\n",
       "      <td>Ngựa cỏ bùn</td>\n",
       "      <td>Ngựa cỏ bùn\\n\\nNgựa cỏ bùn hay Cǎonímǎ (chữ Hán: , phiên âm Hán-Việt: \"thảo nê mã\") là một Internet meme tại Trung Quốc được sử dụng rộng rãi như một dạng biểu tượng nhằm phản đối kiểm duyệt Internet tại Trung Quốc đang ngày càng tăng. Đây là lối chơi chữ với cum từ trong tiếng Trung phổ thông \"cào nǐ mā\" (chữ Hán: , phiên âm Hán-Việt: \"tháo nễ ma\"), nghĩa đen tức là \"địt mẹ mày\" (từ Cǎo/草 là từ \"cấu\" trong từ \"giao cấu\"; ní/泥, tức là từ \"nị\", chỉ ngôi thứ 2, là bạn, mày và từ mǎ/马 là từ \"ma\" hay \"ma ma\" có nghĩa là mẹ hay vú nuôi), và là một trong danh sách 10 sinh vật thần thoại được tạo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77453</th>\n",
       "      <td>Gettext</td>\n",
       "      <td>Gettext\\n\\nTrong điện toán, gettext là một hệ thống quốc tế hóa và bản địa hóa (i18n) thường dùng cho việc viết các ứng dụng đa ngôn ngữ trên các hệ điều hành tương tự Unix. Việc triển khai gettext thường được sử dụng phổ biến nhất là GNU gettext, phát hành bởi GNU Project năm 1995.\\n\\ngettext ban đầu được viết bởi Sun Microsystems vào đầu những năm 1990. GNU Project phát hành GNU gettext, một phần mềm tự do triển khai hệ thống vào năm 1995.\\n\\nMã nguồn được sửa đổi đầu tiên để sử dụng các lệnh gọi GNU gettext. Với phần lớn ngôn ngữ lập trình, việc này được thực hiện bằng cách bao các chuỗ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77454</th>\n",
       "      <td>Rosanna Pansino</td>\n",
       "      <td>Rosanna Pansino\\n\\nRosanna Pansino (sinh ngày 8 tháng 6 năm 1985) là một thợ làm bánh, nữ diễn viên, tác giả và nhân vật YouTube người Mỹ. Cô được biết đến nhiều nhất qua series nấu ăn \"Nerdy Nummies\", một trong những chương trình làm bánh nổi tiếng nhất trên YouTube. Cô cũng thủ vai Violet trong series hoạt hình trên YouTube \"Broken Quest\" và vai The Jet Setter trong series \"Escape the Night\" trên YouTube. Cô có tổ tiên là người Ý, Croatia, Đức và Ireland.\\n\\nPansino ban đầu muốn theo đuổi sự nghiệp làm diễn viên. Cô từng đóng những vai diễn nhỏ trong các tập của \"Parks and Recreation\" và...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77455</th>\n",
       "      <td>Hyperbol</td>\n",
       "      <td>Hyperbol\\n\\nTrong toán học, hyperbol hay hypecbol (từ tiếng Hy Lạp: ὑπερβολή, nghĩa đen là \"vượt quá\" hay \"thái quá\") là một kiểu Đường cô-nic, được định nghĩa là đường giao của một mặt nón với một mặt phẳng cắt cả hai nửa của hình nón.\\n\\nĐường hyperbol còn được định nghĩa là quỹ tích của những điểm trong mặt phẳng có giá trị tuyết đối của hiệu khoảng cách tới hai điểm cố định là một hằng số bằng 2\"a\". \"a\" đồng thời cũng bằng độ dài bán trục lớn của Hyberbol. Hai điểm cố định đó gọi là hai tiêu điểm của hyperbol. Đường thẳng đi qua hai tiêu điểm này được gọi là trục thực của hyberbol và t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 fname  \\\n",
       "77451     Ronda Rousey   \n",
       "77452      Ngựa cỏ bùn   \n",
       "77453          Gettext   \n",
       "77454  Rosanna Pansino   \n",
       "77455         Hyperbol   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          text  \n",
       "77451  Ronda Rousey\\n\\nRonda Jean Rousey ( sinh ngày 1 tháng 2 năm 1987) là một nữ võ sĩ MMA, vận động viên judo, và diễn viên người Mỹ. Cô hiện đang tham gia WWE Raw.\\n\\nRousey là nữ vận động viên đầu tiên của Mỹ giành huy chương judo Olympic (huy chương đồng) ở Thế vận hội Mùa hè 2008. Cô là cựu quán quân UFC nữ hạng gà, cũng như là quán quân nữ hạng gà Strikeforce cuối cùng. Cô từng giành 12 chiến thắng MMA liên tiếp, trong đó có sáu chiến thắng ở Ultimate Fighting Championship (UFC), trước khi để thua trận đầu tiên trước Holly Holm vào tháng 11 năm 2015; cô thắng 11 trận trong hiệp 1, 9 trong...  \n",
       "77452  Ngựa cỏ bùn\\n\\nNgựa cỏ bùn hay Cǎonímǎ (chữ Hán: , phiên âm Hán-Việt: \"thảo nê mã\") là một Internet meme tại Trung Quốc được sử dụng rộng rãi như một dạng biểu tượng nhằm phản đối kiểm duyệt Internet tại Trung Quốc đang ngày càng tăng. Đây là lối chơi chữ với cum từ trong tiếng Trung phổ thông \"cào nǐ mā\" (chữ Hán: , phiên âm Hán-Việt: \"tháo nễ ma\"), nghĩa đen tức là \"địt mẹ mày\" (từ Cǎo/草 là từ \"cấu\" trong từ \"giao cấu\"; ní/泥, tức là từ \"nị\", chỉ ngôi thứ 2, là bạn, mày và từ mǎ/马 là từ \"ma\" hay \"ma ma\" có nghĩa là mẹ hay vú nuôi), và là một trong danh sách 10 sinh vật thần thoại được tạo...  \n",
       "77453  Gettext\\n\\nTrong điện toán, gettext là một hệ thống quốc tế hóa và bản địa hóa (i18n) thường dùng cho việc viết các ứng dụng đa ngôn ngữ trên các hệ điều hành tương tự Unix. Việc triển khai gettext thường được sử dụng phổ biến nhất là GNU gettext, phát hành bởi GNU Project năm 1995.\\n\\ngettext ban đầu được viết bởi Sun Microsystems vào đầu những năm 1990. GNU Project phát hành GNU gettext, một phần mềm tự do triển khai hệ thống vào năm 1995.\\n\\nMã nguồn được sửa đổi đầu tiên để sử dụng các lệnh gọi GNU gettext. Với phần lớn ngôn ngữ lập trình, việc này được thực hiện bằng cách bao các chuỗ...  \n",
       "77454  Rosanna Pansino\\n\\nRosanna Pansino (sinh ngày 8 tháng 6 năm 1985) là một thợ làm bánh, nữ diễn viên, tác giả và nhân vật YouTube người Mỹ. Cô được biết đến nhiều nhất qua series nấu ăn \"Nerdy Nummies\", một trong những chương trình làm bánh nổi tiếng nhất trên YouTube. Cô cũng thủ vai Violet trong series hoạt hình trên YouTube \"Broken Quest\" và vai The Jet Setter trong series \"Escape the Night\" trên YouTube. Cô có tổ tiên là người Ý, Croatia, Đức và Ireland.\\n\\nPansino ban đầu muốn theo đuổi sự nghiệp làm diễn viên. Cô từng đóng những vai diễn nhỏ trong các tập của \"Parks and Recreation\" và...  \n",
       "77455  Hyperbol\\n\\nTrong toán học, hyperbol hay hypecbol (từ tiếng Hy Lạp: ὑπερβολή, nghĩa đen là \"vượt quá\" hay \"thái quá\") là một kiểu Đường cô-nic, được định nghĩa là đường giao của một mặt nón với một mặt phẳng cắt cả hai nửa của hình nón.\\n\\nĐường hyperbol còn được định nghĩa là quỹ tích của những điểm trong mặt phẳng có giá trị tuyết đối của hiệu khoảng cách tới hai điểm cố định là một hằng số bằng 2\"a\". \"a\" đồng thời cũng bằng độ dài bán trục lớn của Hyberbol. Hai điểm cố định đó gọi là hai tiêu điểm của hyperbol. Đường thẳng đi qua hai tiêu điểm này được gọi là trục thực của hyberbol và t...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# result_df.to_csv(path/'alltext.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df = pd.read_csv(path/'alltext.csv',encoding='utf-8')\n",
    "result_df = pd.read_csv(path/'alltext.csv',encoding='utf-8',nrows=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnmese_lm = DataBlock(blocks=TextBlock.from_df('text', is_lm=True),\n",
    "                    get_x=ColReader('text'),\n",
    "                    splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs=64\n",
    "# bs=24\n",
    "bs=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = vnmese_lm.dataloaders(result_df, bs=bs, seq_len=72)\n",
    "# dls.show_batch(max_n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## TextBlock datablock summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai2.data.block.DataBlock"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vnmese_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting-up type transforms pipelines\n",
      "Collecting items from                                   fname  \\\n",
      "0     Hội chứng Alice ở xứ sở thần tiên   \n",
      "1                       Nicolas Sarkozy   \n",
      "2                     Công nghệ pháp lý   \n",
      "3                          TT (bài hát)   \n",
      "4                      Adolf von Glümer   \n",
      "...                                 ...   \n",
      "1995                         Mario Puzo   \n",
      "1996                          Vua Nepal   \n",
      "1997                 Thời kỳ quân phiệt   \n",
      "1998              Hồng Tiến, Kiến Xương   \n",
      "1999                      Kỹ thuật RFLP   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         text  \n",
      "0     Hội chứng Alice ở xứ sở thần tiên\\n\\nHội chứng Alice ở xứ sở thần tiên là một bệnh lý thần kinh bị mất phương hướng ảnh hưởng đến nhận thức của con người. Con người sẽ phải trải qua ảo giác về những biến dạng kích thước như micropsia, macropsia, pelopsia, hoặc teleopsia. Sự biến dạng kích thước này có thể xảy ra ở các phương thức cảm giác khác nhau.\\nNó thường liên quan đến chứng đau nửa đầu khi sử dụng các loại thuốc thần kinh. Nó cũng có thể là triệu chứng ban đầu của virus Epstein-Barr (xem mononucleosis).\\n\\nDấu hiệu của Hội chứng Alice ở xứ sở thần tiên (AIWS) là chứng đau nửa đầu, và...  \n",
      "1     Nicolas Sarkozy\\n\\nNicolas Sarkozy (IPA: nikɔˈla saʁkɔˈzi - ), sinh ngày 28 tháng 1 năm 1955 với tên Nicolas Paul Stéphane Sarközy de Nagy-Bocsa, là cựu tổng thống Pháp. Sarkozy kế nhiệm Jacques Chirac vào ngày 16 tháng 5 năm 2007. Ông thường được những người ủng hộ lẫn chống đối đặt cho biệt hiệu là Sarko.\\n\\nNgày 6 tháng 5 năm 2007, Sarkozy đắc cử tổng thống sau khi đánh bại đối thủ thuộc Đảng Xã hội, Ségolène Royal, trong cuộc tổng tuyển cử năm 2007. Sarkozy giành được 53,4% trong khi đối thủ của ông chỉ nhận được 46,6% phiếu bầu. Số cử tri đi bầu đạt 85,5%, mức cao nhất kể từ năm 1981 ...  \n",
      "2     Công nghệ pháp lý\\n\\nCông nghệ pháp lý, còn được gọi là Legal Tech , đề cập đến việc sử dụng công nghệ và phần mềm nhằm cung cấp dịch vụ pháp lý. Các công ty Legal Tech nói chung là các công ty khởi nghiệp được thành lập với mục đích phá vỡ thị trường pháp lý bảo thủ theo truyền thống.\\n\\nTheo truyền thống, công nghệ pháp lý đề cập đến việc ứng dụng công nghệ và phần mềm để giúp các công ty luật quản lý nghiệp vụ, lưu trữ tài liệu, thanh toán, kế toán và khám phá điện tử. Từ năm 2011, Legal Tech đã phát triển để liên kết nhiều hơn với các công ty khởi nghiệp công nghệ phá vỡ việc thực hành...  \n",
      "3     TT (bài hát)\\n\\nTT là một bài hát được thu âm bởi nhóm nhạc nữ Hàn Quốc Twice, là ca khúc chủ đề của EP thứ ba . Bài hát được phát hành vào ngày 24 tháng 10 năm 2016 bởi JYP Entertainment và được phân phối bởi KT Music. Bài hát được viết lời và sáng tác bởi Sam Lewis và Black Eyed Pilseung. Tiêu đề \"TT\" đề cập đến biểu tượng cảm xúc được sử dụng để thể hiện khóc hoặc buồn.\\n\\nPhiên bản tiếng Nhật của \"TT\" đã được phát hành dưới dạng đĩa đơn đầu tiên cho album tổng hợp tiếng Nhật đầu tiên của nhóm, #Twice. MV tiếng nhật kèm theo đã được phát hành vào ngày 21 tháng 6 năm 2017.\\n\\nVào ngày 10...  \n",
      "4     Adolf von Glümer\\n\\nHeinrich Karl Ludwig Adolf von Glümer (5 tháng 6 năm 1814 tại Lengefeld – 3 tháng 1 năm 1896 tại Freiburg im Breisgau) là một sĩ quan quân đội Phổ, được thăng đến cấp Thượng tướng Bộ binh. Ông đã tham gia chỉ huy các lực lượng Phổ - Đức trong cuộc Chiến tranh Áo-Phổ (1866) và Chiến tranh Pháp-Đức (1870 – 1871).\\n\\nGlümer đã nhập ngũ trong Trung đoàn Bộ binh số 26 vào năm 1831 và học tại Học viện Quân sự Phổ. Từ năm 1842 cho đến năm 1843, ông tham gia trong Lữ đoàn Pháo binh Cận vệ, và sau đó là cục trưởng cục đo đạc địa hình của Bộ Tổng tham mưu. Tiếp theo đó, từ năm 18...  \n",
      "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...  \n",
      "1995  Mario Puzo\\n\\nMario Gianluigi Puzo (15 tháng 10 năm 1920 – 2 tháng 7 năm 1999) là một nhà văn, nhà biên kịch người Mỹ, được biết đến với những tiểu thuyết về Mafia, đặc biệt là \"Bố già\" (1969), mà sau này ông đồng chuyển thể thành một bộ phim cùng với Francis Ford Coppola. Ông đã giành được Giải Oscar cho kịch bản chuyển thể xuất sắc nhất vào giữa những năm 1972 và 1974. Dù là một nhà văn được cưng chiều của Hollywood nhưng ông vẫn luôn cảm thấy thất vọng về kinh đô điện ảnh của Mỹ.\\n\\nPuzo sinh ra trong một gia đình nghèo của người xứ Napoli nhập cư sống ở khu phố Hell's Kitchen của thành...  \n",
      "1996  Vua Nepal\\n\\nVua Nepal, theo truyền thống được gọi là Mahārājādhirāja (), là nguyên thủ quốc gia và là vua của Nepal từ năm 1768 đến 2008. Ông từng là người đứng đầu nền quân chủ cũ của Nepal—Triều đại Shah. Chế độ quân chủ được thành lập năm 1768 và bị Quốc hội Lập hiến Nepal bãi bỏ vào ngày 28 tháng 5 năm 2008. Các tiểu vương địa phương ở Mustang, Bajhang, Salyan và Jajarkot cũng được bãi bỏ vào tháng 10 cùng năm.\\n\\nVương quốc Nepal do Prithvi Narayan Shah thành lập vào ngày 25 tháng 9 năm 1768, xuất thân là một vị vua Gorkha đã thành công trong cuộc chiến thống nhất các vương quốc Kath...  \n",
      "1997  Thời kỳ quân phiệt\\n\\nThời kỳ quân phiệt (, Quân phiệt thời đại) là giai đoạn trong lịch sử Trung Hoa Dân Quốc từ năm 1916 đến 1928 khi mà quân phiệt Trung Quốc chia nhau cai trị tại các khu vực Tứ Xuyên, Sơn Tây, Thanh Hải, Ninh Hạ, Quảng Đông, Quảng Tây, Vân Nam, Cam Túc và Tân Cương.\\n\\nThời kỳ quân phiệt kéo dài từ khi Viên Thế Khải chết năm 1916 cho đến năm 1928, khi cuộc Bắc phạt kết thúc với sự tái thống nhất Trung Quốc và bắt đầu \"thập niên Nam Kinh\"; tuy nhiên khi các quân phiệt cũ như Ngô Bội Phu và Tôn Truyền Phương bị hạ bệ thì lại nổi lên một số quân phiệt nhỏ trong thập niên ...  \n",
      "1998  Hồng Tiến, Kiến Xương\\n\\nHồng Tiến là xã thuộc huyện Kiến Xương, tỉnh Thái Bình, Việt Nam.\\n\\nXã nằm trên một vùng đất bồi của hạ lưu tả ngạn sông Hồng, được thành lập năm 1963 trên cơ sở tách ra khỏi xã Bình Thanh gồm một phần thôn Khả Cảnh và các làng Khả Lễ, làng Khả Cửu.\\n\\nXã Hồng Tiến nay được phân thành 6 thôn gồm: Khả Cảnh, Tân Thành, Đông Tiến, Nam Hòa, Nam Tiến và Cao Bình.\\n\\nVùng đất này xưa kia do cụ Đào Khắc Tuân dẫn 10 nhân đinh của 5 họ (Đào, Đỗ, Vũ, Bùi, Nguyễn - thường gọi là Ngũ tộc) từ làng Khả Phú ra quai đê lập làng Cơ Chỉ vào năm Canh Dần 1820.\\n\\nThôn Đông Tiến trướ...  \n",
      "1999  Kỹ thuật RFLP\\n\\nTrong sinh học phân tử, đa hình chiều dài đoạn cắt giới hạn, hay là RFLP (thường đọc là \"rif-lip\"), là kỹ thuật khai thác những khác biệt trong trình tự DNA. Trong phân tích RFLP, DNA mẫu được cắt thành các đoạn nhỏ bằng cách sử dụng các enzyme cắt giới hạn, và sau đó các đoạn DNA nhỏ tạo thành được phân tách dựa theo kích thước bằng kỹ thuật điện di trên gel. Mặc dù ngày nay kỹ thuật này đã trở nên lỗi thời do bị thay thế bởi công nghệ giải trình tự, RFLP là công nghệ nghiên cứu đa hình DNA đầu tiên đủ rẻ để có thể được ứng dụng một cách rộng rãi. RFLP là công cụ quan trọ...  \n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "Found 2000 items\n",
      "2 datasets of sizes 1600,400\n",
      "Setting up Pipeline: ColReader -> Tokenizer -> Numericalize\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building one sample\n",
      "  Pipeline: ColReader -> Tokenizer -> Numericalize\n",
      "    starting from\n",
      "      fname                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Lâm Tế Nghĩa Huyền\n",
      "text           [xxbos, xxmaj, lâm, xxup, tế, xxmaj, nghĩa, xxmaj, huyền, \\n\\n, xxmaj, lâm, xxup, tế, xxmaj, nghĩa, xxmaj, huyền, (, zh, ., \", línjì, yìxuán, \", /, \", lin, -, chi, i, -, hsüan, \", 臨濟義玄, ,, ja, ., \", rinzai, gigen, \", ), ,, ?, -866, /, 867, ,, là, một, vị, xxmaj, thiền, sư, xxmaj, trung, xxmaj, quốc, ,, là, xxup, tổ, khai, dòng, thiền, xxmaj, lâm, xxup, tế, ., xxup, sư, là, môn, đệ, xuất, sắc, nhất, của, xxmaj, thiền, sư, xxmaj, hoàng, xxup, bá, xxmaj, hi, xxmaj, vận, ., xxmaj, môn, đệ, đắc, pháp, danh, tiếng, của, ...]\n",
      "text_length                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1083\n",
      "Name: 842, dtype: object\n",
      "    applying ColReader gives\n",
      "      (#1083) ['xxbos','xxmaj','lâm','xxup','tế','xxmaj','nghĩa','xxmaj','huyền','\\n\\n'...]\n",
      "    applying Tokenizer gives\n",
      "      (#1083) ['xxbos','xxmaj','lâm','xxup','tế','xxmaj','nghĩa','xxmaj','huyền','\\n\\n'...]\n",
      "    applying Numericalize gives\n",
      "      TensorText of size 1083\n",
      "\n",
      "Final sample: (TensorText([  2,   8, 685,  ...,   8, 917,  10]),)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up after_item: Pipeline: ToTensor\n",
      "Setting up before_batch: Pipeline: \n",
      "Setting up after_batch: Pipeline: \n",
      "\n",
      "Building one batch\n",
      "Applying item_tfms to the first sample:\n",
      "  Pipeline: ToTensor\n",
      "    starting from\n",
      "      (TensorText of size 1083)\n",
      "    applying ToTensor gives\n",
      "      (TensorText of size 1083)\n",
      "\n",
      "Adding the next 1 samples\n",
      "\n",
      "No before_batch transform to apply\n",
      "\n",
      "Collating items in a batch\n",
      "Error! It's not possible to collate your items in a batch\n",
      "Could not collate the 0-th members of your tuples because got the following shapes\n",
      "torch.Size([1083]),torch.Size([1403])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1083] at entry 0 and [1403] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-ef893dd1ebd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvnmese_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/kwon/nlp/fastai2_nlp/fastai2/data/block.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, source, bs, show_batch, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mwhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_fail_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Make sure all parts of your samples are tensors of the same size\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwhy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mwhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'noop'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kwon/nlp/fastai2_nlp/fastai2/data/block.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, source, bs, show_batch, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nCollating items in a batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretain_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kwon/nlp/fastai2_nlp/fastai2/data/load.py\u001b[0m in \u001b[0;36mcreate_batch\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mretain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0mretain_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfa_collate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfa_convert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprebatched\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kwon/nlp/fastai2_nlp/fastai2/data/load.py\u001b[0m in \u001b[0;36mfa_collate\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     return (default_collate(t) if isinstance(b, _collate_types)\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32melse\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfa_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             else default_collate(t))\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kwon/nlp/fastai2_nlp/fastai2/data/load.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     return (default_collate(t) if isinstance(b, _collate_types)\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32melse\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfa_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             else default_collate(t))\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kwon/nlp/fastai2_nlp/fastai2/data/load.py\u001b[0m in \u001b[0;36mfa_collate\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfa_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     return (default_collate(t) if isinstance(b, _collate_types)\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfa_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             else default_collate(t))\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1083] at entry 0 and [1403] at entry 1"
     ]
    }
   ],
   "source": [
    "# vnmese_lm.summary(result_df, bs=2)\n",
    "# TODO: in LM, for some reason the sequences in a batch aren’t padded to be of equal length \n",
    "# while making a LM. I know they are made equal when building the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Study LM dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai2.data.core.DataLoaders"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16880"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xxunk', 'xxpad', 'xxbos', 'xxeos', 'xxfld', 'xxrep', 'xxwrep', 'xxup', 'xxmaj', ',', '.', 'và', 'của', '\"', 'là', 'được', 'các', 'một', '\\n\\n', 'trong', 'có', 'năm', 'đã', ')', '(', 'với', 'cho', 'người', 'vào', 'ở', 'không', 'thành', 'từ', 'những', 'khi', 'công', 'tháng', 'đến', '-', 'này', 'ngày', 'tại', 'sau', 'quân', 'đó', 'quốc', 'để', 'ông', 'đầu', 'sự', 'ra', 'thể', 'chính', 'bị', 'về', 'như', 'số', 'nam', 'trên', 'trung', 'lại', 'gia', 'cũng', 'nhà', 'chiến', 'làm', 'đại', 'học', 'động', 'bộ', 'dân', 'theo', 'nhiều', 'nhất', ':', 'việt', 'nước', 'hiện', 'hai', '3', 'phát', 'việc', 'thời', 'thế', 'nhân', 'hành', 'chỉ', 'anh', 'do', 'pháp', 'khác', 'cùng', 'định', 'đồng', 'nó', 'quan', 'bản', 'con', 'hội', 'cuộc']\n"
     ]
    }
   ],
   "source": [
    "print(dls.vocab[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malas', 'donepezil', 'cholinesterase', 'żurakowski', '好', 'き', 'で', 'す', 'takumi', '-photphoryl', 'trochiliformes', 'cypselomorphae', 'blust', 'gujarat', '1.450', 'mxml', 'fayette', 'rocn', 'meeker', 'spitz', 'tatopoulos', 'cnestidium', 'plantes', 'haüy', 'buffon', 'mlền', 'gambiez', 'linarès', 'đă', 'hadhramaut', 'cdc', 'lidia', 'sundar', '嘉順宮', 'l3', 'autosomal', 'engebi', 'veldarad', 'veldt', 'bounnhang', 'vorachith', 'có:<br', 'vnukovo', 'nordaustlandet', 'hopen', 'grumant', 'schengen', 'beloved', 'invisibles', 'baste', 'powter', 'furtado', 'timberlake', 'flexjet', 'eternalblue', 'aiesecer', 'gv', 'youthspeak', 'shindong', 'goong', 'moeyan', 'peleus', 'priam', 'inu', 'monoxide', 'hbco', 'u-110', 'lettera', 'pbdos', 'pence', 'scara', 'toys', 'sketrobo', 'ngõa', 'eustatius', 'saba', 'tncmđch', 'vázquez', 'ayllón', 'spartina', 'nps', 'programmer', 'squeaker', 'ély', 'nolting', 'maneli', 'karnow', 'rattigan', 'iwamoto', 'komi', 'tocantins', 'beginnings', 'starmen.net', 'xxfake', 'xxfake', 'xxfake', 'xxfake', 'xxfake', 'xxfake', 'xxfake']\n"
     ]
    }
   ],
   "source": [
    "print(dls.vocab[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<fastai2.text.data.LMDataLoader at 0x7f36d0ac8190>,\n",
       " <fastai2.text.data.LMDataLoader at 0x7f363a0d0b90>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.train,dls.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y = dls.train.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 72])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape # (bs,bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LMTensorText([[   2,    8, 1018,  ..., 1365,    9,   16],\n",
       "        [ 482,   15,  195,  ...,  295,   31,    9],\n",
       "        [  78,   45,   61,  ...,   35,   93,    8],\n",
       "        ...,\n",
       "        [  58,  627,  599,  ...,  369,   11, 3755],\n",
       "        [   8, 5229,    8,  ..., 1103,    8,   59],\n",
       "        [ 132,   20,  251,  ...,  633,  937,  262]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x # LMTensorText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(fastai2.text.data.LMTensorText, 'torch.cuda.LongTensor')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x),x.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   8, 1018,   48,  ...,    9,   16,    7],\n",
       "        [  15,  195,   14,  ...,   31,    9,    8],\n",
       "        [  45,   61,   91,  ...,   93,    8, 8130],\n",
       "        ...,\n",
       "        [ 627,  599, 1001,  ...,   11, 3755,  544],\n",
       "        [5229,    8,  290,  ...,    8,   59,    8],\n",
       "        [  20,  251,  554,  ...,  937,  262,   37]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y # move each row of x to the right by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai2.text.data.LMDataLoader"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dls.train) #inherit TfmdDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj phong trào xxmaj cần xxmaj vương \\n\\n xxmaj phong trào xxmaj cần xxmaj vương ( chữ xxmaj nôm : xxunk ) nổ ra vào cuối thế kỷ 19 do đại thần nhà xxmaj nguyễn là xxmaj tôn xxmaj thất xxmaj thuyết nhân danh vị hoàng đế trẻ tuổi vua xxmaj hàm xxmaj nghi đề xướng trước nạn xâm lược của thực dân xxmaj pháp . \\n\\n xxmaj tại triều đình</td>\n",
       "      <td>xxmaj phong trào xxmaj cần xxmaj vương \\n\\n xxmaj phong trào xxmaj cần xxmaj vương ( chữ xxmaj nôm : xxunk ) nổ ra vào cuối thế kỷ 19 do đại thần nhà xxmaj nguyễn là xxmaj tôn xxmaj thất xxmaj thuyết nhân danh vị hoàng đế trẻ tuổi vua xxmaj hàm xxmaj nghi đề xướng trước nạn xâm lược của thực dân xxmaj pháp . \\n\\n xxmaj tại triều đình xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tế ban đầu đặt tiêu chuẩn cho tên miền chấp nhận . xxmaj quốc tế hóa tên miền là một giải pháp kỹ thuật để dịch các tên được viết bằng các tập lệnh gốc ngôn ngữ thành biểu diễn văn bản xxup ascii tương thích với xxup hệ thống tên miền . xxmaj tên miền quốc tế hóa chỉ có thể được sử dụng với các ứng dụng được thiết kế</td>\n",
       "      <td>ban đầu đặt tiêu chuẩn cho tên miền chấp nhận . xxmaj quốc tế hóa tên miền là một giải pháp kỹ thuật để dịch các tên được viết bằng các tập lệnh gốc ngôn ngữ thành biểu diễn văn bản xxup ascii tương thích với xxup hệ thống tên miền . xxmaj tên miền quốc tế hóa chỉ có thể được sử dụng với các ứng dụng được thiết kế riêng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vắn \" , \" kim xxmaj tiền \" , \" long xxup hổ xxmaj hội \" . ông nội ông là xxmaj trần xxmaj quang xxmaj diệm ( năm xxmaj diệm ) , cha ông là xxmaj trần xxmaj quang xxmaj chiêu ( bảy xxmaj triều ) , cô là xxmaj trần xxmaj ngọc xxmaj viện ( tức xxmaj ba xxmaj viện , người đã sáng lập gánh cải lương đồng xxup</td>\n",
       "      <td>\" , \" kim xxmaj tiền \" , \" long xxup hổ xxmaj hội \" . ông nội ông là xxmaj trần xxmaj quang xxmaj diệm ( năm xxmaj diệm ) , cha ông là xxmaj trần xxmaj quang xxmaj chiêu ( bảy xxmaj triều ) , cô là xxmaj trần xxmaj ngọc xxmaj viện ( tức xxmaj ba xxmaj viện , người đã sáng lập gánh cải lương đồng xxup nữ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxmaj thứ sử . \\n\\n đời đường xxmaj cao tông , ông được đổi thành xxup tả vệ đại tướng quân . xxmaj khoảng năm 655 - 657 , ông lĩnh chức xxmaj hành quân tổng quản , dẫn binh xuất chinh xxmaj tây đột xxmaj quyết . xxmaj tuy nhiên , trong quá trình hành quân , quân đường tàn sát thường dân , người đột xxmaj quyết phẫn nộ ,</td>\n",
       "      <td>thứ sử . \\n\\n đời đường xxmaj cao tông , ông được đổi thành xxup tả vệ đại tướng quân . xxmaj khoảng năm 655 - 657 , ông lĩnh chức xxmaj hành quân tổng quản , dẫn binh xuất chinh xxmaj tây đột xxmaj quyết . xxmaj tuy nhiên , trong quá trình hành quân , quân đường tàn sát thường dân , người đột xxmaj quyết phẫn nộ , quyết</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.train.show_batch(max_n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## All type of tfms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Datablock tfms \n",
    "\n",
    "block tfms to be added at the end of  X dataset pipeline  +  after_item pipeline +  after_batch pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vnmese_lm.type_tfms) # only 1 type tfms for X \n",
    "# since 'blocks' param provide only 1: blocks=TextBlock.from_df('text', is_lm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer: (str,object) -> encodes\n",
       "(Path,object) -> encodes (object,object) -> decodes"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnmese_lm.type_tfms[0][0] # Tokenizer transform. Will be in X pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Numericalize: (object,object) -> encodes (object,object) -> decodes"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnmese_lm.type_tfms[0][1] # Numericalize transform. Will be in X pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [ToTensor: (PILMask,object) -> encodes\n",
       "(PILBase,object) -> encodes ]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnmese_lm.default_item_tfms #default item tfm (for dataloaders' after_item pipeline) for PILBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#0) []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnmese_lm.default_batch_tfms #default batch item tfm (for dataloaders' after_batch pipeline\n",
    "# normall it will be IntToFloatTensor, but token should be int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#1) [ToTensor: (PILMask,object) -> encodes\n",
       " (PILBase,object) -> encodes ],\n",
       " (#0) [])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnmese_lm.item_tfms,vnmese_lm.batch_tfms \n",
    "# nothing different from default_item_tfms and default_batch_tfms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Dataset tfms (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 1600)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.valid.dataset),len(dls.train.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dsets = dls.train.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dsets[0]),len(dsets[0]) # tuple of 1 since there's no label y yet (LM model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([723])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_ds = dls.train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_ds = dls.valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, fastai2.data.core.TfmdLists)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds.tls),type(train_ds.tls[0]) # 1 tfmdlist for train, again because no label y yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: ColReader -> Tokenizer -> Numericalize"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0].tfms # or train_ds.tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: ColReader -> Tokenizer -> Numericalize"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds.tls[0].tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0x7f3623e8f750', '0x7f3623e8fd50')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(id(train_ds.tls[0].tfms)),hex(id(val_ds.tls[0].tfms)) # 2 different pipelines though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>Emile Berliner</td>\n",
       "      <td>[xxbos, xxmaj, emile, xxmaj, berliner, \\n\\n, xxmaj, emile, xxmaj, berliner, hay, xxmaj, emil, xxmaj, berliner, (, ngày, 20, tháng, 5, năm, 1851, –, ngày, 3, tháng, 8, năm, 1929, ), là, một, nhà, phát, minh, người, đức, gốc, xxmaj, do, xxmaj, thái, ., ông, được, biết, đến, với, vai, trò, là, người, phát, triển, máy, quay, đĩa, ., ông, đã, sáng, lập, xxmaj, the, xxmaj, berliner, xxmaj, gramophone, xxmaj, company, (, công, ty, xxmaj, máy, quay, đĩa, xxmaj, berliner, ), năm, 1895, ,, xxmaj, the, xxmaj, gramophone, xxmaj, company, (, công, ty, xxmaj, máy, quay, đĩa, ), tại, xxmaj, luân, ...]</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>Sông Meghna</td>\n",
       "      <td>[xxbos, xxmaj, sông, xxmaj, meghna, \\n\\n, xxmaj, sông, xxmaj, meghna, (, ), là, một, trong, những, con, sông, quan, trọng, nhất, ở, xxmaj, bangladesh, ,, một, trong, ba, con, sông, hình, thành, đồng, bằng, sông, xxmaj, hằng, ,, vùng, đồng, bằng, lớn, nhất, trên, trái, đất, ,, chảy, ra, xxmaj, vịnh, xxmaj, bengal, ., xxmaj, một, phần, của, hệ, thống, sông, surma, -, meghna, ,, xxmaj, meghna, được, hình, thành, bên, trong, xxmaj, bangladesh, thuộc, huyện, xxmaj, kishoreganj, phía, trên, thị, trấn, xxmaj, bhairab, xxmaj, bazar, ,, được, nhập, lại, từ, hai, con, sông, xxmaj, surma, và, xxmaj, ...</td>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>Máy phát điện rung động</td>\n",
       "      <td>[xxbos, xxmaj, máy, phát, điện, rung, động, \\n\\n, xxmaj, máy, phát, điện, rung, động, ,, hay, xxmaj, máy, phát, điện, rung, ,, là, loại, máy, phát, điện, chuyển, đổi, động, năng, từ, rung, động, thành, năng, lượng, điện, ., xxmaj, rung, có, thể, là, từ, sóng, áp, suất, của, âm, thanh, hoặc, môi, trường, xung, quanh, khác, ., \\n\\n, xxmaj, máy, phát, điện, rung, động, thường, bao, gồm, một, bộ, cộng, hưởng, được, sử, dụng, để, khuếch, đại, nguồn, rung, và, cơ, chế, bộ, chuyển, đổi, năng, lượng, từ, các, rung, động, thành, năng, lượng, điện, ., xxup, bộ, chuyển, ...]</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>Burundi</td>\n",
       "      <td>[xxbos, xxmaj, burundi, \\n\\n, xxmaj, burundi, (, or, ), ,, tên, chính, thức, xxmaj, cộng, hòa, xxmaj, burundi, (, ,, ;, ,, hoặc, ), là, một, quốc, gia, ở, đông, châu, xxmaj, phi, ., \\n\\n, xxmaj, vào, thế, kỷ, xxup, xv, ,, những, người, du, mục, xxmaj, tutsi, (, còn, gọi, là, người, xxmaj, watutsi, ), ,, được, xem, là, một, dân, tộc, từ, xxmaj, ethiopia, đến, ,, bắt, đầu, cuộc, chinh, phục, người, xxmaj, hutu, ., xxup, họ, thành, lập, vương, quốc, xxmaj, mwami, và, thống, trị, theo, thể, chế, quân, chủ, chuyên, chế, ., xxmaj, những, người, châu, ...]</td>\n",
       "      <td>2210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mùa bão Nam Thái Bình Dương 2017-18</td>\n",
       "      <td>[xxbos, xxmaj, mùa, bão, xxmaj, nam, xxmaj, thái, xxmaj, bình, xxmaj, dương, 2017, -, 18, \\n\\n, xxmaj, mùa, bão, ở, xxmaj, nam, xxmaj, thái, xxmaj, bình, xxmaj, dương, năm, 2017, -, 18, là, thời, kỳ, năm, có, nhiều, cơn, lốc, xoáy, nhiệt, đới, hình, thành, ở, xxmaj, nam, xxmaj, thái, xxmaj, bình, xxmaj, dương, ở, phía, đông, 160, °, e, ., xxmaj, mùa, bắt, đầu, chính, thức, vào, ngày, 1, tháng, 11, năm, 2017, và, kết, thúc, vào, ngày, 30, tháng, 4, năm, 2018, ;, tuy, nhiên, ,, một, cơn, bão, nhiệt, đới, có, thể, hình, thành, vào, bất, kỳ, ...]</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>Tầng trình diễn</td>\n",
       "      <td>[xxbos, xxmaj, tầng, trình, diễn, \\n\\n, xxmaj, tầng, trình, diễn, là, tầng, thứ, sáu, trong, bảy, tầng, cấp, của, mô, hình, xxup, osi, ., xxmaj, tầng, này, đáp, ứng, những, nhu, cầu, dịch, vụ, mà, tầng, ứng, dụng, đòi, hỏi, ,, đồng, thời, phát, hành, những, yêu, cầu, dịch, vụ, đối, với, tầng, phiên, ., \\n\\n, xxmaj, tầng, trình, diễn, chịu, trách, nhiệm, phân, phát, và, định, dạng, dữ, liệu, cho, tầng, ứng, dụng, ,, để, dữ, liệu, được, tiếp, tục, xử, lý, hoặc, hiển, thị, ., xxmaj, tầng, này, giải, phóng, tầng, ứng, dụng, khỏi, gánh, nặng, của, việc, ...]</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>Mehmed V</td>\n",
       "      <td>[xxbos, xxmaj, mehmed, v, \\n\\n, xxmaj, mehmed, v, (, thường, gọi, là, \", reşat, xxmaj, mehmet, \", ;, 2, tháng, 11, năm, 1844, –, 3, tháng, 7, năm, 1918, ), là, vị, sultan, thứ, 35, của, đế, quốc, xxmaj, ottoman, ,, ở, ngôi, từ, ngày, 27, tháng, 4, năm, 1909, đến, khi, qua, đời, ., xxmaj, dưới, thời, ông, ,, quân, xxmaj, ottoman, tham, gia, các, cuộc, chiến, tranh, vùng, xxmaj, balkan, và, xxmaj, chiến, tranh, thế, giới, thứ, nhất, ., \\n\\n, xxmaj, mehmed, v, chào, đời, ngày, 2, tháng, 11, năm, 1844, ở, thủ, đô, xxmaj, constantinopolis, ,, là, ...]</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>Bão Joan (1997)</td>\n",
       "      <td>[xxbos, xxmaj, bão, xxmaj, joan, (, 1997, ), \\n\\n, xxmaj, bão, xxmaj, joan, năm, 1997, là, cơn, bão, giữ, được, cường, độ, siêu, bão, trong, thời, gian, dài, nhất, tại, thời, điểm, đó, ,, vận, tốc, gió, tối, đa, duy, trì, một, phút, luôn, giữ, ở, mức, ít, nhất, 150, dặm, /, giờ, (, 240,  , km, /, giờ, ), trong, 4, ngày, rưỡi, liên, tục, ., xxmaj, joan, ,, cùng, với, xxmaj, ivan, ở, phía, xxmaj, tây, ,, cả, hai, đều, trở, thành, những, cơn, bão, mạnh, nhất, trong, cùng, thời, điểm, trên, xxmaj, tây, xxmaj, bắc, xxmaj, thái, ...]</td>\n",
       "      <td>2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>Cúp bóng đá châu Á 2019</td>\n",
       "      <td>[xxbos, xxmaj, cúp, bóng, đá, châu, á, 2019, \\n\\n, xxmaj, cúp, bóng, đá, châu, á, 2019, (, ), là, xxmaj, cúp, bóng, đá, châu, á, lần, thứ, 17, ,, với, chu, kỳ, 4, năm, 1, lần, ,, do, xxmaj, liên, đoàn, bóng, đá, châu, á, (, afc, ), tổ, chức, ., xxmaj, giải, đấu, được, tổ, chức, tại, xxmaj, các, xxmaj, tiểu, vương, quốc, ả, xxmaj, rập, xxmaj, thống, nhất, (, uae, ), từ, ​​ngày, 5, tháng, 1, đến, ngày, 1, tháng, 2, năm, 2019, ., để, giành, được, quyền, đăng, cai, giải, đấu, này, ,, xxup, uae, đã, vượt, ...]</td>\n",
       "      <td>3323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>1-800-273-8255 (bài hát)</td>\n",
       "      <td>[xxbos, 1, -, 800, -, 273, -, 8255, (, bài, hát, ), \\n\\n, \", 1, -, 800, -, 273, -, 8255, \", là, một, bài, hát, của, rapper, người, xxup, mỹ, xxmaj, logic, ., xxmaj, bài, hát, được, phát, hành, ngày, 28, tháng, 4, năm, 2017, thông, qua, hãng, đĩa, xxmaj, visionary, xxmaj, music, xxmaj, group, và, xxmaj, def, xxmaj, jam, xxmaj, recordings, ,, là, đĩa, đơn, thứ, ba, từ, album, phòng, thu, thứ, ba, của, anh, \", everybody, \", ., xxmaj, tên, bài, hát, cũng, là, số, điện, thoại, của, đường, dây, xxmaj, ngăn, chặn, xxup, tự, tử, xxmaj, ...]</td>\n",
       "      <td>1053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    fname  \\\n",
       "1004                       Emile Berliner   \n",
       "1015                          Sông Meghna   \n",
       "504               Máy phát điện rung động   \n",
       "850                               Burundi   \n",
       "12    Mùa bão Nam Thái Bình Dương 2017-18   \n",
       "...                                   ...   \n",
       "1729                      Tầng trình diễn   \n",
       "1557                             Mehmed V   \n",
       "1407                      Bão Joan (1997)   \n",
       "1000              Cúp bóng đá châu Á 2019   \n",
       "1351             1-800-273-8255 (bài hát)   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         text  \\\n",
       "1004        [xxbos, xxmaj, emile, xxmaj, berliner, \\n\\n, xxmaj, emile, xxmaj, berliner, hay, xxmaj, emil, xxmaj, berliner, (, ngày, 20, tháng, 5, năm, 1851, –, ngày, 3, tháng, 8, năm, 1929, ), là, một, nhà, phát, minh, người, đức, gốc, xxmaj, do, xxmaj, thái, ., ông, được, biết, đến, với, vai, trò, là, người, phát, triển, máy, quay, đĩa, ., ông, đã, sáng, lập, xxmaj, the, xxmaj, berliner, xxmaj, gramophone, xxmaj, company, (, công, ty, xxmaj, máy, quay, đĩa, xxmaj, berliner, ), năm, 1895, ,, xxmaj, the, xxmaj, gramophone, xxmaj, company, (, công, ty, xxmaj, máy, quay, đĩa, ), tại, xxmaj, luân, ...]   \n",
       "1015  [xxbos, xxmaj, sông, xxmaj, meghna, \\n\\n, xxmaj, sông, xxmaj, meghna, (, ), là, một, trong, những, con, sông, quan, trọng, nhất, ở, xxmaj, bangladesh, ,, một, trong, ba, con, sông, hình, thành, đồng, bằng, sông, xxmaj, hằng, ,, vùng, đồng, bằng, lớn, nhất, trên, trái, đất, ,, chảy, ra, xxmaj, vịnh, xxmaj, bengal, ., xxmaj, một, phần, của, hệ, thống, sông, surma, -, meghna, ,, xxmaj, meghna, được, hình, thành, bên, trong, xxmaj, bangladesh, thuộc, huyện, xxmaj, kishoreganj, phía, trên, thị, trấn, xxmaj, bhairab, xxmaj, bazar, ,, được, nhập, lại, từ, hai, con, sông, xxmaj, surma, và, xxmaj, ...   \n",
       "504                                [xxbos, xxmaj, máy, phát, điện, rung, động, \\n\\n, xxmaj, máy, phát, điện, rung, động, ,, hay, xxmaj, máy, phát, điện, rung, ,, là, loại, máy, phát, điện, chuyển, đổi, động, năng, từ, rung, động, thành, năng, lượng, điện, ., xxmaj, rung, có, thể, là, từ, sóng, áp, suất, của, âm, thanh, hoặc, môi, trường, xung, quanh, khác, ., \\n\\n, xxmaj, máy, phát, điện, rung, động, thường, bao, gồm, một, bộ, cộng, hưởng, được, sử, dụng, để, khuếch, đại, nguồn, rung, và, cơ, chế, bộ, chuyển, đổi, năng, lượng, từ, các, rung, động, thành, năng, lượng, điện, ., xxup, bộ, chuyển, ...]   \n",
       "850                                               [xxbos, xxmaj, burundi, \\n\\n, xxmaj, burundi, (, or, ), ,, tên, chính, thức, xxmaj, cộng, hòa, xxmaj, burundi, (, ,, ;, ,, hoặc, ), là, một, quốc, gia, ở, đông, châu, xxmaj, phi, ., \\n\\n, xxmaj, vào, thế, kỷ, xxup, xv, ,, những, người, du, mục, xxmaj, tutsi, (, còn, gọi, là, người, xxmaj, watutsi, ), ,, được, xem, là, một, dân, tộc, từ, xxmaj, ethiopia, đến, ,, bắt, đầu, cuộc, chinh, phục, người, xxmaj, hutu, ., xxup, họ, thành, lập, vương, quốc, xxmaj, mwami, và, thống, trị, theo, thể, chế, quân, chủ, chuyên, chế, ., xxmaj, những, người, châu, ...]   \n",
       "12                                                       [xxbos, xxmaj, mùa, bão, xxmaj, nam, xxmaj, thái, xxmaj, bình, xxmaj, dương, 2017, -, 18, \\n\\n, xxmaj, mùa, bão, ở, xxmaj, nam, xxmaj, thái, xxmaj, bình, xxmaj, dương, năm, 2017, -, 18, là, thời, kỳ, năm, có, nhiều, cơn, lốc, xoáy, nhiệt, đới, hình, thành, ở, xxmaj, nam, xxmaj, thái, xxmaj, bình, xxmaj, dương, ở, phía, đông, 160, °, e, ., xxmaj, mùa, bắt, đầu, chính, thức, vào, ngày, 1, tháng, 11, năm, 2017, và, kết, thúc, vào, ngày, 30, tháng, 4, năm, 2018, ;, tuy, nhiên, ,, một, cơn, bão, nhiệt, đới, có, thể, hình, thành, vào, bất, kỳ, ...]   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...   \n",
       "1729                                          [xxbos, xxmaj, tầng, trình, diễn, \\n\\n, xxmaj, tầng, trình, diễn, là, tầng, thứ, sáu, trong, bảy, tầng, cấp, của, mô, hình, xxup, osi, ., xxmaj, tầng, này, đáp, ứng, những, nhu, cầu, dịch, vụ, mà, tầng, ứng, dụng, đòi, hỏi, ,, đồng, thời, phát, hành, những, yêu, cầu, dịch, vụ, đối, với, tầng, phiên, ., \\n\\n, xxmaj, tầng, trình, diễn, chịu, trách, nhiệm, phân, phát, và, định, dạng, dữ, liệu, cho, tầng, ứng, dụng, ,, để, dữ, liệu, được, tiếp, tục, xử, lý, hoặc, hiển, thị, ., xxmaj, tầng, này, giải, phóng, tầng, ứng, dụng, khỏi, gánh, nặng, của, việc, ...]   \n",
       "1557                                                 [xxbos, xxmaj, mehmed, v, \\n\\n, xxmaj, mehmed, v, (, thường, gọi, là, \", reşat, xxmaj, mehmet, \", ;, 2, tháng, 11, năm, 1844, –, 3, tháng, 7, năm, 1918, ), là, vị, sultan, thứ, 35, của, đế, quốc, xxmaj, ottoman, ,, ở, ngôi, từ, ngày, 27, tháng, 4, năm, 1909, đến, khi, qua, đời, ., xxmaj, dưới, thời, ông, ,, quân, xxmaj, ottoman, tham, gia, các, cuộc, chiến, tranh, vùng, xxmaj, balkan, và, xxmaj, chiến, tranh, thế, giới, thứ, nhất, ., \\n\\n, xxmaj, mehmed, v, chào, đời, ngày, 2, tháng, 11, năm, 1844, ở, thủ, đô, xxmaj, constantinopolis, ,, là, ...]   \n",
       "1407                                                                    [xxbos, xxmaj, bão, xxmaj, joan, (, 1997, ), \\n\\n, xxmaj, bão, xxmaj, joan, năm, 1997, là, cơn, bão, giữ, được, cường, độ, siêu, bão, trong, thời, gian, dài, nhất, tại, thời, điểm, đó, ,, vận, tốc, gió, tối, đa, duy, trì, một, phút, luôn, giữ, ở, mức, ít, nhất, 150, dặm, /, giờ, (, 240,  , km, /, giờ, ), trong, 4, ngày, rưỡi, liên, tục, ., xxmaj, joan, ,, cùng, với, xxmaj, ivan, ở, phía, xxmaj, tây, ,, cả, hai, đều, trở, thành, những, cơn, bão, mạnh, nhất, trong, cùng, thời, điểm, trên, xxmaj, tây, xxmaj, bắc, xxmaj, thái, ...]   \n",
       "1000                                                                                           [xxbos, xxmaj, cúp, bóng, đá, châu, á, 2019, \\n\\n, xxmaj, cúp, bóng, đá, châu, á, 2019, (, ), là, xxmaj, cúp, bóng, đá, châu, á, lần, thứ, 17, ,, với, chu, kỳ, 4, năm, 1, lần, ,, do, xxmaj, liên, đoàn, bóng, đá, châu, á, (, afc, ), tổ, chức, ., xxmaj, giải, đấu, được, tổ, chức, tại, xxmaj, các, xxmaj, tiểu, vương, quốc, ả, xxmaj, rập, xxmaj, thống, nhất, (, uae, ), từ, ​​ngày, 5, tháng, 1, đến, ngày, 1, tháng, 2, năm, 2019, ., để, giành, được, quyền, đăng, cai, giải, đấu, này, ,, xxup, uae, đã, vượt, ...]   \n",
       "1351                                                               [xxbos, 1, -, 800, -, 273, -, 8255, (, bài, hát, ), \\n\\n, \", 1, -, 800, -, 273, -, 8255, \", là, một, bài, hát, của, rapper, người, xxup, mỹ, xxmaj, logic, ., xxmaj, bài, hát, được, phát, hành, ngày, 28, tháng, 4, năm, 2017, thông, qua, hãng, đĩa, xxmaj, visionary, xxmaj, music, xxmaj, group, và, xxmaj, def, xxmaj, jam, xxmaj, recordings, ,, là, đĩa, đơn, thứ, ba, từ, album, phòng, thu, thứ, ba, của, anh, \", everybody, \", ., xxmaj, tên, bài, hát, cũng, là, số, điện, thoại, của, đường, dây, xxmaj, ngăn, chặn, xxup, tự, tử, xxmaj, ...]   \n",
       "\n",
       "      text_length  \n",
       "1004          723  \n",
       "1015          797  \n",
       "504           545  \n",
       "850          2210  \n",
       "12            987  \n",
       "...           ...  \n",
       "1729          514  \n",
       "1557          834  \n",
       "1407         2100  \n",
       "1000         3323  \n",
       "1351         1053  \n",
       "\n",
       "[1600 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0].items \n",
    "# no transform applied yet, but note that texts have already been 'ColReader' and 'Tokenizer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorText([    2,     8,  7777,     8,  5749,    18,     8,  7777,     8,  5749,\n",
       "          243,     8,  6096,     8,  5749,    24,    40,   589,    36,   257,\n",
       "           21,  4861,   590,    40,    79,    36,   344,    21,  2492,    23,\n",
       "           14,    17,    63,    80,   167,    27,   198,   643,     8,    88,\n",
       "            8,   226,    10,    47,    15,   361,    37,    25,   509,   464,\n",
       "           14,    27,    80,   252,   165,   597,   837,    10,    47,    22,\n",
       "          415,   112,     8,   435,     8,  5749,     8, 15876,     8,  2834,\n",
       "           24,    35,   540,     8,   165,   597,   837,     8,  5749,    23,\n",
       "           21,  2921,     9,     8,   435,     8, 15876,     8,  2834,    24,\n",
       "           35,   540,     8,   165,   597,   837,    23,    41,     8,  1484,\n",
       "         1642,     9,     8,    87,    28,    21,  3766,     9,     8,  6876,\n",
       "            8,     0,    41,     8, 10631,     9,   198,    21,  3518,    11,\n",
       "            8,  5749,     8,  4923,    38,  2285,    38,  5940,     8,  2834,\n",
       "           41,     8,  5590,     9,     8,  1021,    21,  3112,   250,     8,\n",
       "         5749,    15,   115,    41,     8, 10631,     9,   198,    21,  4861,\n",
       "           19,    17,    61,   259,   363,    61,    27,     8,    88,     8,\n",
       "          226,    10,     7,    32,   409,     9,    47,    15,    67,    46,\n",
       "          128,    31,    17,   363,    61,    71,   272,   123,    12,    61,\n",
       "          259,     9,    19,    34,   393,   521,   125,    49,    12,    47,\n",
       "           60,    14,    80,   167,    10,     8,    42,    34,    67,  1625,\n",
       "            9,    47,    65,   306,   771,    10,    46,  1024,   486,    81,\n",
       "          237,    61,    28,     8,    64,   227,    89,    38,   560,     9,\n",
       "            8,  5749,    22,   428,   606,   460,     7,   214,    21,  2934,\n",
       "           91,    27,   715,    12,   712,    47,     9,   104,    84,    12,\n",
       "          695,   153,   152,    47,    22,    65,    81,    41,     8,  1853,\n",
       "            9,     7,  4192,  1347,     8,    42,    44,     9,    47,   773,\n",
       "          234,     8,   739,     8,  1249,     9,   286,   826,    35,    81,\n",
       "         1184,    82,    55,   522,   253,  1362,    11,    65,  1682,    16,\n",
       "         2182,  5634,     9,   172,   914,     9,    47,   527,   337,   188,\n",
       "          127,    41,     8,   340,     8,  8713,     8,  2489,    10,     8,\n",
       "           42,    17,   238,    82,   248,    65,    81,    19,  1468,    98,\n",
       "           73,    92,     9,    47,   332,   173,    48,   574,   291,  1630,\n",
       "         1047,    25,    35,   463,   349,   290,   216,    55,   249,  1040,\n",
       "            9,   165,    80,   837,    10,     7,    32,    44,     9,    47,\n",
       "           22,    80,   167,    50,    17,   546,    15,    80,   252,    32,\n",
       "           17,   187,    69,   272,   249,  1040,    24,    17,    19,    33,\n",
       "          546,    48,   138,    12,    47,   617,   290,    23,    10,     8,\n",
       "          124,   415,   311,    22,    15,   730,    60,   160,   435,     8,\n",
       "         3535,     8, 15877,     8,  2834,    24,    35,   540,   249,  1040,\n",
       "            8,  3535,    23,    10,     8,   107,    28,    40,  1144,    36,\n",
       "          148,    21,  3546,     9,     8,   687,   548,   217,     8,  1046,\n",
       "         1287,     8,   176,     7,   116,   484,   370,   124,   415,   311,\n",
       "           30,    15,    35,   149,    10,     7,    54,    42,     9,     8,\n",
       "         5749,   253,   460,   115,   286,    29,     8,  3336,    21,  5849,\n",
       "           11,    65,    81,    41,   435,     8,  3535,     8, 15877,     8,\n",
       "         2834,    26,    37,    21,  3918,     9,    47,   597,    60,     8,\n",
       "         1853,     9,     7,  4192,    10,    11,   128,    31,    63,   527,\n",
       "          337,   270,    84,    10,     8,  7777,     8,  5749,   128,    31,\n",
       "           35,    70,     7,   214,    21,  3606,    10,    18,     8,    21,\n",
       "         4148,     9,     8,  5749,   173,    48,   798,   640,    33,   204,\n",
       "           89,    12,    81,   524,   349,   290,    10,    47,    22,    15,\n",
       "          217,   124,   415,   311,    48,   138,    26,   111,    47,   195,\n",
       "           14,    13,   165,   478,    13,    21,  3382,    10,     8,   165,\n",
       "          597,   837,    48,   138,   524,   349,   290,   124,   165,   339,\n",
       "         1447,   290,  1284,    58,   165,   597,   837,   118,   792,   228,\n",
       "           17,   321,   389,    25,   587,  1801,   661,    55,  5060,  1890,\n",
       "            9,   569,    42,    44,   228,    17,   609,     0,    11,    15,\n",
       "          376,  2933,   124,    49,   728,   936,    58,    17,   837,   329,\n",
       "          118,   792,   124,   530,   187,    10,     8,   204,    89,    39,\n",
       "          487,    25,   204,    89,    15,    65,   160,   165,    12,     8,\n",
       "        15175,    10,     8,    21,   154,     5,    79,   344,     9,     8,\n",
       "         5749,    80,   167,    50,   204,    89,   346,  1146,   100,    46,\n",
       "          329,   349,   124,   103,   106,   108,   837,    10,     8,    19,\n",
       "          538,    17,   681,    21,    42,     9,    47,    22,   429,    31,\n",
       "           35,    35,   463,    12,    47,    26,    33,    35,   540,   359,\n",
       "          386,    10,     8,   278,   210,     9,    47,   851,   942,    20,\n",
       "           51,    80,   252,   247,    53,    39,   737,   100,    14,    86,\n",
       "          346,  1399,    14,    17,   111,   359,   386,     9,    11,    21,\n",
       "         2921,    47,    22,   495,   345,    17,   341,   612,    84,   309,\n",
       "          431,  1973,   860,     9,     5,    79,   277,    46,    47,   415,\n",
       "          112,    50,    35,   540,     8,   435,     8,  5749,     8, 15876,\n",
       "            8,  2834,    24,    35,   540,     8,   165,   597,   837,     8,\n",
       "         5749,    23,    10])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0][0] # when indexed, tfms are applied (last one: Numericalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Found 2000 items\n",
    "# 2 datasets of sizes 1600,400\n",
    "# Setting up Pipeline: ColReader -> Tokenizer -> Numericalize\n",
    "\n",
    "# Building one sample\n",
    "#   Pipeline: ColReader -> Tokenizer -> Numericalize\n",
    "#     starting from\n",
    "#       fname                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Lâm Tế Nghĩa Huyền\n",
    "# text           [xxbos, xxmaj, lâm, xxup, tế, xxmaj, nghĩa, xxmaj, huyền, \\n\\n, xxmaj, lâm, xxup, tế, xxmaj, nghĩa, xxmaj, huyền, (, zh, ., \", línjì, yìxuán, \", /, \", lin, -, chi, i, -, hsüan, \", 臨濟義玄, ,, ja, ., \", rinzai, gigen, \", ), ,, ?, -866, /, 867, ,, là, một, vị, xxmaj, thiền, sư, xxmaj, trung, xxmaj, quốc, ,, là, xxup, tổ, khai, dòng, thiền, xxmaj, lâm, xxup, tế, ., xxup, sư, là, môn, đệ, xuất, sắc, nhất, của, xxmaj, thiền, sư, xxmaj, hoàng, xxup, bá, xxmaj, hi, xxmaj, vận, ., xxmaj, môn, đệ, đắc, pháp, danh, tiếng, của, ...]\n",
    "# text_length                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1083\n",
    "# Name: 842, dtype: object\n",
    "#     applying ColReader gives\n",
    "#       (#1083) ['xxbos','xxmaj','lâm','xxup','tế','xxmaj','nghĩa','xxmaj','huyền','\\n\\n'...]\n",
    "#     applying Tokenizer gives\n",
    "#       (#1083) ['xxbos','xxmaj','lâm','xxup','tế','xxmaj','nghĩa','xxmaj','huyền','\\n\\n'...]\n",
    "#     applying Numericalize gives\n",
    "#       TensorText of size 1083\n",
    "\n",
    "# Final sample: (TensorText([  2,   8, 685,  ...,   8, 917,  10]),)\n",
    "\n",
    "\n",
    "# Setting up after_item: Pipeline: ToTensor\n",
    "# Setting up before_batch: Pipeline: \n",
    "# Setting up after_batch: Pipeline: \n",
    "\n",
    "# Building one batch\n",
    "# Applying item_tfms to the first sample:\n",
    "#   Pipeline: ToTensor\n",
    "#     starting from\n",
    "#       (TensorText of size 1083)\n",
    "#     applying ToTensor gives\n",
    "#       (TensorText of size 1083)\n",
    "\n",
    "# Adding the next 1 samples\n",
    "\n",
    "# No before_batch transform to apply\n",
    "\n",
    "# Collating items in a batch\n",
    "# Error! It's not possible to collate your items in a batch\n",
    "# Could not collate the 0-th members of your tuples because got the following shapes\n",
    "# torch.Size([1083]),torch.Size([1403])\n",
    "\n",
    "# TODO: in LM, for some reason the sequences in a batch aren’t padded to be of equal length \n",
    "# while making a LM. I know they are made equal when building the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LM learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(dls, \n",
    "                               AWD_LSTM, \n",
    "                               metrics=[accuracy, Perplexity()],\n",
    "                               drop_mult=1.0,\n",
    "                               pretrained=False,\n",
    "                               path=path).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026666666666666665"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "lr *= bs/48\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(fastai2.text.learner.LMLearner, fastai2.text.models.core.SequentialRNN)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(learn),type(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AWD_LSTM(\n",
       "   (encoder): Embedding(16880, 400, padding_idx=1)\n",
       "   (encoder_dp): EmbeddingDropout(\n",
       "     (emb): Embedding(16880, 400, padding_idx=1)\n",
       "   )\n",
       "   (rnns): ModuleList(\n",
       "     (0): WeightDropout(\n",
       "       (module): LSTM(400, 1152, batch_first=True)\n",
       "     )\n",
       "     (1): WeightDropout(\n",
       "       (module): LSTM(1152, 1152, batch_first=True)\n",
       "     )\n",
       "     (2): WeightDropout(\n",
       "       (module): LSTM(1152, 400, batch_first=True)\n",
       "     )\n",
       "   )\n",
       "   (input_dp): RNNDropout()\n",
       "   (hidden_dps): ModuleList(\n",
       "     (0): RNNDropout()\n",
       "     (1): RNNDropout()\n",
       "     (2): RNNDropout()\n",
       "   )\n",
       " ),\n",
       " LinearDecoder(\n",
       "   (decoder): Linear(in_features=400, out_features=16880, bias=True)\n",
       "   (output_dp): RNNDropout()\n",
       " ))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[0],learn.model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze() # == learn.opt.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai2.optimizer.Optimizer"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(learn.opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn.opt.param_lists) # 4 layers total, for discriminative fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Parameter containing:\n",
       "tensor([[-0.0265, -0.0237, -0.0002,  ...,  0.0589,  0.0365, -0.0771],\n",
       "        [-0.0727,  0.0680,  0.0860,  ..., -0.0225,  0.0744, -0.0529],\n",
       "        [-0.0837, -0.0377, -0.0800,  ...,  0.0547, -0.0811, -0.0814],\n",
       "        ...,\n",
       "        [-0.0955, -0.0637, -0.0995,  ...,  0.0144, -0.0873, -0.0919],\n",
       "        [-0.0015,  0.0195, -0.0042,  ...,  0.0760,  0.0056, -0.0345],\n",
       "        [-0.0373, -0.0433, -0.0862,  ..., -0.0831,  0.0852, -0.0219]],\n",
       "       device='cuda:0', requires_grad=True),Parameter containing:\n",
       "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.opt.param_lists[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([16880, 400]), torch.Size([16880])]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[getattr(i,'shape') for i in learn.opt.param_lists[3]] \n",
    "# matrix weight + bias of last linear layer (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([4608, 1152]),\n",
       " torch.Size([4608, 400]),\n",
       " torch.Size([4608]),\n",
       " torch.Size([4608])]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[getattr(i,'shape') for i in learn.opt.param_lists[0]] # 1st LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([4608, 1152]),\n",
       " torch.Size([4608, 1152]),\n",
       " torch.Size([4608]),\n",
       " torch.Size([4608])]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[getattr(i,'shape') for i in learn.opt.param_lists[1]] # 2nd LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1600, 400]),\n",
       " torch.Size([1600, 1152]),\n",
       " torch.Size([1600]),\n",
       " torch.Size([1600])]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[getattr(i,'shape') for i in learn.opt.param_lists[2]] # 3rd LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#4) [{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05},{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05},{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05},{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05}]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.opt.hypers # list of hyperparams for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice(None, 1, None)\n",
      "slice(None, 1, None)\n",
      "slice(1, None, None)\n",
      "slice(1, 2, None)\n",
      "slice(1, 2, 3)\n",
      "slice(None, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "# slice(start, stop, step)\n",
    "print(slice(1))\n",
    "print(slice(None,1))\n",
    "print(slice(1,None))\n",
    "print(slice(1,2))\n",
    "print(slice(1,2,3))\n",
    "print(slice(None,2,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(range(10))[slice(None)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [0],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2, 3],\n",
       " [0, 1, 2, 3, 4],\n",
       " [0, 1, 2, 3, 4, 5],\n",
       " [0, 1, 2, 3, 4, 5, 6],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8]]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(range(10))[slice(i)] for i in range(10)] # [:0],[:1],[:2]..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [3, 4, 5, 6, 7, 8, 9],\n",
       " [4, 5, 6, 7, 8, 9],\n",
       " [5, 6, 7, 8, 9],\n",
       " [6, 7, 8, 9],\n",
       " [7, 8, 9],\n",
       " [8, 9],\n",
       " [9]]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(range(10))[slice(i,None)] for i in range(10)] # [0:],[1:],[2:] ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9]]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(range(10))[slice(i,i+2)] for i in range(10)] # [0:2],[1:3], ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10))[slice(0,7,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.153887</td>\n",
       "      <td>5.969858</td>\n",
       "      <td>0.119671</td>\n",
       "      <td>391.450165</td>\n",
       "      <td>02:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.682713</td>\n",
       "      <td>4.455638</td>\n",
       "      <td>0.261569</td>\n",
       "      <td>86.111069</td>\n",
       "      <td>02:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.234314</td>\n",
       "      <td>4.185904</td>\n",
       "      <td>0.289397</td>\n",
       "      <td>65.752914</td>\n",
       "      <td>02:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "learn.fit_one_cycle(3, lr, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/quantran/.fastai/data/viwiki/models\n"
     ]
    }
   ],
   "source": [
    "mdl_path = path/'models'\n",
    "print(mdl_path)\n",
    "mdl_path.mkdir(exist_ok=True)\n",
    "lm_fns = [f'vi_wt', f'vi_wt_vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.to_fp32().save(mdl_path/lm_fns[0], with_opt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(mdl_path/(lm_fns[1] + '.pkl')):\n",
    "    os.remove(mdl_path/(lm_fns[1] + '.pkl'))\n",
    "#     print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mdl_path/(lm_fns[1] + '.pkl'), 'wb') as f:\n",
    "    pickle.dump(learn.dls.vocab, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## try drop_mult 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.453883</td>\n",
       "      <td>6.472377</td>\n",
       "      <td>0.101275</td>\n",
       "      <td>647.020081</td>\n",
       "      <td>02:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = language_model_learner(dls, \n",
    "                               AWD_LSTM, \n",
    "                               metrics=[accuracy, Perplexity()],\n",
    "                               drop_mult=0.5,\n",
    "                               pretrained=False,\n",
    "                               path=path).to_fp16()\n",
    "\n",
    "lr = 1e-2\n",
    "lr *= bs/48\n",
    "lr\n",
    "\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(1, lr, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/quantran/.fastai/data/viwiki/models\n"
     ]
    }
   ],
   "source": [
    "mdl_path = path/'models'\n",
    "print(mdl_path)\n",
    "mdl_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lm_fns = [f'vi_wt', f'vi_wt_vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# learn.to_fp32().save(mdl_path/lm_fns[0], with_opt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# learn.dls.vocab.save(mdl_path/(lm_fns[1] + '.pkl'))\n",
    "# with open(mdl_path/(lm_fns[1] + '.pkl'), 'wb') as f:\n",
    "#     pickle.dump(learn.dls.vocab, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## try original wikitext param training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "config = awd_lstm_lm_config.copy()\n",
    "config.update({'input_p': 0.6, 'output_p': 0.4, 'weight_p': 0.5, 'embed_p': 0.1, 'hidden_p': 0.2})\n",
    "model = get_language_model(AWD_LSTM, len(dls.vocab), config=config)\n",
    "opt_func = partial(Adam, wd=0.1, eps=1e-7)\n",
    "cbs = [MixedPrecision(clip=0.1), ModelResetter, RNNRegularizer(alpha=2, beta=1)]\n",
    "learn = Learner(dls, model, \n",
    "                loss_func=CrossEntropyLossFlat(), \n",
    "                opt_func=opt_func, \n",
    "                cbs=cbs, metrics=[accuracy, Perplexity()]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>202909.375000</td>\n",
       "      <td>9.725590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16740.558594</td>\n",
       "      <td>03:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 5e-03, moms=(0.8,0.7,0.8), div=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning LM with sentiment analysis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df.loc[pd.isna(train_df.comment),'comment']='NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_df.loc[pd.isna(test_df.comment),'comment']='NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_000000</td>\n",
       "      <td>Dung dc sp tot cam on \\nshop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_000001</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_000002</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_000003</td>\n",
       "      <td>:(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_000004</td>\n",
       "      <td>Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý :((</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  \\\n",
       "0  train_000000   \n",
       "1  train_000001   \n",
       "2  train_000002   \n",
       "3  train_000003   \n",
       "4  train_000004   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  comment  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                       Dung dc sp tot cam on \\nshop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                       Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                 Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất   \n",
       "3  :(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                  Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý :((   \n",
       "\n",
       "   label  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    1.0  \n",
       "4    1.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([train_df,test_df], sort=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>test_010976</td>\n",
       "      <td>Thời gian giao hàng rất nhanh.ngon.mà cay quá... Chất lượng sản phẩm tuyệt vời</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>test_010977</td>\n",
       "      <td>Sản phẩm hơi cũ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>test_010978</td>\n",
       "      <td>Sản phẩm chắc chắn nhưng k bóng bằng trong hình</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>test_010979</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời có mùi thơm rất dễ chịu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10980</th>\n",
       "      <td>test_010980</td>\n",
       "      <td>như quảng cáo. sim rất tốt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  \\\n",
       "10976  test_010976   \n",
       "10977  test_010977   \n",
       "10978  test_010978   \n",
       "10979  test_010979   \n",
       "10980  test_010980   \n",
       "\n",
       "                                                                               comment  \\\n",
       "10976   Thời gian giao hàng rất nhanh.ngon.mà cay quá... Chất lượng sản phẩm tuyệt vời   \n",
       "10977                                                                  Sản phẩm hơi cũ   \n",
       "10978                                  Sản phẩm chắc chắn nhưng k bóng bằng trong hình   \n",
       "10979                            Chất lượng sản phẩm tuyệt vời có mùi thơm rất dễ chịu   \n",
       "10980                                                       như quảng cáo. sim rất tốt   \n",
       "\n",
       "       label  \n",
       "10976    NaN  \n",
       "10977    NaN  \n",
       "10978    NaN  \n",
       "10979    NaN  \n",
       "10980    NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj rao kính cận nhận được miếng mica lắp vào mắt đeo nhưng không đeo . xxmaj lần sau đề nghị shop có sao nói vậy . xxmaj thanks . xxbos \" bạn cho mình hỏi , thực tế với những gì bạn dùng thì pin được bao lâu . nói thật là nghĩ đến pin aw là mình ko muốn dùng nhưng cứ hỏi đã vì dùng mà cứ phải</td>\n",
       "      <td>xxmaj rao kính cận nhận được miếng mica lắp vào mắt đeo nhưng không đeo . xxmaj lần sau đề nghị shop có sao nói vậy . xxmaj thanks . xxbos \" bạn cho mình hỏi , thực tế với những gì bạn dùng thì pin được bao lâu . nói thật là nghĩ đến pin aw là mình ko muốn dùng nhưng cứ hỏi đã vì dùng mà cứ phải sạc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mừng xxbos xxmaj chất lượng sản phẩm rất kém bé bị hăm đóng lần dầu da bi đo hết lên xxbos đóng gói sp rất đẹp . xxmaj giao hàng nhanh . xxmaj nhưng sạc ko sử dụng được cắm sạc cho pin sạc thì vào điện nhưng pin ko sạc cho điện thoại được . đang chờ xxmaj shop giải quyết cho mình . xxbos xxmaj sản phẩm rất ok giao</td>\n",
       "      <td>xxbos xxmaj chất lượng sản phẩm rất kém bé bị hăm đóng lần dầu da bi đo hết lên xxbos đóng gói sp rất đẹp . xxmaj giao hàng nhanh . xxmaj nhưng sạc ko sử dụng được cắm sạc cho pin sạc thì vào điện nhưng pin ko sạc cho điện thoại được . đang chờ xxmaj shop giải quyết cho mình . xxbos xxmaj sản phẩm rất ok giao hàng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>. xxmaj cái thừa cái thiếu . xxmaj nt thì còn tỏ thái độ bảo do khách nữa . xxup bó tay . ốp thì cứng . xxmaj bậy cả cường lực lên xxbos đặt 1 đường giao một nẻo xxbos đặt 2 nhưng shop gữi 3 😘 😘 xxbos đóng gói kĩ càng hàng tốt xxbos xxmaj sách này mua để tặng người bạn . xxmaj khi nhận hàng không kiểm</td>\n",
       "      <td>xxmaj cái thừa cái thiếu . xxmaj nt thì còn tỏ thái độ bảo do khách nữa . xxup bó tay . ốp thì cứng . xxmaj bậy cả cường lực lên xxbos đặt 1 đường giao một nẻo xxbos đặt 2 nhưng shop gữi 3 😘 😘 xxbos đóng gói kĩ càng hàng tốt xxbos xxmaj sách này mua để tặng người bạn . xxmaj khi nhận hàng không kiểm tra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_sen = TextDataLoaders.from_df(df, path=path, text_col='comment', \n",
    "                                  is_lm=True, \n",
    "                                  valid_pct=0.1,\n",
    "                                  seed=42)\n",
    "dls_sen.show_batch(max_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vi_wt', 'vi_wt_vocab']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_sen = language_model_learner(dls_sen, \n",
    "                               AWD_LSTM, \n",
    "                               metrics=[accuracy, Perplexity()],\n",
    "                               drop_mult=1.0,\n",
    "                               pretrained_fnames=lm_fns,\n",
    "                               path=path).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "lr *= bs/48."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5128"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls_sen.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(5128, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(5128, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=5128, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_sen.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [(#2) [Parameter containing:\n",
       "tensor([[-0.0800,  0.3884, -0.1179,  ..., -0.5469,  0.1759,  0.0697],\n",
       "        [ 0.0634,  0.0703, -0.0291,  ...,  0.2793, -0.0209,  0.0485],\n",
       "        [-0.0406, -0.3611,  0.0178,  ..., -0.0819,  0.0106, -0.0262],\n",
       "        ...,\n",
       "        [-0.0170,  0.0205, -0.0073,  ...,  0.2009,  0.0289,  0.0180],\n",
       "        [ 0.0424,  0.0948, -0.0264,  ...,  0.3237,  0.0136,  0.0779],\n",
       "        [ 0.0424,  0.0948, -0.0264,  ...,  0.3237,  0.0136,  0.0779]],\n",
       "       device='cuda:0', requires_grad=True),Parameter containing:\n",
       "tensor([ 2.2461, -0.9399, -0.2966,  ..., -0.4433, -0.9424, -0.9424],\n",
       "       device='cuda:0', requires_grad=True)]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_sen.opt.param_lists[-1:] # note that last linear layer requires_grad is True\n",
    "# equivalent to learn_sen.freeze() aka freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: save params copy for each params in paramlist, including embedding.\n",
    "# and check if they are updated, especially the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4608, 1152])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_sen.opt.param_lists[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4608, 400])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_sen.opt.param_lists[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn_sen.model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['0.encoder.weight', '0.encoder_dp.emb.weight', '0.rnns.0.weight_hh_l0_raw', '0.rnns.0.module.weight_ih_l0', '0.rnns.0.module.bias_ih_l0', '0.rnns.0.module.bias_hh_l0', '0.rnns.1.weight_hh_l0_raw', '0.rnns.1.module.weight_ih_l0', '0.rnns.1.module.bias_ih_l0', '0.rnns.1.module.bias_hh_l0', '0.rnns.2.weight_hh_l0_raw', '0.rnns.2.module.weight_ih_l0', '0.rnns.2.module.bias_ih_l0', '0.rnns.2.module.bias_hh_l0', '1.decoder.weight', '1.decoder.bias'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_sen.model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: what is state_dict? is it native or fastai code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.152511</td>\n",
       "      <td>6.019076</td>\n",
       "      <td>0.067690</td>\n",
       "      <td>411.198425</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.058696</td>\n",
       "      <td>5.990380</td>\n",
       "      <td>0.067661</td>\n",
       "      <td>399.566528</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_sen.fit_one_cycle(2, lr*10, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.036370</td>\n",
       "      <td>5.988560</td>\n",
       "      <td>0.067676</td>\n",
       "      <td>398.839935</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.851128</td>\n",
       "      <td>5.646402</td>\n",
       "      <td>0.090719</td>\n",
       "      <td>283.270386</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.631660</td>\n",
       "      <td>5.454767</td>\n",
       "      <td>0.120689</td>\n",
       "      <td>233.870316</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.468768</td>\n",
       "      <td>5.241914</td>\n",
       "      <td>0.158550</td>\n",
       "      <td>189.031525</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.267761</td>\n",
       "      <td>5.027405</td>\n",
       "      <td>0.200832</td>\n",
       "      <td>152.536713</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.145017</td>\n",
       "      <td>4.926765</td>\n",
       "      <td>0.218511</td>\n",
       "      <td>137.932571</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.077459</td>\n",
       "      <td>4.887059</td>\n",
       "      <td>0.233612</td>\n",
       "      <td>132.563156</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5.060335</td>\n",
       "      <td>4.879044</td>\n",
       "      <td>0.235192</td>\n",
       "      <td>131.504837</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_sen.unfreeze()\n",
    "learn_sen.fit_one_cycle(8, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn_sen.save_encoder('finetuned_sen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: prepare for backward lm + sent classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('fastai2': conda)",
   "language": "python",
   "name": "python37664bitfastai2conda023d9f2c3b894be385b0b3b80e252fc1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
