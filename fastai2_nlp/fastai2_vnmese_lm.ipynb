{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/home/quan/.fastai/data/viwiki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/quan/.fastai/data/viwiki')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/quan/.fastai/data/viwiki/docs')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path/'docs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/quan/.fastai/data/viwiki/models\n"
     ]
    }
   ],
   "source": [
    "mdl_path = path/'models'\n",
    "print(mdl_path)\n",
    "mdl_path.mkdir(exist_ok=True)\n",
    "lm_fns = [f'vi_wt', f'vi_wt_vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [Path('/home/quan/.fastai/data/viwiki/docs/Doug Emhoff.txt'),Path('/home/quan/.fastai/data/viwiki/docs/HMS Myngs (R06).txt'),Path('/home/quan/.fastai/data/viwiki/docs/Xuân La (phường).txt'),Path('/home/quan/.fastai/data/viwiki/docs/Cung điện Goldstein.txt'),Path('/home/quan/.fastai/data/viwiki/docs/Tứ khố toàn thư.txt')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'docs').ls()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note! Dataset: we have a list of txt files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Prepare df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_lol(path): # make list of list containing file name and file content\n",
    "    name = path.stem\n",
    "    with open(path, 'r',encoding=\"utf-8\") as temp:\n",
    "        data = temp.read()\n",
    "    return [name,data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doug Emhoff\n",
      "\n",
      "Douglas Craig Emhoff (sinh ngày 13 tháng 10 năm 1964) là một luật sư người Mỹ và là chồng của Phó Tổng thống đắc cử Kamala Harris. Ông sẽ trở thành \"Đệ nhị Phu quân\" đầu tiên trong lịch sử Mỹ và là người phối ngẫu gốc Do Thái đầu tiên của một phó tổng thống.\n",
      "\n",
      "Emhoff sinh ra tại quận Brooklyn của Thành phố New York, là con trai của bố mẹ gốc Do Thái là bà Barbara (nhũ danh Kanzer) và ông Michael Emhoff. Ông có một anh trai là Andy Emhoff và một em gái là Jamie Emhoff. Ông sống ở New Jersey từ năm 1969 đến năm 1981 trước khi cùng gia đình chuyển đến California năm 17 tuổi. Emhoff lấy bằng Cử nhân Văn học tại Đại học Bang California tại Northridge và bằng Tiến sĩ Luật từ Trường Luật Gould thuộc Viện Đại học Nam California vào năm 1990.\n",
      "\n",
      "Emhoff đã kết hôn 16 năm với người vợ đầu là bà Kerstin Emhoff (nhũ danh Mackin). Họ có hai con, Cole và Ella. Sau khi cuộc hôn nhân thứ nhất kết thúc, ông kết hôn với bà Kamala Harris vào ngày 22 tháng 8 năm 2014, tại Santa Barbara, California. Lúc này bà Kamala đang giữ chức Tổng chưởng lý của tiểu bang California. Tính đến tháng 8 năm 2019, Emhoff và Harris có tổng tài sản ròng ước tính là 5,8 triệu đô la.\n",
      "\n",
      "Kamala Harris là ứng cử viên trong cuộc bầu cử sơ bộ Tổng thống Đảng Dân chủ năm 2020 trước khi rút lui vào tháng 12 năm 2019. Harris được chọn là ứng cử viên phó tổng thống tranh cử cùng Joe Biden cho cuộc bầu cử tổng thống Hoa Kỳ năm 2020 vào ngày 11 tháng 8 năm 2020, khiến Emhoff trở thành người đàn ông thứ ba trong lịch sử Hoa Kỳ trở thành vợ hoặc chồng của một ứng viên phó tổng thống. Khi Harris nhậm chức, Emhoff sẽ trở thành Đệ nhị Phu quân đầu tiên của Hoa Kỳ. Ông cũng sẽ là người phối ngẫu gốc Do Thái đầu tiên của một phó tổng thống Hoa Kỳ.\n",
      "\n",
      "Trong vai trò là Đệ nhị Phu quân, Emhoff sẽ tập trung vào việc đảm bảo việc tiếp cận công lý và đại diện pháp lý trở nên bình đẳng hơn.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = make_lol((path/'docs').ls()[0])\n",
    "print(temp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82346"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((path/'docs').ls()) # number of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: doing things in parallel\n",
    "??parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# results = parallel(make_lol,(path/'docs').ls())\n",
    "\n",
    "# result_df = pd.DataFrame(results,columns=['fname','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82341</th>\n",
       "      <td>Vấn đề môi trường ở Indonesia</td>\n",
       "      <td>Vấn đề môi trường ở Indonesia\\n\\nthumb|360px|Các nhân viên cứu hỏa Indonesia đang cố gắng để ngăn chặn lửa rừng ở Nam Kalimantan (2015).\\n\\nCác vấn đề môi trường ở Indonesia liên quan đến mật độ dân số cao và công nghiệp hóa nhanh, và chúng thường được ưu tiên thấp hơn do mức nghèo đói cao và quản lý nguồn lực có hạn chế.\\n\\nCác vấn đề bao gồm nạn phá rừng quy mô lớn (phần lớn là bất hợp pháp) và các vụ cháy rừng liên quan gây ra sương mù dầy đặc ở các khu vực phía Tây Indonesia, Malaysia và Singapore; khai thác quá mức các nguồn tài nguyên biển; và các vấn đề về môi trường liên quan đến q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82342</th>\n",
       "      <td>Cát Vinh</td>\n",
       "      <td>Cát Vinh\\n\\nCát Vinh (, ? – 528) thủ lĩnh khởi nghĩa nông dân Hà Bắc, là lực lượng lớn mạnh nhất trong phong trào Lục Trấn khởi nghĩa phản kháng nhà Bắc Ngụy.\\n\\nBan đầu Cát Vinh là Trấn tướng của trấn Hoài Sóc. Theo phép của nhà Bắc Ngụy, Trấn tướng đều lấy quý tộc Tiên Ti đảm nhiệm, từ đó suy đoán ông cũng là người Tiên Ti.\\n\\nTháng giêng năm Hiếu Xương thứ 2 (526), nguyên Hoài Sóc trấn binh Tiên Vu Tu Lễ tại thành Tả Nhân, Định Châu lãnh đạo khởi nghĩa. Hoài Sóc trấn tướng Cát Vinh tham gia khởi nghĩa.\\n\\nTháng 8, Nguyên Hồng Nghiệp làm phản, giết Tiên Vu Tu Lễ, xin hàng triều đình. Cát...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82343</th>\n",
       "      <td>Pye Wacket</td>\n",
       "      <td>Pye Wacket\\n\\nPye Wacket là mật danh của một tên lửa không đối không dạng thấu kính thử nghiệm được chi nhánh Convair của tập đoàn General Dynamics phát triển vào năm 1957. Dự định là một tên lửa phòng thủ cho máy bay ném bom B-70 Valkyrie Mach 3, chương trình đã cho thấy thử nghiệm đường ống gió khí động học rộng rãi và có vẻ đầy hứa hẹn; tuy nhiên việc hủy bỏ B-70 đã loại bỏ yêu cầu đối với tên lửa, và dự án này cũng bị hủy bỏ luôn.\\n\\nDự án \"Pye Wacket\", được chính thức gọi là Chương trình Lenticular Defense Missile (LDM) và theo số dự án WS-740A, được thành lập vào năm 1958 để đáp ứng ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82344</th>\n",
       "      <td>Giải cờ vua M-Tel</td>\n",
       "      <td>Giải cờ vua M-Tel\\n\\nGiải cờ vua M-Tel, tên chính thức tiếng Bulgaria: М-Тел Мастърс, tiếng Anh M-Tel Masters là một giải cờ vua thường niên được tổ chức từ năm 2005 đến 2009 tại Sofia, thủ đô của Bulgaria. Giải đấu lấy tên theo nhà tài trợ và cũng là nhà tổ chức, công ty mạng di động hàng đầu của Bulgaria M-Tel. Mỗi năm giải mời 6 đại kiện tướng hàng đầu (thường có hệ số điểm Elo trên 2700) tham dự, thi đấu theo thể thức vòng tròn 2 lượt. Địa điểm thi đấu tại khách sạn 5 sao Grand Hotel Sofia. Do những khó khăn về kinh tế, cũng như một số lý do khách quan nên giải đấu không còn được tổ ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82345</th>\n",
       "      <td>Salzburg</td>\n",
       "      <td>Salzburg\\n\\nSalzburg ( ; ; nghĩa đen là \"Salt Fortress\" hay \"Pháo đài muối\"; tiếng Bayern: \"Soizbuag\") là thủ phủ của tiểu bang cùng tên thuộc Cộng hòa Áo. Với 150.269 dân cư, Salzburg là thành phố lớn thứ tư của Áo sau Viên, Graz và Linz.\\n\\nThị trấn nằm trên địa điểm của khu định cư La Mã trước đây của \"Iuvavum\". Salzburg được thành lập như một tòa giám mục vào năm 696 và trở thành trụ sở của tổng giám mục vào năm 798. Nguồn thu nhập chính của nó là khai thác và buôn bán muối và đôi khi là khai thác vàng. Pháo đài Hohensalzburg, một trong những pháo đài thời trung cổ lớn nhất ở châu Âu, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               fname  \\\n",
       "82341  Vấn đề môi trường ở Indonesia   \n",
       "82342                       Cát Vinh   \n",
       "82343                     Pye Wacket   \n",
       "82344              Giải cờ vua M-Tel   \n",
       "82345                       Salzburg   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          text  \n",
       "82341  Vấn đề môi trường ở Indonesia\\n\\nthumb|360px|Các nhân viên cứu hỏa Indonesia đang cố gắng để ngăn chặn lửa rừng ở Nam Kalimantan (2015).\\n\\nCác vấn đề môi trường ở Indonesia liên quan đến mật độ dân số cao và công nghiệp hóa nhanh, và chúng thường được ưu tiên thấp hơn do mức nghèo đói cao và quản lý nguồn lực có hạn chế.\\n\\nCác vấn đề bao gồm nạn phá rừng quy mô lớn (phần lớn là bất hợp pháp) và các vụ cháy rừng liên quan gây ra sương mù dầy đặc ở các khu vực phía Tây Indonesia, Malaysia và Singapore; khai thác quá mức các nguồn tài nguyên biển; và các vấn đề về môi trường liên quan đến q...  \n",
       "82342  Cát Vinh\\n\\nCát Vinh (, ? – 528) thủ lĩnh khởi nghĩa nông dân Hà Bắc, là lực lượng lớn mạnh nhất trong phong trào Lục Trấn khởi nghĩa phản kháng nhà Bắc Ngụy.\\n\\nBan đầu Cát Vinh là Trấn tướng của trấn Hoài Sóc. Theo phép của nhà Bắc Ngụy, Trấn tướng đều lấy quý tộc Tiên Ti đảm nhiệm, từ đó suy đoán ông cũng là người Tiên Ti.\\n\\nTháng giêng năm Hiếu Xương thứ 2 (526), nguyên Hoài Sóc trấn binh Tiên Vu Tu Lễ tại thành Tả Nhân, Định Châu lãnh đạo khởi nghĩa. Hoài Sóc trấn tướng Cát Vinh tham gia khởi nghĩa.\\n\\nTháng 8, Nguyên Hồng Nghiệp làm phản, giết Tiên Vu Tu Lễ, xin hàng triều đình. Cát...  \n",
       "82343  Pye Wacket\\n\\nPye Wacket là mật danh của một tên lửa không đối không dạng thấu kính thử nghiệm được chi nhánh Convair của tập đoàn General Dynamics phát triển vào năm 1957. Dự định là một tên lửa phòng thủ cho máy bay ném bom B-70 Valkyrie Mach 3, chương trình đã cho thấy thử nghiệm đường ống gió khí động học rộng rãi và có vẻ đầy hứa hẹn; tuy nhiên việc hủy bỏ B-70 đã loại bỏ yêu cầu đối với tên lửa, và dự án này cũng bị hủy bỏ luôn.\\n\\nDự án \"Pye Wacket\", được chính thức gọi là Chương trình Lenticular Defense Missile (LDM) và theo số dự án WS-740A, được thành lập vào năm 1958 để đáp ứng ...  \n",
       "82344  Giải cờ vua M-Tel\\n\\nGiải cờ vua M-Tel, tên chính thức tiếng Bulgaria: М-Тел Мастърс, tiếng Anh M-Tel Masters là một giải cờ vua thường niên được tổ chức từ năm 2005 đến 2009 tại Sofia, thủ đô của Bulgaria. Giải đấu lấy tên theo nhà tài trợ và cũng là nhà tổ chức, công ty mạng di động hàng đầu của Bulgaria M-Tel. Mỗi năm giải mời 6 đại kiện tướng hàng đầu (thường có hệ số điểm Elo trên 2700) tham dự, thi đấu theo thể thức vòng tròn 2 lượt. Địa điểm thi đấu tại khách sạn 5 sao Grand Hotel Sofia. Do những khó khăn về kinh tế, cũng như một số lý do khách quan nên giải đấu không còn được tổ ch...  \n",
       "82345  Salzburg\\n\\nSalzburg ( ; ; nghĩa đen là \"Salt Fortress\" hay \"Pháo đài muối\"; tiếng Bayern: \"Soizbuag\") là thủ phủ của tiểu bang cùng tên thuộc Cộng hòa Áo. Với 150.269 dân cư, Salzburg là thành phố lớn thứ tư của Áo sau Viên, Graz và Linz.\\n\\nThị trấn nằm trên địa điểm của khu định cư La Mã trước đây của \"Iuvavum\". Salzburg được thành lập như một tòa giám mục vào năm 696 và trở thành trụ sở của tổng giám mục vào năm 798. Nguồn thu nhập chính của nó là khai thác và buôn bán muối và đôi khi là khai thác vàng. Pháo đài Hohensalzburg, một trong những pháo đài thời trung cổ lớn nhất ở châu Âu, ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# result_df.to_csv(path/'alltext.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build LM wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df = pd.read_csv(path/'alltext.csv',encoding='utf-8')\n",
    "result_df = pd.read_csv(path/'alltext.csv',encoding='utf-8',nrows=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnmese_lm = DataBlock(blocks=TextBlock.from_df('text', is_lm=True),\n",
    "                    get_x=ColReader('text'),\n",
    "                    splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs=64\n",
    "# bs=24\n",
    "bs=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "dls = vnmese_lm.dataloaders(result_df, bs=bs, seq_len=72)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj raymond xxmaj gravel \\n\\n xxmaj raymond xxmaj gravel ( 4 tháng 11 năm 1952 – 11 tháng 8 năm 2014 ) là một linh mục xxmaj công giáo và chính khách xxmaj canada từ tỉnh xxmaj quebec . xxmaj gravel trước đây là xxmaj thành viên của xxmaj quốc hội về việc tranh cử xxmaj xxunk , là thành viên của xxmaj bloc xxmaj xxunk . ông được bầu vào</td>\n",
       "      <td>xxmaj raymond xxmaj gravel \\n\\n xxmaj raymond xxmaj gravel ( 4 tháng 11 năm 1952 – 11 tháng 8 năm 2014 ) là một linh mục xxmaj công giáo và chính khách xxmaj canada từ tỉnh xxmaj quebec . xxmaj gravel trước đây là xxmaj thành viên của xxmaj quốc hội về việc tranh cử xxmaj xxunk , là thành viên của xxmaj bloc xxmaj xxunk . ông được bầu vào xxup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxmaj trong mùa xxmaj thu năm 1964 , chiếc tàu khu trục hoạt động ngoài khơi bờ biển xxmaj việt xxmaj nam để hộ tống và canh phòng máy bay cho xxmaj lực lượng đặc nhiệm 77 , và thỉnh thoảng tham gia bắn phá bờ biển hỗ trợ lực lượng trên bộ tại khu vực đồng bằng sông xxmaj cửu xxmaj long . xxup nó rời khu vực chiến sự vào</td>\n",
       "      <td>trong mùa xxmaj thu năm 1964 , chiếc tàu khu trục hoạt động ngoài khơi bờ biển xxmaj việt xxmaj nam để hộ tống và canh phòng máy bay cho xxmaj lực lượng đặc nhiệm 77 , và thỉnh thoảng tham gia bắn phá bờ biển hỗ trợ lực lượng trên bộ tại khu vực đồng bằng sông xxmaj cửu xxmaj long . xxup nó rời khu vực chiến sự vào tháng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cháy . xxup xxunk đã không xác nhận tính hợp pháp của video nhưng họ đã phát biểu rằng máy bay đã cháy trước khi phát nổ . \\n\\n xxmaj thời gian ngắn sau vụ nổ , những nhân viên phản ứng nhanh đã tới với 22 xe cứu thương , 4 xe bus cứu thương , và 1 máy bay trực thăng , nhưng vụ cháy lớn đã ngăn họ cố</td>\n",
       "      <td>. xxup xxunk đã không xác nhận tính hợp pháp của video nhưng họ đã phát biểu rằng máy bay đã cháy trước khi phát nổ . \\n\\n xxmaj thời gian ngắn sau vụ nổ , những nhân viên phản ứng nhanh đã tới với 22 xe cứu thương , 4 xe bus cứu thương , và 1 máy bay trực thăng , nhưng vụ cháy lớn đã ngăn họ cố gắng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>đúng là lần lượt thuộc chủ quyền của hai quốc gia bản xứ trên đảo xxmaj xxunk ít nhất là từ năm 1700 . xxmaj các quốc gia bản xứ này đã lần lượt phụ thuộc vào công ty đông ấn của xxup hà xxmaj lan , hành động nhân danh xxmaj nhà nước xxup hà xxmaj lan từ năm 1677 và sau đó trực tiếp phụ thuộc vào xxmaj nhà nước</td>\n",
       "      <td>là lần lượt thuộc chủ quyền của hai quốc gia bản xứ trên đảo xxmaj xxunk ít nhất là từ năm 1700 . xxmaj các quốc gia bản xứ này đã lần lượt phụ thuộc vào công ty đông ấn của xxup hà xxmaj lan , hành động nhân danh xxmaj nhà nước xxup hà xxmaj lan từ năm 1677 và sau đó trực tiếp phụ thuộc vào xxmaj nhà nước xxup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## TextBlock datablock summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.data.block.DataBlock"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vnmese_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting-up type transforms pipelines\n",
      "Collecting items from                     fname  \\\n",
      "0             Doug Emhoff   \n",
      "1         HMS Myngs (R06)   \n",
      "2        Xuân La (phường)   \n",
      "3     Cung điện Goldstein   \n",
      "4         Tứ khố toàn thư   \n",
      "...                   ...   \n",
      "1995       Viva World Cup   \n",
      "1996     Nguyên lý Pareto   \n",
      "1997        Moshe Rynecki   \n",
      "1998  Ngựa Selle Français   \n",
      "1999       Takahashi Juri   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         text  \n",
      "0     Doug Emhoff\\n\\nDouglas Craig Emhoff (sinh ngày 13 tháng 10 năm 1964) là một luật sư người Mỹ và là chồng của Phó Tổng thống đắc cử Kamala Harris. Ông sẽ trở thành \"Đệ nhị Phu quân\" đầu tiên trong lịch sử Mỹ và là người phối ngẫu gốc Do Thái đầu tiên của một phó tổng thống.\\n\\nEmhoff sinh ra tại quận Brooklyn của Thành phố New York, là con trai của bố mẹ gốc Do Thái là bà Barbara (nhũ danh Kanzer) và ông Michael Emhoff. Ông có một anh trai là Andy Emhoff và một em gái là Jamie Emhoff. Ông sống ở New Jersey từ năm 1969 đến năm 1981 trước khi cùng gia đình chuyển đến California năm 17 tuổi. E...  \n",
      "1     HMS Myngs (R06)\\n\\nHMS \"Myngs\" (R06/D06) là một soái hạm khu trục dẫn đầu lớp tàu khu trục Z của Hải quân Hoàng gia Anh Quốc được chế tạo trong Chiến tranh Thế giới thứ hai. Sống sót qua cuộc xung đột, nó được đưa về lực lượng dự bị năm 1954 và dự định cải biến thành một tàu frigate, nhưng lại được bán cho Ai Cập năm 1955 và tiếp tục phục vụ như là chiếc \"El Qaher\". Nó bị máy bay Israel đánh chìm năm 1970.\\n\\n\"Myngs\" được đặt hàng vào tháng 2 năm 1942 như một phần của Chi hạm đội Khẩn cấp 10, và được chế tạo tại xưởng tàu của hãng Vickers-Armstrong ở Tyneside. Nó được đặt lườn vào ngày 27 ...  \n",
      "2     Xuân La (phường)\\n\\nXuân La là một phường trực thuộc quận Tây Hồ, thành phố Hà Nội, Việt Nam.\\n\\nPhường Xuân La nằm ở phía tây của hồ Tây. Đây là vùng đất cổ của Hà Nội, nổi tiếng với các ngôi chùa: Khai Nguyên, Thiên Niên, Vạn Niên, Ức Niên.\\n\\n\\nNăm 1995, phường Xuân La có diện tích 217,7 hécta và dân số 6.386 người.\\n\\nNăm 2009, phường này có diện tích là 235,074 ha và dân số 18.903 người.\\n\\nXã Xuân La được thành lập trong thời kì kháng chiến chống Pháp trên cơ sở sáp nhập các làng Quán La xã, Quán La sở, Xuân Tảo sở và Vệ Hồ. Khi thành lập, xã Xuân La thuộc quận Lãng Bạc, sau thuộc hu...  \n",
      "3     Cung điện Goldstein\\n\\nCung điện Goldstein hay còn được gọi là Biệt thự Goldstein hoặc Cung điện Przemysłowców, là một tòa nhà có kiến trúc Neo-Renaissance (kiến trúc Phục hưng của Ý) nằm ở phía tây của trung tâm thành phố Katowice, ngay ở góc của Quảng trường Wolności và đường Jana Matejki.\\n\\nCung điện Goldstein được xây dựng vào năm 1872 bởi anh em Abraham và Józef Goldstein, những người Do Thái giàu có đến từ lãnh thổ của phân vùng Nga, người đã làm kinh doanh ở Górnym Śląsku một thời gian. Họ đến Katowice với tư cách là những người buôn gỗ và thành lập chuỗi xưởng cưa. Ngoài việc điều...  \n",
      "4     Tứ khố toàn thư\\n\\nTứ khố toàn thư (tiếng Trung: 四庫全書) là bách khoa lớn nhất trong lịch sử phong kiến Trung Quốc. Nó được Hoàng đế Càn Long nhà Thanh giao cho 361 học giả, đứng đầu là Kỉ Quân và Lục Tích Hùng, biên soạn trong khoảng thời gian từ 1773 đến 1782, nó đã trải qua vô vàn sóng gió cùng với máu tanh vì trong thời gian này chế độ vua chúa nhà Thanh bớ gắt gao những người có tư tưởng phản Thanh phục Minh dù là trong thơ ca. Với 4 phần lớn là Kinh (經), Sử (史), Tử (子), Tập (集), \"Tứ khố toàn thư\" đã tập hợp trên 10.000 bản thảo từ các bộ sưu tập của những triều đại phong kiến Trung Quố...  \n",
      "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...  \n",
      "1995  Viva World Cup\\n\\nVIVA World cup là giải đấu được tổ chức bởi NF-Board 2 năm 1 lần. Các đội tham dự giải là những đội tuyển quốc gia không phải là thành viên của FIFA.\\n\\nVào tháng 5 năm 2005, NF Board thông báo thành viên Bắc Síp sẽ là chủ nhà giải đấu để kỷ niệm 50 năm thành lập của thành viên này. Tuy nhiên, vì nhiều lý do, NF Board đã chuyển giải đấu sang cho thành viên Occitania (1 vùng nằm ở Nam Âu). 6 đội tham dự là Monaco, Sápmi, Nam Cameroon, Tây Papua (vùng), đội của người Roman. Tuy nhiên, vì nhiều lý do chỉ còn lại Monaco, Sapmi và chủ nhà tham dự. Nam Cameroon cũng tham dự như...  \n",
      "1996  Nguyên lý Pareto\\n\\nQuy luật Pareto hay quy luật 80/20 (quy luật thiểu số quan trọng và phân bố nhân tố) nói rằng trong nhiều sự kiện, khoảng 80% kết quả là do 20% nguyên nhân gây ra. Nhà tư tưởng quản trị doanh nghiệp Joseph M. Juran đề xuất quy luật này và đặt theo tên của nhà kinh tế người Ý Vilfredo Pareto người đã quan sát 80% đất ở Ý là thuộc sở hữu của 20% dân số. Đây cũng là quy luật phổ biến trong kinh doanh chẳng hạn 80% doanh thu là từ 20% trong số các khách hàng.\\n\\nKhi xét một thứ gì được sở hữu bởi một số lượng lớn vừa đủ người thì luôn tồn tại một số k (50 < k < 100) sao cho...  \n",
      "1997  Moshe Rynecki\\n\\nMoshe Rynecki (, \"Mosheh Rynetski\"; sinh năm 1881 - mất năm 1943) là một họa sĩ người Ba Lan gốc Do Thái. Ông sinh ra trong một gia đình sùng đạo tại Międzyrzec Podlaski, Ba Lan. Cha mẹ ông có 18 người con. Ông là một trong năm người con còn sống của họ. Những người con khác mất lúc còn bé do mắc nhiều loại bệnh khác nhau.\\n\\nMoshe Rynecki bắt đầu vẽ tranh từ khi còn nhỏ. Theo lời kể của gia đình, ông thường dùng phấn hoặc đôi khi dùng sơn, nếu có, để vẽ lên sàn và tường nhà. Trong cuốn hồi ký của con trai ông, George, \"Chưa lần nào ông bị đánh vì không vâng lời căn dặn củ...  \n",
      "1998  Ngựa Selle Français\\n\\nNgựa Selle Français (viết tắt SF) là một giống ngựa của môn thể thao đua ngựa có nguồn tốc từ Pháp. Nó được nổi tiếng chủ yếu cho sự thành công của giống ngựa này trong chương trình thi nhảy. Một con ngựa thể thao thon gọn với màu hạt dẻ. \\nNgựa Selle Français đã được lai tạo ra vào năm 1958 khi một số giống ngựa cưỡi Pháp đã được sáp nhập. Các giống mới được có nghĩa là để phục vụ như là một con ngựa thể thao thống nhất trong một khoảng thời gian khi con ngựa đã được thay thế bằng cơ giới hóa và được chuyển vào một vật được sử dụng chủ yếu cho các môn thể thao và gi...  \n",
      "1999  Takahashi Juri\\n\\nQua việc cô được chọn làm thực tập sinh của Woolim Entertainment, và hiện đang hoạt động dưới nhóm nhạc Rocket Punch cùng công ty vào tháng 8 năm 2019..\\n\\nTakahashi Juri đã vượt qua vòng thi thử giọng tuyển thành viên thứ 12 của AKB48 vào ngày 20 tháng 2 năm 2011. Cô được chuyển lên Team 4 vào tháng 3 năm 2012 (Saitama Super Arena), nhưng sau đó chuyển về Team A vào tháng 8 năm 2012 (Tokyo Dome Team Shuffle). Tại AKB48 Group Shuffle vào tháng 2 năm 2014, Takahashi Juri chuyển sang trở thành thành viên của Team B. Trong kì (AKB48 Spring Shuffle 2015), Takahashi Juri được ...  \n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "Found 2000 items\n",
      "2 datasets of sizes 1600,400\n",
      "Setting up Pipeline: ColReader -- {'cols': 'text', 'pref': '', 'suff': '', 'label_delim': None} -> Tokenizer -> Numericalize\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building one sample\n",
      "  Pipeline: ColReader -- {'cols': 'text', 'pref': '', 'suff': '', 'label_delim': None} -> Tokenizer -> Numericalize\n",
      "    starting from\n",
      "      fname                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Nhân mụn\n",
      "text           [xxbos, xxmaj, nhân, mụn, \\n\\n, xxmaj, nhân, mụn, (, tiếng, xxmaj, anh, :, \", comedo, \", ;, \", conmedones, \", ), là, tình, trạnh, một, nang, lông, (, lỗ, chân, lông, ), trên, da, bị, bít, tắc, ., xxmaj, keratin, (, mảnh, vụn, da, ), kết, hợp, với, dầu, thừa, trên, da, khóa, kín, nang, lông, ., xxmaj, nhân, mụn, trứng, cá, có, thể, ở, dạng, mở, (, mụn, đầu, đen, ), hoặc, bị, da, đóng, kín, (, mụn, đầu, trắng, ), và, dẫn, đến, tình, trạng, mụn, trứng, cá, hoặc, không, ., xxup, từ, \", comedo, \", bắt, nguồn, ...]\n",
      "text_length                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   726\n",
      "Name: 1890, dtype: object\n",
      "    applying ColReader -- {'cols': 'text', 'pref': '', 'suff': '', 'label_delim': None} gives\n",
      "      ['xxbos', 'xxmaj', 'nhân', 'mụn', '\\n\\n', 'xxmaj', 'nhân', 'mụn', '(', 'tiếng', 'xxmaj', 'anh', ':', '\"', 'comedo', '\"', ';', '\"', 'conmedones', '\"', ')', 'là', 'tình', 'trạnh', 'một', 'nang', 'lông', '(', 'lỗ', 'chân', 'lông', ')', 'trên', 'da', 'bị', 'bít', 'tắc', '.', 'xxmaj', 'keratin', '(', 'mảnh', 'vụn', 'da', ')', 'kết', 'hợp', 'với', 'dầu', 'thừa', 'trên', 'da', 'khóa', 'kín', 'nang', 'lông', '.', 'xxmaj', 'nhân', 'mụn', 'trứng', 'cá', 'có', 'thể', 'ở', 'dạng', 'mở', '(', 'mụn', 'đầu', 'đen', ')', 'hoặc', 'bị', 'da', 'đóng', 'kín', '(', 'mụn', 'đầu', 'trắng', ')', 'và', 'dẫn', 'đến', 'tình', 'trạng', 'mụn', 'trứng', 'cá', 'hoặc', 'không', '.', 'xxup', 'từ', '\"', 'comedo', '\"', 'bắt', 'nguồn', 'từ', 'tiếng', 'xxmaj', 'latin', '\"', 'comedere', '\"', 'có', 'nghĩa', 'là', \"'\", 'ăn', 'hết', \"'\", ',', 'trước', 'kia', 'được', 'sử', 'dụng', 'để', 'mô', 'tả', 'giun', 'ký', 'sinh', ';', 'trong', 'thuật', 'ngữ', 'y', 'học', 'hiện', 'đại', ',', 'nó', 'được', 'dùng', 'để', 'liên', 'tưởng', 'sự', 'xuất', 'hiện', 'của', 'loài', 'vật', 'kí', 'sinh', 'dạng', 'giống', 'ấu', 'trùng', '.', '\\n\\n', 'xxmaj', 'tình', 'trạng', 'viêm', 'da', 'mãn', 'tính', 'thường', 'xuất', 'hiện', 'gồm', 'có', 'các', 'nốt', 'mụn', 'nhân', ',', 'mụn', 'sẩn', 'viêm', '(', 'inflamed', 'papules', ')', 'và', 'các', 'nốt', 'mụn', 'mủ', '(', 'pustules', 'hoặc', 'pimples', ')', 'được', 'gọi', 'là', 'mụn', 'trứng', 'cá', '.', 'xxmaj', 'nhiễm', 'trùng', 'này', 'gây', 'viêm', 'và', 'sự', 'phát', 'triển', 'của', 'mủ', '.', 'xxup', 'có', 'một', 'tình', 'trạng', 'da', 'được', 'được', 'phân', 'loại', 'là', 'mụn', 'trứng', 'cá', 'hay', 'không', 'còn', 'phụ', 'thuộc', 'vào', 'số', 'lượng', 'mụn', 'có', 'nhân', 'và', 'nhiễm', 'trùng', '.', 'xxmaj', 'mụn', 'có', 'nhân', 'không', 'nên', 'nhầm', 'lẫn', 'với', 'dạng', 'các', 'sợi', 'bã', 'nhờn', '(', 'sebaceous', 'filament', ')', '.', '\\n\\n', 'xxmaj', 'ung', 'thư', 'biểu', 'mô', 'ống', 'thể', 'xxmaj', 'comedo', 'tại', 'chỗ', '(', 'dcis', ')', 'không', 'liên', 'quan', 'đến', 'các', 'tình', 'trạng', 'da', 'được', 'thảo', 'luận', 'ở', 'đây', '.', 'xxup', 'dcis', 'là', 'một', 'dạng', 'ung', 'thư', 'vú', 'không', 'xâm', 'lấn', ',', 'nhưng', 'xxup', 'dcis', 'loại', 'comedo', 'có', 'thể', 'tấn', 'công', 'nhiều', 'hơn', 'và', 'do', 'đó', 'có', 'thể', 'dễ', 'bị', 'xâm', 'lấn', 'hơn', '.', '\\n\\n', 'xxup', 'sự', 'tăng', 'tiết', 'dầu', 'ở', 'tuyến', 'bã', 'nhờn', 'tăng', 'lên', 'ở', 'tuổi', 'dậy', 'thì', ',', 'gây', 'ra', 'tắc', 'nang', 'lông', 'và', 'mụn', 'trứng', 'cá', 'thường', 'gặp', 'ở', 'thanh', 'thiếu', 'niên', '.', 'xxmaj', 'mụn', 'trứng', 'cá', 'cũng', 'được', 'nhận', 'thấy', 'trong', 'thời', 'điểm', 'tiền', 'kinh', 'nguyệt', 'và', 'ở', 'những', 'phụ', 'nữ', 'mắc', 'hội', 'chứng', 'buồng', 'trứng', 'đa', 'nang', '.', 'xxmaj', 'hút', 'thuốc', 'có', 'thể', 'làm', 'tình', 'trạng', 'mụn', 'nặng', 'hơn', '.', '\\n\\n', 'ôxy', 'hóa', 'chứ', 'không', 'phải', 'vệ', 'sinh', 'kém', 'hay', 'bụi', 'bẩn', 'dẫn', 'đến', 'mụn', 'đầu', 'đen', 'bị', 'đen', 'đầu', '.', 'xxmaj', 'việc', 'rửa', 'hoặc', 'chà', 'xát', 'da', 'quá', 'nhiều', 'có', 'thể', 'làm', 'nặng', 'thêm', 'do', 'kích', 'ứng', 'da', '.', 'xxmaj', 'chạm', 'và', 'nặn', 'nhân', 'mụn', 'có', 'thể', 'gây', 'kích', 'ứng', 'và', 'viêm', 'nhiễm', 'lan', 'rộng', '.', 'xxmaj', 'không', 'rõ', 'việc', 'cạo', 'râu', 'có', 'ảnh', 'hưởng', 'gì', 'đến', 'sự', 'phát', 'triển', 'của', 'việc', 'hình', 'thành', 'nhân', 'mụn', 'hay', 'mụn', 'trứng', 'cá', '.', '\\n\\n', 'xxmaj', 'một', 'số', 'nhưng', 'không', 'phải', 'tất', 'cả', ',', 'các', 'sản', 'phẩm', 'cho', 'da', 'có', 'thể', 'làm', 'tăng', 'nhân', 'mụn', 'do', 'bít', 'kín', 'lỗ', 'chân', 'lông', 'và', 'các', 'sản', 'phẩm', 'làm', 'trơn', 'dành', 'cho', 'tóc', '(', 'như', 'pomade', ')', 'có', 'thể', 'làm', 'nặng', 'thêm', 'tình', 'trạng', 'mụn', 'trứng', 'cá', '.', 'xxmaj', 'những', 'sản', 'phẩm', 'dành', 'cho', 'da', 'tuyên', 'bố', 'không', 'làm', 'tắc', 'nghẽn', 'nang', 'lông', 'có', 'thể', 'được', 'dán', 'nhãn', 'không', 'gây', 'bít', 'tắc', 'lỗ', 'chân', 'lông', 'hoặc', 'không', 'gây', 'mụn', '.', 'xxmaj', 'các', 'sản', 'phẩm', 'cho', 'da', 'và', 'đồ', 'trang', 'điểm', 'không', 'chứa', 'dầu', ',', 'có', 'gốc', 'nước', 'rất', 'có', 'thể', 'ít', 'gây', 'mụn', 'trứng', 'cá', '.', 'xxmaj', 'người', 'ta', 'không', 'chắc', 'liệu', 'rằng', 'các', 'yếu', 'tố', 'trong', 'chế', 'độ', 'ăn', 'kiêng', 'hoặc', 'tiếp', 'xúc', 'với', 'ánh', 'nắng', 'mặt', 'trời', 'có', 'làm', 'mụn', 'nhân', 'tốt', 'lên', ',', 'tệ', 'hơn', 'hay', 'không', 'ảnh', 'hưởng', 'hay', 'không', '.', '\\n\\n', 'xxmaj', 'một', 'sợi', 'lông', 'mọc', 'bất', 'thường', ',', 'lông', 'mọc', 'ngược', ',', 'có', 'thể', 'bít', 'lỗ', 'chân', 'lông', 'và', 'gây', 'phồng', 'hoặc', 'dẫn', 'đến', 'nhiễm', 'trùng', '(', 'gây', 'viêm', 'và', 'mủ', ')', '.', '\\n\\n', 'xxmaj', 'mội', 'vài', 'gen', 'có', 'thể', 'đóng', 'vai', 'trò', 'trong', 'nguy', 'cơ', 'phát', 'triển', 'mụn', 'trứng', 'cá', '.', 'xxmaj', 'nhân', 'mụn', 'có', 'thể', 'phổ', 'biến', 'hơn', 'ở', 'một', 'số', 'nhóm', 'chủng', 'tộc', '.', 'xxmaj', 'người', 'gốc', 'xxmaj', 'châu', 'xxmaj', 'phi', 'gần', 'đây', 'có', 'thể', 'gặp', 'phải', 'tình', 'trạng', 'viêm', 'tắc', 'lỗ', 'chân', 'lông', 'hơn', ',', 'mụn', 'trứng', 'cá', 'nhân', 'hơn', ',', 'khởi', 'phát', 'tình', 'trạng', 'viêm', 'sớm', 'hơn', '.']\n",
      "    applying Tokenizer gives\n",
      "      ['xxbos', 'xxmaj', 'nhân', 'mụn', '\\n\\n', 'xxmaj', 'nhân', 'mụn', '(', 'tiếng', 'xxmaj', 'anh', ':', '\"', 'comedo', '\"', ';', '\"', 'conmedones', '\"', ')', 'là', 'tình', 'trạnh', 'một', 'nang', 'lông', '(', 'lỗ', 'chân', 'lông', ')', 'trên', 'da', 'bị', 'bít', 'tắc', '.', 'xxmaj', 'keratin', '(', 'mảnh', 'vụn', 'da', ')', 'kết', 'hợp', 'với', 'dầu', 'thừa', 'trên', 'da', 'khóa', 'kín', 'nang', 'lông', '.', 'xxmaj', 'nhân', 'mụn', 'trứng', 'cá', 'có', 'thể', 'ở', 'dạng', 'mở', '(', 'mụn', 'đầu', 'đen', ')', 'hoặc', 'bị', 'da', 'đóng', 'kín', '(', 'mụn', 'đầu', 'trắng', ')', 'và', 'dẫn', 'đến', 'tình', 'trạng', 'mụn', 'trứng', 'cá', 'hoặc', 'không', '.', 'xxup', 'từ', '\"', 'comedo', '\"', 'bắt', 'nguồn', 'từ', 'tiếng', 'xxmaj', 'latin', '\"', 'comedere', '\"', 'có', 'nghĩa', 'là', \"'\", 'ăn', 'hết', \"'\", ',', 'trước', 'kia', 'được', 'sử', 'dụng', 'để', 'mô', 'tả', 'giun', 'ký', 'sinh', ';', 'trong', 'thuật', 'ngữ', 'y', 'học', 'hiện', 'đại', ',', 'nó', 'được', 'dùng', 'để', 'liên', 'tưởng', 'sự', 'xuất', 'hiện', 'của', 'loài', 'vật', 'kí', 'sinh', 'dạng', 'giống', 'ấu', 'trùng', '.', '\\n\\n', 'xxmaj', 'tình', 'trạng', 'viêm', 'da', 'mãn', 'tính', 'thường', 'xuất', 'hiện', 'gồm', 'có', 'các', 'nốt', 'mụn', 'nhân', ',', 'mụn', 'sẩn', 'viêm', '(', 'inflamed', 'papules', ')', 'và', 'các', 'nốt', 'mụn', 'mủ', '(', 'pustules', 'hoặc', 'pimples', ')', 'được', 'gọi', 'là', 'mụn', 'trứng', 'cá', '.', 'xxmaj', 'nhiễm', 'trùng', 'này', 'gây', 'viêm', 'và', 'sự', 'phát', 'triển', 'của', 'mủ', '.', 'xxup', 'có', 'một', 'tình', 'trạng', 'da', 'được', 'được', 'phân', 'loại', 'là', 'mụn', 'trứng', 'cá', 'hay', 'không', 'còn', 'phụ', 'thuộc', 'vào', 'số', 'lượng', 'mụn', 'có', 'nhân', 'và', 'nhiễm', 'trùng', '.', 'xxmaj', 'mụn', 'có', 'nhân', 'không', 'nên', 'nhầm', 'lẫn', 'với', 'dạng', 'các', 'sợi', 'bã', 'nhờn', '(', 'sebaceous', 'filament', ')', '.', '\\n\\n', 'xxmaj', 'ung', 'thư', 'biểu', 'mô', 'ống', 'thể', 'xxmaj', 'comedo', 'tại', 'chỗ', '(', 'dcis', ')', 'không', 'liên', 'quan', 'đến', 'các', 'tình', 'trạng', 'da', 'được', 'thảo', 'luận', 'ở', 'đây', '.', 'xxup', 'dcis', 'là', 'một', 'dạng', 'ung', 'thư', 'vú', 'không', 'xâm', 'lấn', ',', 'nhưng', 'xxup', 'dcis', 'loại', 'comedo', 'có', 'thể', 'tấn', 'công', 'nhiều', 'hơn', 'và', 'do', 'đó', 'có', 'thể', 'dễ', 'bị', 'xâm', 'lấn', 'hơn', '.', '\\n\\n', 'xxup', 'sự', 'tăng', 'tiết', 'dầu', 'ở', 'tuyến', 'bã', 'nhờn', 'tăng', 'lên', 'ở', 'tuổi', 'dậy', 'thì', ',', 'gây', 'ra', 'tắc', 'nang', 'lông', 'và', 'mụn', 'trứng', 'cá', 'thường', 'gặp', 'ở', 'thanh', 'thiếu', 'niên', '.', 'xxmaj', 'mụn', 'trứng', 'cá', 'cũng', 'được', 'nhận', 'thấy', 'trong', 'thời', 'điểm', 'tiền', 'kinh', 'nguyệt', 'và', 'ở', 'những', 'phụ', 'nữ', 'mắc', 'hội', 'chứng', 'buồng', 'trứng', 'đa', 'nang', '.', 'xxmaj', 'hút', 'thuốc', 'có', 'thể', 'làm', 'tình', 'trạng', 'mụn', 'nặng', 'hơn', '.', '\\n\\n', 'ôxy', 'hóa', 'chứ', 'không', 'phải', 'vệ', 'sinh', 'kém', 'hay', 'bụi', 'bẩn', 'dẫn', 'đến', 'mụn', 'đầu', 'đen', 'bị', 'đen', 'đầu', '.', 'xxmaj', 'việc', 'rửa', 'hoặc', 'chà', 'xát', 'da', 'quá', 'nhiều', 'có', 'thể', 'làm', 'nặng', 'thêm', 'do', 'kích', 'ứng', 'da', '.', 'xxmaj', 'chạm', 'và', 'nặn', 'nhân', 'mụn', 'có', 'thể', 'gây', 'kích', 'ứng', 'và', 'viêm', 'nhiễm', 'lan', 'rộng', '.', 'xxmaj', 'không', 'rõ', 'việc', 'cạo', 'râu', 'có', 'ảnh', 'hưởng', 'gì', 'đến', 'sự', 'phát', 'triển', 'của', 'việc', 'hình', 'thành', 'nhân', 'mụn', 'hay', 'mụn', 'trứng', 'cá', '.', '\\n\\n', 'xxmaj', 'một', 'số', 'nhưng', 'không', 'phải', 'tất', 'cả', ',', 'các', 'sản', 'phẩm', 'cho', 'da', 'có', 'thể', 'làm', 'tăng', 'nhân', 'mụn', 'do', 'bít', 'kín', 'lỗ', 'chân', 'lông', 'và', 'các', 'sản', 'phẩm', 'làm', 'trơn', 'dành', 'cho', 'tóc', '(', 'như', 'pomade', ')', 'có', 'thể', 'làm', 'nặng', 'thêm', 'tình', 'trạng', 'mụn', 'trứng', 'cá', '.', 'xxmaj', 'những', 'sản', 'phẩm', 'dành', 'cho', 'da', 'tuyên', 'bố', 'không', 'làm', 'tắc', 'nghẽn', 'nang', 'lông', 'có', 'thể', 'được', 'dán', 'nhãn', 'không', 'gây', 'bít', 'tắc', 'lỗ', 'chân', 'lông', 'hoặc', 'không', 'gây', 'mụn', '.', 'xxmaj', 'các', 'sản', 'phẩm', 'cho', 'da', 'và', 'đồ', 'trang', 'điểm', 'không', 'chứa', 'dầu', ',', 'có', 'gốc', 'nước', 'rất', 'có', 'thể', 'ít', 'gây', 'mụn', 'trứng', 'cá', '.', 'xxmaj', 'người', 'ta', 'không', 'chắc', 'liệu', 'rằng', 'các', 'yếu', 'tố', 'trong', 'chế', 'độ', 'ăn', 'kiêng', 'hoặc', 'tiếp', 'xúc', 'với', 'ánh', 'nắng', 'mặt', 'trời', 'có', 'làm', 'mụn', 'nhân', 'tốt', 'lên', ',', 'tệ', 'hơn', 'hay', 'không', 'ảnh', 'hưởng', 'hay', 'không', '.', '\\n\\n', 'xxmaj', 'một', 'sợi', 'lông', 'mọc', 'bất', 'thường', ',', 'lông', 'mọc', 'ngược', ',', 'có', 'thể', 'bít', 'lỗ', 'chân', 'lông', 'và', 'gây', 'phồng', 'hoặc', 'dẫn', 'đến', 'nhiễm', 'trùng', '(', 'gây', 'viêm', 'và', 'mủ', ')', '.', '\\n\\n', 'xxmaj', 'mội', 'vài', 'gen', 'có', 'thể', 'đóng', 'vai', 'trò', 'trong', 'nguy', 'cơ', 'phát', 'triển', 'mụn', 'trứng', 'cá', '.', 'xxmaj', 'nhân', 'mụn', 'có', 'thể', 'phổ', 'biến', 'hơn', 'ở', 'một', 'số', 'nhóm', 'chủng', 'tộc', '.', 'xxmaj', 'người', 'gốc', 'xxmaj', 'châu', 'xxmaj', 'phi', 'gần', 'đây', 'có', 'thể', 'gặp', 'phải', 'tình', 'trạng', 'viêm', 'tắc', 'lỗ', 'chân', 'lông', 'hơn', ',', 'mụn', 'trứng', 'cá', 'nhân', 'hơn', ',', 'khởi', 'phát', 'tình', 'trạng', 'viêm', 'sớm', 'hơn', '.']\n",
      "    applying Numericalize gives\n",
      "      TensorText of size 726\n",
      "\n",
      "Final sample: (TensorText([    2,     8,    90,  2952,    17,     8,    90,  2952,    24,   172,\n",
      "            8,    77,    61,    13, 13801,    13,   157,    13,     0,    13,\n",
      "           23,    14,   256,     0,    16,  2898,  1296,    24,  1328,   649,\n",
      "         1296,    23,    58,   957,    53,  5871,  1173,    10,     8,     0,\n",
      "           24,  1709,  4104,   957,    23,   152,   118,    25,  1101,   797,\n",
      "           58,   957,  1019,  1925,  2898,  1296,    10,     8,    90,  2952,\n",
      "         1216,   403,    20,    50,    29,   550,   431,    24,  2952,    43,\n",
      "          934,    23,   177,    53,   957,   470,  1925,    24,  2952,    43,\n",
      "          909,    23,    11,   371,    36,   256,   787,  2952,  1216,   403,\n",
      "          177,    32,    10,     7,    33,    13, 13801,    13,   173,   522,\n",
      "           33,   172,     8,  2527,    13,     0,    13,    20,   268,    14,\n",
      "          656,   440,   564,   656,     9,   109,  1421,    15,    99,   110,\n",
      "           46,   513,   657,  2087,   487,   125,   157,    19,   332,   567,\n",
      "          652,    73,    74,    69,     9,    80,    15,   347,    46,   136,\n",
      "          637,    47,   106,    74,    12,   437,   186,  3292,   125,   550,\n",
      "          373,  2218,   800,    10,    17,     8,   256,   787,  1879,   957,\n",
      "         1373,   175,   153,   106,    74,   187,    20,    18,  2502,  2952,\n",
      "           90,     9,  2952,     0,  1879,    24,     0,     0,    23,    11,\n",
      "           18,  2502,  2952, 17219,    24,     0,   177,     0,    23,    15,\n",
      "          200,    14,  2952,  1216,   403,    10,     8,  1195,   800,    37,\n",
      "          489,  1879,    11,    47,    85,   305,    12, 17219,    10,     7,\n",
      "           20,    16,   256,   787,   957,    15,    15,   297,   206,    14,\n",
      "         2952,  1216,   403,   243,    32,    97,   383,   183,    28,    55,\n",
      "          155,  2952,    20,    90,    11,  1195,   800,    10,     8,  2952,\n",
      "           20,    90,    32,   227,  1869,  1059,    25,   550,    18,  1609,\n",
      "         4526,  5558,    24,     0,     0,    23,    10,    17,     8,  1413,\n",
      "          492,   426,   513,  1363,    50,     8, 13801,    42,   985,    24,\n",
      "        17220,    23,    32,   136,    93,    36,    18,   256,   787,   957,\n",
      "           15,   993,   639,    29,   205,    10,     7, 17220,    14,    16,\n",
      "          550,  1413,   492,  1894,    32,  1030,  2820,     9,   100,     7,\n",
      "        17220,   206, 13801,    20,    50,   327,    39,    64,    98,    11,\n",
      "           92,    44,    20,    50,   918,    53,  1030,  2820,    98,    10,\n",
      "           17,     7,    47,   312,   665,  1101,    29,   648,  4526,  5558,\n",
      "          312,   159,    29,   369,  1240,   220,     9,   489,    49,  1173,\n",
      "         2898,  1296,    11,  2952,  1216,   403,   153,   611,    29,   323,\n",
      "          669,   561,    10,     8,  2952,  1216,   403,    60,    15,   141,\n",
      "          269,    19,    75,   214,   321,   241,  2356,    11,    29,    30,\n",
      "          383,   316,  1233,   102,   468,  2549,  1216,   605,  2898,    10,\n",
      "            8,  1198,   881,    20,    50,    68,   256,   787,  2952,   767,\n",
      "           98,    10,    17,  4080,   226,  1460,    32,   123,   446,   125,\n",
      "         1259,   243,  2064,  3376,   371,    36,  2952,    43,   934,    53,\n",
      "          934,    43,    10,     8,    72,  2464,   177,  8023,  4940,   957,\n",
      "          401,    64,    20,    50,    68,   767,   485,    92,   551,   399,\n",
      "          957,    10,     8,  1364,    11,     0,    90,  2952,    20,    50,\n",
      "          489,   551,   399,    11,  1879,  1195,   366,   452,    10,     8,\n",
      "           32,   708,    72,  6049,  4553,    20,   322,   512,   719,    36,\n",
      "           47,    85,   305,    12,    72,   108,    31,    90,  2952,   243,\n",
      "         2952,  1216,   403,    10,    17,     8,    16,    55,   100,    32,\n",
      "          123,   414,   113,     9,    18,   167,   333,    26,   957,    20,\n",
      "           50,    68,   312,    90,  2952,    92,  5871,  1925,  1328,   649,\n",
      "         1296,    11,    18,   167,   333,    68,  3001,   730,    26,  1110,\n",
      "           24,    51,     0,    23,    20,    50,    68,   767,   485,   256,\n",
      "          787,  2952,  1216,   403,    10,     8,    30,   167,   333,   730,\n",
      "           26,   957,   559,   379,    32,    68,  1173,  4349,  2898,  1296,\n",
      "           20,    50,    15,  3811,  1938,    32,   489,  5871,  1173,  1328,\n",
      "          649,  1296,   177,    32,   489,  2952,    10,     8,    18,   167,\n",
      "          333,    26,   957,    11,   600,   319,   214,    32,   893,  1101,\n",
      "            9,    20,   662,    96,   231,    20,    50,   552,   489,  2952,\n",
      "         1216,   403,    10,     8,    27,   330,    32,  1201,   455,   107,\n",
      "           18,   413,   765,    19,   279,   126,   440,  4359,   177,   115,\n",
      "         1116,    25,   975,  2896,   239,   947,    20,    68,  2952,    90,\n",
      "          542,   159,     9,  1394,    98,   243,    32,   322,   512,   243,\n",
      "           32,    10,    17,     8,    16,  1609,  1296,  1899,   387,   153,\n",
      "            9,  1296,  1899,   995,     9,    20,    50,  5871,  1328,   649,\n",
      "         1296,    11,   489,  5703,   177,   371,    36,  1195,   800,    24,\n",
      "          489,  1879,    11, 17219,    23,    10,    17,     8,     0,   664,\n",
      "         1754,    20,    50,   470,   444,   500,    19,   954,   146,    85,\n",
      "          305,  2952,  1216,   403,    10,     8,    90,  2952,    20,    50,\n",
      "          606,   396,    98,    29,    16,    55,   348,   970,   536,    10,\n",
      "            8,    27,   662,     8,   234,     8,   434,   370,   205,    20,\n",
      "           50,   611,   123,   256,   787,  1879,  1173,  1328,   649,  1296,\n",
      "           98,     9,  2952,  1216,   403,    90,    98,     9,   717,    85,\n",
      "          256,   787,  1879,  1002,    98,    10]),)\n",
      "\n",
      "\n",
      "Collecting items from                     fname  \\\n",
      "0             Doug Emhoff   \n",
      "1         HMS Myngs (R06)   \n",
      "2        Xuân La (phường)   \n",
      "3     Cung điện Goldstein   \n",
      "4         Tứ khố toàn thư   \n",
      "...                   ...   \n",
      "1995       Viva World Cup   \n",
      "1996     Nguyên lý Pareto   \n",
      "1997        Moshe Rynecki   \n",
      "1998  Ngựa Selle Français   \n",
      "1999       Takahashi Juri   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         text  \n",
      "0     Doug Emhoff\\n\\nDouglas Craig Emhoff (sinh ngày 13 tháng 10 năm 1964) là một luật sư người Mỹ và là chồng của Phó Tổng thống đắc cử Kamala Harris. Ông sẽ trở thành \"Đệ nhị Phu quân\" đầu tiên trong lịch sử Mỹ và là người phối ngẫu gốc Do Thái đầu tiên của một phó tổng thống.\\n\\nEmhoff sinh ra tại quận Brooklyn của Thành phố New York, là con trai của bố mẹ gốc Do Thái là bà Barbara (nhũ danh Kanzer) và ông Michael Emhoff. Ông có một anh trai là Andy Emhoff và một em gái là Jamie Emhoff. Ông sống ở New Jersey từ năm 1969 đến năm 1981 trước khi cùng gia đình chuyển đến California năm 17 tuổi. E...  \n",
      "1     HMS Myngs (R06)\\n\\nHMS \"Myngs\" (R06/D06) là một soái hạm khu trục dẫn đầu lớp tàu khu trục Z của Hải quân Hoàng gia Anh Quốc được chế tạo trong Chiến tranh Thế giới thứ hai. Sống sót qua cuộc xung đột, nó được đưa về lực lượng dự bị năm 1954 và dự định cải biến thành một tàu frigate, nhưng lại được bán cho Ai Cập năm 1955 và tiếp tục phục vụ như là chiếc \"El Qaher\". Nó bị máy bay Israel đánh chìm năm 1970.\\n\\n\"Myngs\" được đặt hàng vào tháng 2 năm 1942 như một phần của Chi hạm đội Khẩn cấp 10, và được chế tạo tại xưởng tàu của hãng Vickers-Armstrong ở Tyneside. Nó được đặt lườn vào ngày 27 ...  \n",
      "2     Xuân La (phường)\\n\\nXuân La là một phường trực thuộc quận Tây Hồ, thành phố Hà Nội, Việt Nam.\\n\\nPhường Xuân La nằm ở phía tây của hồ Tây. Đây là vùng đất cổ của Hà Nội, nổi tiếng với các ngôi chùa: Khai Nguyên, Thiên Niên, Vạn Niên, Ức Niên.\\n\\n\\nNăm 1995, phường Xuân La có diện tích 217,7 hécta và dân số 6.386 người.\\n\\nNăm 2009, phường này có diện tích là 235,074 ha và dân số 18.903 người.\\n\\nXã Xuân La được thành lập trong thời kì kháng chiến chống Pháp trên cơ sở sáp nhập các làng Quán La xã, Quán La sở, Xuân Tảo sở và Vệ Hồ. Khi thành lập, xã Xuân La thuộc quận Lãng Bạc, sau thuộc hu...  \n",
      "3     Cung điện Goldstein\\n\\nCung điện Goldstein hay còn được gọi là Biệt thự Goldstein hoặc Cung điện Przemysłowców, là một tòa nhà có kiến trúc Neo-Renaissance (kiến trúc Phục hưng của Ý) nằm ở phía tây của trung tâm thành phố Katowice, ngay ở góc của Quảng trường Wolności và đường Jana Matejki.\\n\\nCung điện Goldstein được xây dựng vào năm 1872 bởi anh em Abraham và Józef Goldstein, những người Do Thái giàu có đến từ lãnh thổ của phân vùng Nga, người đã làm kinh doanh ở Górnym Śląsku một thời gian. Họ đến Katowice với tư cách là những người buôn gỗ và thành lập chuỗi xưởng cưa. Ngoài việc điều...  \n",
      "4     Tứ khố toàn thư\\n\\nTứ khố toàn thư (tiếng Trung: 四庫全書) là bách khoa lớn nhất trong lịch sử phong kiến Trung Quốc. Nó được Hoàng đế Càn Long nhà Thanh giao cho 361 học giả, đứng đầu là Kỉ Quân và Lục Tích Hùng, biên soạn trong khoảng thời gian từ 1773 đến 1782, nó đã trải qua vô vàn sóng gió cùng với máu tanh vì trong thời gian này chế độ vua chúa nhà Thanh bớ gắt gao những người có tư tưởng phản Thanh phục Minh dù là trong thơ ca. Với 4 phần lớn là Kinh (經), Sử (史), Tử (子), Tập (集), \"Tứ khố toàn thư\" đã tập hợp trên 10.000 bản thảo từ các bộ sưu tập của những triều đại phong kiến Trung Quố...  \n",
      "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...  \n",
      "1995  Viva World Cup\\n\\nVIVA World cup là giải đấu được tổ chức bởi NF-Board 2 năm 1 lần. Các đội tham dự giải là những đội tuyển quốc gia không phải là thành viên của FIFA.\\n\\nVào tháng 5 năm 2005, NF Board thông báo thành viên Bắc Síp sẽ là chủ nhà giải đấu để kỷ niệm 50 năm thành lập của thành viên này. Tuy nhiên, vì nhiều lý do, NF Board đã chuyển giải đấu sang cho thành viên Occitania (1 vùng nằm ở Nam Âu). 6 đội tham dự là Monaco, Sápmi, Nam Cameroon, Tây Papua (vùng), đội của người Roman. Tuy nhiên, vì nhiều lý do chỉ còn lại Monaco, Sapmi và chủ nhà tham dự. Nam Cameroon cũng tham dự như...  \n",
      "1996  Nguyên lý Pareto\\n\\nQuy luật Pareto hay quy luật 80/20 (quy luật thiểu số quan trọng và phân bố nhân tố) nói rằng trong nhiều sự kiện, khoảng 80% kết quả là do 20% nguyên nhân gây ra. Nhà tư tưởng quản trị doanh nghiệp Joseph M. Juran đề xuất quy luật này và đặt theo tên của nhà kinh tế người Ý Vilfredo Pareto người đã quan sát 80% đất ở Ý là thuộc sở hữu của 20% dân số. Đây cũng là quy luật phổ biến trong kinh doanh chẳng hạn 80% doanh thu là từ 20% trong số các khách hàng.\\n\\nKhi xét một thứ gì được sở hữu bởi một số lượng lớn vừa đủ người thì luôn tồn tại một số k (50 < k < 100) sao cho...  \n",
      "1997  Moshe Rynecki\\n\\nMoshe Rynecki (, \"Mosheh Rynetski\"; sinh năm 1881 - mất năm 1943) là một họa sĩ người Ba Lan gốc Do Thái. Ông sinh ra trong một gia đình sùng đạo tại Międzyrzec Podlaski, Ba Lan. Cha mẹ ông có 18 người con. Ông là một trong năm người con còn sống của họ. Những người con khác mất lúc còn bé do mắc nhiều loại bệnh khác nhau.\\n\\nMoshe Rynecki bắt đầu vẽ tranh từ khi còn nhỏ. Theo lời kể của gia đình, ông thường dùng phấn hoặc đôi khi dùng sơn, nếu có, để vẽ lên sàn và tường nhà. Trong cuốn hồi ký của con trai ông, George, \"Chưa lần nào ông bị đánh vì không vâng lời căn dặn củ...  \n",
      "1998  Ngựa Selle Français\\n\\nNgựa Selle Français (viết tắt SF) là một giống ngựa của môn thể thao đua ngựa có nguồn tốc từ Pháp. Nó được nổi tiếng chủ yếu cho sự thành công của giống ngựa này trong chương trình thi nhảy. Một con ngựa thể thao thon gọn với màu hạt dẻ. \\nNgựa Selle Français đã được lai tạo ra vào năm 1958 khi một số giống ngựa cưỡi Pháp đã được sáp nhập. Các giống mới được có nghĩa là để phục vụ như là một con ngựa thể thao thống nhất trong một khoảng thời gian khi con ngựa đã được thay thế bằng cơ giới hóa và được chuyển vào một vật được sử dụng chủ yếu cho các môn thể thao và gi...  \n",
      "1999  Takahashi Juri\\n\\nQua việc cô được chọn làm thực tập sinh của Woolim Entertainment, và hiện đang hoạt động dưới nhóm nhạc Rocket Punch cùng công ty vào tháng 8 năm 2019..\\n\\nTakahashi Juri đã vượt qua vòng thi thử giọng tuyển thành viên thứ 12 của AKB48 vào ngày 20 tháng 2 năm 2011. Cô được chuyển lên Team 4 vào tháng 3 năm 2012 (Saitama Super Arena), nhưng sau đó chuyển về Team A vào tháng 8 năm 2012 (Tokyo Dome Team Shuffle). Tại AKB48 Group Shuffle vào tháng 2 năm 2014, Takahashi Juri chuyển sang trở thành thành viên của Team B. Trong kì (AKB48 Spring Shuffle 2015), Takahashi Juri được ...  \n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "Found 2000 items\n",
      "2 datasets of sizes 1600,400\n",
      "Setting up Pipeline: ColReader -- {'cols': 'text', 'pref': '', 'suff': '', 'label_delim': None} -> Tokenizer -> Numericalize\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up after_item: Pipeline: ToTensor\n",
      "Setting up before_batch: Pipeline: \n",
      "Setting up after_batch: Pipeline: \n",
      "\n",
      "Building one batch\n",
      "Applying item_tfms to the first sample:\n",
      "  Pipeline: ToTensor\n",
      "    starting from\n",
      "      (TensorText of size 726)\n",
      "    applying ToTensor gives\n",
      "      (TensorText of size 726)\n",
      "\n",
      "Adding the next 1 samples\n",
      "\n",
      "No before_batch transform to apply\n",
      "\n",
      "Collating items in a batch\n",
      "Error! It's not possible to collate your items in a batch\n",
      "Could not collate the 0-th members of your tuples because got the following shapes\n",
      "(726,),(2872,)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [726] at entry 0 and [2872] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ef893dd1ebd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvnmese_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/kwon/nlp/fastai2_nlp/fastai/data/block.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, source, bs, show_batch, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mwhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_fail_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Make sure all parts of your samples are tensors of the same size\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwhy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mwhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'noop'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kwon/nlp/fastai2_nlp/fastai/data/block.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, source, bs, show_batch, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nCollating items in a batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretain_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kwon/nlp/fastai2_nlp/fastai/data/load.py\u001b[0m in \u001b[0;36mcreate_batch\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mretain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0mretain_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfa_collate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfa_convert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprebatched\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kwon/nlp/fastai2_nlp/fastai/data/load.py\u001b[0m in \u001b[0;36mfa_collate\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     return (default_collate(t) if isinstance(b, _collate_types)\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32melse\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfa_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             else default_collate(t))\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kwon/nlp/fastai2_nlp/fastai/data/load.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     return (default_collate(t) if isinstance(b, _collate_types)\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32melse\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfa_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             else default_collate(t))\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kwon/nlp/fastai2_nlp/fastai/data/load.py\u001b[0m in \u001b[0;36mfa_collate\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;34m\"A replacement for PyTorch `default_collate` which maintains types and handles `Sequence`s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     return (default_collate(t) if isinstance(b, _collate_types)\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfa_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             else default_collate(t))\n",
      "\u001b[0;32m~/anaconda3/envs/fastai_v2/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kwon/nlp/fastai2_nlp/fastai/torch_core.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;31m#         if func.__name__[0]!='_': print(func, types, args, kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;31m#         with torch._C.DisableTorchFunction(): ret = _convert(func(*args, **(kwargs or {})), self.__class__)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__torch_function__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai_v2/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 995\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    996\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [726] at entry 0 and [2872] at entry 1"
     ]
    }
   ],
   "source": [
    "# vnmese_lm.summary(result_df, bs=2)\n",
    "# TODO: in LM, for some reason the sequences in a batch aren’t padded to be of equal length \n",
    "# while making a LM. I know they are made equal when building the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note! The tokenizer here, is it suitable for other language such as Vietnamese?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Study LM dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.data.core.DataLoaders"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17280"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xxunk', 'xxpad', 'xxbos', 'xxeos', 'xxfld', 'xxrep', 'xxwrep', 'xxup', 'xxmaj', ',', '.', 'và', 'của', '\"', 'là', 'được', 'một', '\\n\\n', 'các', 'trong', 'có', 'năm', 'đã', ')', '(', 'với', 'cho', 'người', 'vào', 'ở', 'những', 'thành', 'không', 'từ', 'tháng', 'khi', 'đến', 'này', 'ngày', 'công', '-', 'sau', 'tại', 'đầu', 'đó', 'ông', 'để', 'sự', 'về', 'ra', 'thể', 'như', 'quốc', 'bị', 'chính', 'số', 'quân', 'lại', 'trên', 'nhà', 'cũng', ':', 'nam', 'gia', 'nhiều', 'trung', 'theo', 'bộ', 'làm', 'đại', 'động', 'nhất', 'việc', 'học', 'hiện', 'thời', 'chiến', 'anh', 'hai', '3', 'nó', 'cùng', 'chỉ', 'thế', 'con', 'phát', 'bản', 'khác', 'định', 'đồng', 'nhân', 'dân', 'do', 'quan', 'họ', 'hành', 'nước', 'còn', 'hơn', 'sử']\n"
     ]
    }
   ],
   "source": [
    "print(dls.vocab[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cdi', 'lignin', 'hoai', 'surabaja', 'heitler', 'hewett', 'whitten', 'sackets', 'fulton', 'colchinium', 'mng', 'volodymyr', 'macaire', 'garneau', 'asi', 'yanqui', 'u.x.o', 'plc', 'tnr', 'satchō', 'vờn', 'ahli', 'maleate', 'galsworthy', 'aoun', 'chamillionaire', 'tu-22m3', 'chievo', 'e13', 'cauca', 'uribe', 'rojas', 'lleras', 'sarir', 'cargo', 'tunner', 'sabado', 'roto', 'palo', 'mủ', 'dcis', 'milovan', 'spn', 'akane', 'yasu', 'bcg', 'mantoux', 'x5', 'ichthyopsida', 'adreno', 'processor', '617', 'chamakh', 'pacman', 'turya', 'dromostanolone', 'virilization', '2α', 'undong', 'platinumgames', 'noatun', 'rodin', 'otero', 'briand', 'complementary', 'polysilicon', 'hecht', 'upstate', 'catawba', 'mays', 'amber', 'mahaffey', 'coefficient', 'ginoza', 'kagari', 'shogo', 'ubukata', 'fukami', 'hayakawa', 'doping', 'paulina', 'porizkova', 'bottom', 'antm', 'samatha', 'dd25', 'ops-50', 'mk-15', 'hajar', 'khayyám', 'woodbridge', 'lanna', 'cagayan', 'province', 'ifugao', 'sápmi', 'perla', 'facteur', 'aqps', 'xxfake']\n"
     ]
    }
   ],
   "source": [
    "print(dls.vocab[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<fastai.text.data.LMDataLoader at 0x7f09d46b34f0>,\n",
       " <fastai.text.data.LMDataLoader at 0x7f08cec90a00>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.train,dls.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y = dls.train.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 72)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape # (bs,bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LMTensorText([[   2,  645,    8,  ..., 1663,  111,   31],\n",
       "        [   7,  112,   46,  ...,   32,  183,  840],\n",
       "        [  11,   18,   67,  ...,   11,  624,  181],\n",
       "        ...,\n",
       "        [1300,    8, 1625,  ...,    2,    8,  244],\n",
       "        [ 630, 1067,   10,  ...,    8,  191,   32],\n",
       "        [ 367,  290,  258,  ..., 2723,   22,   68]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x # LMTensorText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(fastai.text.data.LMTensorText, 'torch.cuda.LongTensor')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x),x.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 72)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorText([[ 645,    8,   85,  ...,  111,   31,  146],\n",
       "        [ 112,   46,   36,  ...,  183,  840,    8],\n",
       "        [  18,   67,  467,  ...,  624,  181,  119],\n",
       "        ...,\n",
       "        [   8, 1625,    7,  ...,    8,  244, 1348],\n",
       "        [1067,   10,    7,  ...,  191,   32,  290],\n",
       "        [ 290,  258,  322,  ...,   22,   68,   39]], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y # move each row of x to the right by 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "check bptt (seq_len) size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp_i = iter(dls.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 72]) torch.Size([128, 72])\n"
     ]
    }
   ],
   "source": [
    "temp_x,temp_y = next(temp_i)\n",
    "print(temp_x.shape,temp_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 72]) torch.Size([128, 72])\n"
     ]
    }
   ],
   "source": [
    "temp_x,temp_y = next(temp_i)\n",
    "print(temp_x.shape,temp_y.shape)\n",
    "# bptt not changing during LM model.\n",
    "# though there might be a param somewhere to set up variable bptt length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj phong trào xxmaj cần xxmaj vương \\n\\n xxmaj phong trào xxmaj cần xxmaj vương ( chữ xxmaj nôm : xxunk ) nổ ra vào cuối thế kỷ 19 do đại thần nhà xxmaj nguyễn là xxmaj tôn xxmaj thất xxmaj thuyết nhân danh vị hoàng đế trẻ tuổi vua xxmaj hàm xxmaj nghi đề xướng trước nạn xâm lược của thực dân xxmaj pháp . \\n\\n xxmaj tại triều đình</td>\n",
       "      <td>xxmaj phong trào xxmaj cần xxmaj vương \\n\\n xxmaj phong trào xxmaj cần xxmaj vương ( chữ xxmaj nôm : xxunk ) nổ ra vào cuối thế kỷ 19 do đại thần nhà xxmaj nguyễn là xxmaj tôn xxmaj thất xxmaj thuyết nhân danh vị hoàng đế trẻ tuổi vua xxmaj hàm xxmaj nghi đề xướng trước nạn xâm lược của thực dân xxmaj pháp . \\n\\n xxmaj tại triều đình xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tế ban đầu đặt tiêu chuẩn cho tên miền chấp nhận . xxmaj quốc tế hóa tên miền là một giải pháp kỹ thuật để dịch các tên được viết bằng các tập lệnh gốc ngôn ngữ thành biểu diễn văn bản xxup ascii tương thích với xxup hệ thống tên miền . xxmaj tên miền quốc tế hóa chỉ có thể được sử dụng với các ứng dụng được thiết kế</td>\n",
       "      <td>ban đầu đặt tiêu chuẩn cho tên miền chấp nhận . xxmaj quốc tế hóa tên miền là một giải pháp kỹ thuật để dịch các tên được viết bằng các tập lệnh gốc ngôn ngữ thành biểu diễn văn bản xxup ascii tương thích với xxup hệ thống tên miền . xxmaj tên miền quốc tế hóa chỉ có thể được sử dụng với các ứng dụng được thiết kế riêng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vắn \" , \" kim xxmaj tiền \" , \" long xxup hổ xxmaj hội \" . ông nội ông là xxmaj trần xxmaj quang xxmaj diệm ( năm xxmaj diệm ) , cha ông là xxmaj trần xxmaj quang xxmaj chiêu ( bảy xxmaj triều ) , cô là xxmaj trần xxmaj ngọc xxmaj viện ( tức xxmaj ba xxmaj viện , người đã sáng lập gánh cải lương đồng xxup</td>\n",
       "      <td>\" , \" kim xxmaj tiền \" , \" long xxup hổ xxmaj hội \" . ông nội ông là xxmaj trần xxmaj quang xxmaj diệm ( năm xxmaj diệm ) , cha ông là xxmaj trần xxmaj quang xxmaj chiêu ( bảy xxmaj triều ) , cô là xxmaj trần xxmaj ngọc xxmaj viện ( tức xxmaj ba xxmaj viện , người đã sáng lập gánh cải lương đồng xxup nữ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxmaj thứ sử . \\n\\n đời đường xxmaj cao tông , ông được đổi thành xxup tả vệ đại tướng quân . xxmaj khoảng năm 655 - 657 , ông lĩnh chức xxmaj hành quân tổng quản , dẫn binh xuất chinh xxmaj tây đột xxmaj quyết . xxmaj tuy nhiên , trong quá trình hành quân , quân đường tàn sát thường dân , người đột xxmaj quyết phẫn nộ ,</td>\n",
       "      <td>thứ sử . \\n\\n đời đường xxmaj cao tông , ông được đổi thành xxup tả vệ đại tướng quân . xxmaj khoảng năm 655 - 657 , ông lĩnh chức xxmaj hành quân tổng quản , dẫn binh xuất chinh xxmaj tây đột xxmaj quyết . xxmaj tuy nhiên , trong quá trình hành quân , quân đường tàn sát thường dân , người đột xxmaj quyết phẫn nộ , quyết</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.train.show_batch(max_n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Datablock tfms \n",
    "\n",
    "block tfms to be added at the end of  X dataset pipeline  +  after_item pipeline +  after_batch pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vnmese_lm.type_tfms) # only 1 type tfms for X \n",
    "# since 'blocks' param provide only 1: blocks=TextBlock.from_df('text', is_lm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer: (str,object) -> encodes\n",
       "(Path,object) -> encodes (object,object) -> decodes"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnmese_lm.type_tfms[0][0] # Tokenizer transform. Will be in X pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Numericalize: (object,object) -> encodes (object,object) -> decodes"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnmese_lm.type_tfms[0][1] # Numericalize transform. Will be in X pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [ToTensor: (PILMask,object) -> encodes\n",
       "(PILBase,object) -> encodes ]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnmese_lm.default_item_tfms #default item tfm (for dataloaders' after_item pipeline) for PILBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#0) []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnmese_lm.default_batch_tfms #default batch item tfm (for dataloaders' after_batch pipeline\n",
    "# normall it will be IntToFloatTensor, but token should be int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#1) [ToTensor: (PILMask,object) -> encodes\n",
       " (PILBase,object) -> encodes ],\n",
       " (#0) [])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnmese_lm.item_tfms,vnmese_lm.batch_tfms \n",
    "# nothing different from default_item_tfms and default_batch_tfms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Dataset and its tfms (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 1600)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.valid.dataset),len(dls.train.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dsets = dls.train.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, 1)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dsets[0]),len(dsets[0]) # tuple of 1 since there's no label y yet (LM model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1958])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_ds = dls.train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_ds = dls.valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, fastai2.data.core.TfmdLists)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds.tls),type(train_ds.tls[0]) # 1 tfmdlist for train, again because no label y yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: ColReader -> Tokenizer -> Numericalize"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0].tfms # or train_ds.tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: ColReader -> Tokenizer -> Numericalize"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds.tls[0].tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0x7f3623e8f750', '0x7f3623e8fd50')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(id(train_ds.tls[0].tfms)),hex(id(val_ds.tls[0].tfms)) # 2 different pipelines though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>Vân Trục</td>\n",
       "      <td>[xxbos, xxmaj, vân, xxmaj, trục, \\n\\n, xxmaj, vân, xxmaj, trục, là, một, xã, thuộc, huyện, xxmaj, lập, xxmaj, thạch, ,, tỉnh, xxmaj, vĩnh, xxmaj, phúc, ,, xxmaj, việt, xxmaj, nam, ., \\n\\n, xxup, xã, có, diện, tích, 12,25,  , km², ,, dân, số, năm, 2013, là, 4630, người, ,, mật, độ, dân, số, đạt, 379người, /, km², ., \\n\\n, 1, ., xxmaj, tên, gọi, ,, vị, trí, địa, lý, :, \\n\\n, 1.1, ., xxmaj, tên, gọi, ,, lịch, sử, hình, thành, :, \\n\\n, -, xxmaj, trước, cách, mạng, tháng, 8, năm, 1945, ,, địa, phận, xã, xxmaj, vân, xxmaj, trục, ...]</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>Mạc (họ)</td>\n",
       "      <td>[xxbos, xxmaj, mạc, (, họ, ), \\n\\n, xxmaj, mạc, là, một, họ, của, người, ,, có, ở, các, quốc, gia, á, đông, như, xxmaj, trung, xxmaj, quốc, ,, xxmaj, việt, xxmaj, nam, …, xxmaj, riêng, ở, xxmaj, việt, xxmaj, nam, ,, có, cả, một, triều, đại, phong, kiến, do, những, ông, trị, vì, ,, đó, là, nhà, xxmaj, mạc, ., xxmaj, ngoài, ra, ,, trong, lịch, sử, xxmaj, việt, xxmaj, nam, ,, còn, có, một, gốc, xxmaj, hoa, ,, mà, người, đầu, tiên, là, xxmaj, mạc, xxmaj, cửu, ,, có, công, cai, quản, và, khai, khẩn, xxmaj, miền, xxmaj, tây, ...]</td>\n",
       "      <td>1145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>[xxbos, xxmaj, los, xxmaj, angeles, \\n\\n, xxmaj, los, xxmaj, angeles, (, viết, tắt, xxup, la, ;, phát, âm, tiếng, xxmaj, anh, :, ;, phiên, âm, xxmaj, lốt, xxmaj, an, -, giơ, -, lét, ;, xxmaj, tiếng, xxmaj, tây, xxmaj, ban, xxmaj, nha, :, \", los, ángeles, \", ), là, thành, phố, lớn, nhất, tiểu, bang, xxmaj, california, và, lớn, thứ, nhì, tại, xxmaj, hoa, xxup, kỳ, ,, thuộc, về, xxmaj, quận, xxmaj, los, xxmaj, angeles, ., xxmaj, thành, phố, còn, được, gọi, tắt, là, xxmaj, los, (, \", lốt, \", ), bởi, những, người, xxmaj, việt, ở, những, vùng, lân, ...]</td>\n",
       "      <td>3686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>Safi Faye</td>\n",
       "      <td>[xxbos, xxmaj, safi, xxmaj, faye, \\n\\n, xxmaj, safi, xxmaj, faye, (, sinh, ngày, 22, xxmaj, tháng, 11, năm, 1943, ), là, một, đạo, diễn, phim, và, nhà, dân, tộc, học, người, xxmaj, senegal, ., xxup, bà, là, người, phụ, nữ, châu, xxmaj, phi, xxup, hạ, xxmaj, sahara, đầu, tiên, đạo, diễn, một, bộ, phim, được, phát, hành, thương, mại, vào, năm, 1975, ,, \", kaddu, xxmaj, beykat, \", ., xxup, bà, đã, làm, đạo, diễn, cho, một, số, bộ, phim, tài, liệu, và, viễn, tưởng, tập, trung, vào, cuộc, sống, nông, thôn, ở, xxmaj, sénégal, ., \\n\\n, xxmaj, safi, xxmaj, ...]</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>Cụm tập đoàn quân (Đức Quốc Xã)</td>\n",
       "      <td>[xxbos, xxmaj, cụm, tập, đoàn, quân, (, đức, xxmaj, quốc, xxup, xã, ), \\n\\n, xxmaj, cụm, tập, đoàn, quân, (, tiếng, đức, :, \", heeresgruppe, \", ), là, tổ, chức, tác, chiến, cấp, chiến, lược, cao, nhất, của, xxmaj, quân, đội, đức, xxmaj, quốc, xã, ,, trên, cấp, xxmaj, tập, đoàn, quân, ., xxmaj, cũng, giống, như, biên, chế, phương, diện, quân, của, xxmaj, liên, xxup, xô, ,, cụm, tập, đoàn, quân, là, tổ, chức, đơn, vị, binh, chủng, hợp, thành, ,, thường, gồm, bộ, binh, ,, kỵ, binh, cơ, giới, ,, xe, tăng, ,, pháo, binh, ,, công, binh, ...]</td>\n",
       "      <td>1351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>Ngô Xán</td>\n",
       "      <td>[xxbos, xxmaj, ngô, xxmaj, xán, \\n\\n, xxmaj, ngô, xxmaj, xán, (;, ?, -, 245, ), ,, tự, xxmaj, khổng, xxmaj, hưu, (, 道言, ), ,, là, quan, viên, ,, tướng, lĩnh, đông, xxmaj, ngô, thời, xxmaj, tam, xxmaj, quốc, trong, lịch, sử, xxmaj, trung, xxmaj, quốc, ., \\n\\n, xxmaj, ngô, xxmaj, xán, quê, ở, huyện, ô, xxmaj, trình, ,, quận, xxmaj, ngô, xxmaj, khi, còn, nhỏ, ,, có, một, phụ, nhân, thấy, xxmaj, ngô, xxmaj, xán, ,, nói, với, mẹ, của, xxmaj, xán, rằng, :, \", thằng, bé, này, có, cốt, cách, của, khanh, tướng, ., \", \\n\\n, xxmaj, ngô, ...]</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Hoàng Đế</td>\n",
       "      <td>[xxbos, xxmaj, hoàng, đế, \\n\\n, xxmaj, hoàng, đế, (, trung, phồn, thể, :, 黃帝, ,, xxmaj, trung, giản, thể, :, 黄帝, ,, bính, âm, :, huángdì, ), ,, còn, gọi, là, xxmaj, hiên, xxmaj, viên, xxmaj, hoàng, đế, (, 轩辕黃帝, ), ,, là, một, vị, quân, chủ, huyền, thoại, và, là, anh, hùng, văn, hoá, của, xxmaj, văn, minh, xxmaj, trung, xxmaj, hoa, ,, được, coi, là, thuỷ, tổ, của, mọi, người, xxmaj, hán, ., xxmaj, chữ, \", hoàng, \", (, 黃, ), ở, đây, hàm, nghĩa, sắc, vàng, ,, là, màu, biểu, trưng, cho, hành, xxmaj, thổ, ., xxmaj, ...]</td>\n",
       "      <td>2442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>Khí đồng hành</td>\n",
       "      <td>[xxbos, xxmaj, khí, đồng, hành, \\n\\n, xxmaj, khí, đồng, hành, (, tiếng, xxmaj, anh, :, \", associated, gas, \", ), là, khí, tự, nhiên, được, tìm, thấy, cùng, dầu, thô, ,, có, thể, ở, dạng, hoà, lẫn, với, dầu, thô, hoặc, tạo, thành, không, gian, phía, trên, lớp, dầu, thô, trong, mỏ, dầu, ., \\n\\n, xxmaj, khí, đồng, hành, khi, được, tách, khỏi, dầu, thô, là, hỗn, hợp, chủ, yếu, gồm, etan, (, ch, ), ,, propan, (, ch, ), ,, butan, (, ch, ), và, pentan, (, ch, ), ., xxmaj, ngoài, ra, còn, những, tạp, chất, không, mong, ...]</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>Hoàng Phài</td>\n",
       "      <td>[xxbos, xxmaj, hoàng, xxmaj, phài, \\n\\n, xxmaj, hoàng, xxmaj, phài, là, một, thôn, nằm, tại, xã, xxmaj, cốc, đán, ,, huyện, xxmaj, ngân, xxmaj, sơn, ,, tỉnh, xxmaj, bắc, xxmaj, kạn, \\n\\n, xxmaj, ngày, 31, /, 10, /, 2011, ,, xxup, bộ, xxmaj, văn, hóa, ,, xxmaj, thể, thao, và, xxmaj, du, lịch, đã, chính, thức, công, nhận, và, xếp, hạng, di, tích, lịch, sử, “, địa, điểm, xxmaj, lưu, niệm, nơi, xxmaj, bác, xxup, hồ, dừng, chân, trên, đường, từ, xxmaj, pác, xxup, bó, về, xxmaj, tân, xxmaj, trào, tháng, 5, năm, 1945, ”, tại, thôn, xxmaj, hoàng, xxmaj, ...]</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>American Life (bài hát)</td>\n",
       "      <td>[xxbos, xxmaj, american, xxmaj, life, (, bài, hát, ), \\n\\n, \", american, xxmaj, life, \", (, tạm, dịch, :, \", lối, sống, xxmaj, hoa, xxup, kỳ, \", ), là, một, bài, hát, của, ca, sĩ, người, xxup, mỹ, xxmaj, madonna, nằm, trong, album, phòng, thu, thứ, 9, cùng, tên, của, cô, (, 2003, ), ., xxup, nó, được, phát, hành, làm, đĩa, đơn, đầu, tiên, trích, từ, album, vào, ngày, 8, tháng, 4, năm, 2003, bởi, xxmaj, maverick, xxmaj, records, ., xxmaj, bài, hát, do, xxmaj, madonna, và, xxmaj, mirwais, xxmaj, ahmadzaï, sáng, tác, và, sản, xuất, ,, với, nội, ...]</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                fname  \\\n",
       "1927                         Vân Trục   \n",
       "1747                         Mạc (họ)   \n",
       "1751                      Los Angeles   \n",
       "695                         Safi Faye   \n",
       "1838  Cụm tập đoàn quân (Đức Quốc Xã)   \n",
       "...                               ...   \n",
       "869                           Ngô Xán   \n",
       "368                          Hoàng Đế   \n",
       "973                     Khí đồng hành   \n",
       "1169                       Hoàng Phài   \n",
       "1495          American Life (bài hát)   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text  \\\n",
       "1927                            [xxbos, xxmaj, vân, xxmaj, trục, \\n\\n, xxmaj, vân, xxmaj, trục, là, một, xã, thuộc, huyện, xxmaj, lập, xxmaj, thạch, ,, tỉnh, xxmaj, vĩnh, xxmaj, phúc, ,, xxmaj, việt, xxmaj, nam, ., \\n\\n, xxup, xã, có, diện, tích, 12,25,  , km², ,, dân, số, năm, 2013, là, 4630, người, ,, mật, độ, dân, số, đạt, 379người, /, km², ., \\n\\n, 1, ., xxmaj, tên, gọi, ,, vị, trí, địa, lý, :, \\n\\n, 1.1, ., xxmaj, tên, gọi, ,, lịch, sử, hình, thành, :, \\n\\n, -, xxmaj, trước, cách, mạng, tháng, 8, năm, 1945, ,, địa, phận, xã, xxmaj, vân, xxmaj, trục, ...]   \n",
       "1747                                [xxbos, xxmaj, mạc, (, họ, ), \\n\\n, xxmaj, mạc, là, một, họ, của, người, ,, có, ở, các, quốc, gia, á, đông, như, xxmaj, trung, xxmaj, quốc, ,, xxmaj, việt, xxmaj, nam, …, xxmaj, riêng, ở, xxmaj, việt, xxmaj, nam, ,, có, cả, một, triều, đại, phong, kiến, do, những, ông, trị, vì, ,, đó, là, nhà, xxmaj, mạc, ., xxmaj, ngoài, ra, ,, trong, lịch, sử, xxmaj, việt, xxmaj, nam, ,, còn, có, một, gốc, xxmaj, hoa, ,, mà, người, đầu, tiên, là, xxmaj, mạc, xxmaj, cửu, ,, có, công, cai, quản, và, khai, khẩn, xxmaj, miền, xxmaj, tây, ...]   \n",
       "1751        [xxbos, xxmaj, los, xxmaj, angeles, \\n\\n, xxmaj, los, xxmaj, angeles, (, viết, tắt, xxup, la, ;, phát, âm, tiếng, xxmaj, anh, :, ;, phiên, âm, xxmaj, lốt, xxmaj, an, -, giơ, -, lét, ;, xxmaj, tiếng, xxmaj, tây, xxmaj, ban, xxmaj, nha, :, \", los, ángeles, \", ), là, thành, phố, lớn, nhất, tiểu, bang, xxmaj, california, và, lớn, thứ, nhì, tại, xxmaj, hoa, xxup, kỳ, ,, thuộc, về, xxmaj, quận, xxmaj, los, xxmaj, angeles, ., xxmaj, thành, phố, còn, được, gọi, tắt, là, xxmaj, los, (, \", lốt, \", ), bởi, những, người, xxmaj, việt, ở, những, vùng, lân, ...]   \n",
       "695   [xxbos, xxmaj, safi, xxmaj, faye, \\n\\n, xxmaj, safi, xxmaj, faye, (, sinh, ngày, 22, xxmaj, tháng, 11, năm, 1943, ), là, một, đạo, diễn, phim, và, nhà, dân, tộc, học, người, xxmaj, senegal, ., xxup, bà, là, người, phụ, nữ, châu, xxmaj, phi, xxup, hạ, xxmaj, sahara, đầu, tiên, đạo, diễn, một, bộ, phim, được, phát, hành, thương, mại, vào, năm, 1975, ,, \", kaddu, xxmaj, beykat, \", ., xxup, bà, đã, làm, đạo, diễn, cho, một, số, bộ, phim, tài, liệu, và, viễn, tưởng, tập, trung, vào, cuộc, sống, nông, thôn, ở, xxmaj, sénégal, ., \\n\\n, xxmaj, safi, xxmaj, ...]   \n",
       "1838                    [xxbos, xxmaj, cụm, tập, đoàn, quân, (, đức, xxmaj, quốc, xxup, xã, ), \\n\\n, xxmaj, cụm, tập, đoàn, quân, (, tiếng, đức, :, \", heeresgruppe, \", ), là, tổ, chức, tác, chiến, cấp, chiến, lược, cao, nhất, của, xxmaj, quân, đội, đức, xxmaj, quốc, xã, ,, trên, cấp, xxmaj, tập, đoàn, quân, ., xxmaj, cũng, giống, như, biên, chế, phương, diện, quân, của, xxmaj, liên, xxup, xô, ,, cụm, tập, đoàn, quân, là, tổ, chức, đơn, vị, binh, chủng, hợp, thành, ,, thường, gồm, bộ, binh, ,, kỵ, binh, cơ, giới, ,, xe, tăng, ,, pháo, binh, ,, công, binh, ...]   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ...   \n",
       "869                          [xxbos, xxmaj, ngô, xxmaj, xán, \\n\\n, xxmaj, ngô, xxmaj, xán, (;, ?, -, 245, ), ,, tự, xxmaj, khổng, xxmaj, hưu, (, 道言, ), ,, là, quan, viên, ,, tướng, lĩnh, đông, xxmaj, ngô, thời, xxmaj, tam, xxmaj, quốc, trong, lịch, sử, xxmaj, trung, xxmaj, quốc, ., \\n\\n, xxmaj, ngô, xxmaj, xán, quê, ở, huyện, ô, xxmaj, trình, ,, quận, xxmaj, ngô, xxmaj, khi, còn, nhỏ, ,, có, một, phụ, nhân, thấy, xxmaj, ngô, xxmaj, xán, ,, nói, với, mẹ, của, xxmaj, xán, rằng, :, \", thằng, bé, này, có, cốt, cách, của, khanh, tướng, ., \", \\n\\n, xxmaj, ngô, ...]   \n",
       "368                                          [xxbos, xxmaj, hoàng, đế, \\n\\n, xxmaj, hoàng, đế, (, trung, phồn, thể, :, 黃帝, ,, xxmaj, trung, giản, thể, :, 黄帝, ,, bính, âm, :, huángdì, ), ,, còn, gọi, là, xxmaj, hiên, xxmaj, viên, xxmaj, hoàng, đế, (, 轩辕黃帝, ), ,, là, một, vị, quân, chủ, huyền, thoại, và, là, anh, hùng, văn, hoá, của, xxmaj, văn, minh, xxmaj, trung, xxmaj, hoa, ,, được, coi, là, thuỷ, tổ, của, mọi, người, xxmaj, hán, ., xxmaj, chữ, \", hoàng, \", (, 黃, ), ở, đây, hàm, nghĩa, sắc, vàng, ,, là, màu, biểu, trưng, cho, hành, xxmaj, thổ, ., xxmaj, ...]   \n",
       "973                                         [xxbos, xxmaj, khí, đồng, hành, \\n\\n, xxmaj, khí, đồng, hành, (, tiếng, xxmaj, anh, :, \", associated, gas, \", ), là, khí, tự, nhiên, được, tìm, thấy, cùng, dầu, thô, ,, có, thể, ở, dạng, hoà, lẫn, với, dầu, thô, hoặc, tạo, thành, không, gian, phía, trên, lớp, dầu, thô, trong, mỏ, dầu, ., \\n\\n, xxmaj, khí, đồng, hành, khi, được, tách, khỏi, dầu, thô, là, hỗn, hợp, chủ, yếu, gồm, etan, (, ch, ), ,, propan, (, ch, ), ,, butan, (, ch, ), và, pentan, (, ch, ), ., xxmaj, ngoài, ra, còn, những, tạp, chất, không, mong, ...]   \n",
       "1169     [xxbos, xxmaj, hoàng, xxmaj, phài, \\n\\n, xxmaj, hoàng, xxmaj, phài, là, một, thôn, nằm, tại, xã, xxmaj, cốc, đán, ,, huyện, xxmaj, ngân, xxmaj, sơn, ,, tỉnh, xxmaj, bắc, xxmaj, kạn, \\n\\n, xxmaj, ngày, 31, /, 10, /, 2011, ,, xxup, bộ, xxmaj, văn, hóa, ,, xxmaj, thể, thao, và, xxmaj, du, lịch, đã, chính, thức, công, nhận, và, xếp, hạng, di, tích, lịch, sử, “, địa, điểm, xxmaj, lưu, niệm, nơi, xxmaj, bác, xxup, hồ, dừng, chân, trên, đường, từ, xxmaj, pác, xxup, bó, về, xxmaj, tân, xxmaj, trào, tháng, 5, năm, 1945, ”, tại, thôn, xxmaj, hoàng, xxmaj, ...]   \n",
       "1495         [xxbos, xxmaj, american, xxmaj, life, (, bài, hát, ), \\n\\n, \", american, xxmaj, life, \", (, tạm, dịch, :, \", lối, sống, xxmaj, hoa, xxup, kỳ, \", ), là, một, bài, hát, của, ca, sĩ, người, xxup, mỹ, xxmaj, madonna, nằm, trong, album, phòng, thu, thứ, 9, cùng, tên, của, cô, (, 2003, ), ., xxup, nó, được, phát, hành, làm, đĩa, đơn, đầu, tiên, trích, từ, album, vào, ngày, 8, tháng, 4, năm, 2003, bởi, xxmaj, maverick, xxmaj, records, ., xxmaj, bài, hát, do, xxmaj, madonna, và, xxmaj, mirwais, xxmaj, ahmadzaï, sáng, tác, và, sản, xuất, ,, với, nội, ...]   \n",
       "\n",
       "      text_length  \n",
       "1927         1958  \n",
       "1747         1145  \n",
       "1751         3686  \n",
       "695           808  \n",
       "1838         1351  \n",
       "...           ...  \n",
       "869           642  \n",
       "368          2442  \n",
       "973           605  \n",
       "1169         1182  \n",
       "1495          504  \n",
       "\n",
       "[1600 rows x 3 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0].items \n",
    "# no transform applied yet, but note that texts have already been 'ColReader' and 'Tokenizer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorText([   2,    8, 1179,  ...,   38, 1433,   23]), 1958)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0][0],len(train_ds.tls[0][0]) # when indexed, tfms are applied (last one: Numericalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorText([   2,    8,  882,  ...,  111, 6466,   10]), 1145)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0][1],len(train_ds.tls[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxpad'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in train_ds.tls[0][1]:\n",
    "    if i == train_ds.vocab[1]: \n",
    "        print('there is padding')\n",
    "        break\n",
    "        \n",
    "# print nothing => no padding apply yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Found 2000 items\n",
    "# 2 datasets of sizes 1600,400\n",
    "# Setting up Pipeline: ColReader -> Tokenizer -> Numericalize\n",
    "\n",
    "# Building one sample\n",
    "#   Pipeline: ColReader -> Tokenizer -> Numericalize\n",
    "#     starting from\n",
    "#       fname                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Lâm Tế Nghĩa Huyền\n",
    "# text           [xxbos, xxmaj, lâm, xxup, tế, xxmaj, nghĩa, xxmaj, huyền, \\n\\n, xxmaj, lâm, xxup, tế, xxmaj, nghĩa, xxmaj, huyền, (, zh, ., \", línjì, yìxuán, \", /, \", lin, -, chi, i, -, hsüan, \", 臨濟義玄, ,, ja, ., \", rinzai, gigen, \", ), ,, ?, -866, /, 867, ,, là, một, vị, xxmaj, thiền, sư, xxmaj, trung, xxmaj, quốc, ,, là, xxup, tổ, khai, dòng, thiền, xxmaj, lâm, xxup, tế, ., xxup, sư, là, môn, đệ, xuất, sắc, nhất, của, xxmaj, thiền, sư, xxmaj, hoàng, xxup, bá, xxmaj, hi, xxmaj, vận, ., xxmaj, môn, đệ, đắc, pháp, danh, tiếng, của, ...]\n",
    "# text_length                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1083\n",
    "# Name: 842, dtype: object\n",
    "#     applying ColReader gives\n",
    "#       (#1083) ['xxbos','xxmaj','lâm','xxup','tế','xxmaj','nghĩa','xxmaj','huyền','\\n\\n'...]\n",
    "#     applying Tokenizer gives\n",
    "#       (#1083) ['xxbos','xxmaj','lâm','xxup','tế','xxmaj','nghĩa','xxmaj','huyền','\\n\\n'...]\n",
    "#     applying Numericalize gives\n",
    "#       TensorText of size 1083\n",
    "\n",
    "# Final sample: (TensorText([  2,   8, 685,  ...,   8, 917,  10]),)\n",
    "\n",
    "\n",
    "# Setting up after_item: Pipeline: ToTensor\n",
    "# Setting up before_batch: Pipeline: \n",
    "# Setting up after_batch: Pipeline: \n",
    "\n",
    "# Building one batch\n",
    "# Applying item_tfms to the first sample:\n",
    "#   Pipeline: ToTensor\n",
    "#     starting from\n",
    "#       (TensorText of size 1083)\n",
    "#     applying ToTensor gives\n",
    "#       (TensorText of size 1083)\n",
    "\n",
    "# Adding the next 1 samples\n",
    "\n",
    "# No before_batch transform to apply\n",
    "\n",
    "# Collating items in a batch\n",
    "# Error! It's not possible to collate your items in a batch\n",
    "# Could not collate the 0-th members of your tuples because got the following shapes\n",
    "# torch.Size([1083]),torch.Size([1403])\n",
    "\n",
    "# TODO: in LM, for some reason the sequences in a batch aren’t padded to be of equal length \n",
    "# while making a LM. I know they are made equal when building the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LM learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### define learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(dls, \n",
    "                               AWD_LSTM, \n",
    "                               metrics=[accuracy, Perplexity()],\n",
    "                               drop_mult=1.0,\n",
    "                               pretrained=False,\n",
    "                               path=path).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026666666666666665"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "lr *= bs/48\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(fastai2.text.learner.LMLearner, fastai2.text.models.core.SequentialRNN)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(learn),type(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AWD_LSTM(\n",
       "   (encoder): Embedding(16880, 400, padding_idx=1)\n",
       "   (encoder_dp): EmbeddingDropout(\n",
       "     (emb): Embedding(16880, 400, padding_idx=1)\n",
       "   )\n",
       "   (rnns): ModuleList(\n",
       "     (0): WeightDropout(\n",
       "       (module): LSTM(400, 1152, batch_first=True)\n",
       "     )\n",
       "     (1): WeightDropout(\n",
       "       (module): LSTM(1152, 1152, batch_first=True)\n",
       "     )\n",
       "     (2): WeightDropout(\n",
       "       (module): LSTM(1152, 400, batch_first=True)\n",
       "     )\n",
       "   )\n",
       "   (input_dp): RNNDropout()\n",
       "   (hidden_dps): ModuleList(\n",
       "     (0): RNNDropout()\n",
       "     (1): RNNDropout()\n",
       "     (2): RNNDropout()\n",
       "   )\n",
       " ),\n",
       " LinearDecoder(\n",
       "   (decoder): Linear(in_features=400, out_features=16880, bias=True)\n",
       "   (output_dp): RNNDropout()\n",
       " ))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[0],learn.model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze() # == learn.opt.freeze_to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai2.optimizer.Optimizer"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(learn.opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': [{},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {'do_wd': False}],\n",
       " 'hypers': (#4) [{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05},{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05},{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05},{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05}]}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.opt.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Param groups and weight shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn.opt.param_lists) # 4 layers total, for discriminative fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['torch.Size([4608, 1152]): True',\n",
       " 'torch.Size([4608, 400]): True',\n",
       " 'torch.Size([4608]): True',\n",
       " 'torch.Size([4608]): True',\n",
       " 'torch.Size([4608, 1152]): True',\n",
       " 'torch.Size([4608, 1152]): True',\n",
       " 'torch.Size([4608]): True',\n",
       " 'torch.Size([4608]): True',\n",
       " 'torch.Size([1600, 400]): True',\n",
       " 'torch.Size([1600, 1152]): True',\n",
       " 'torch.Size([1600]): True',\n",
       " 'torch.Size([1600]): True',\n",
       " 'torch.Size([16880, 400]): True',\n",
       " 'torch.Size([16880]): True']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"{getattr(i,'shape')}: {i.requires_grad}\" for l in learn.opt.param_lists for i in l]\n",
    "# all requires_grad true b/c unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn.model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.encoder.weight: torch.Size([16880, 400])',\n",
       " '0.encoder_dp.emb.weight: torch.Size([16880, 400])',\n",
       " '0.rnns.0.weight_hh_l0_raw: torch.Size([4608, 1152])',\n",
       " '0.rnns.0.module.weight_ih_l0: torch.Size([4608, 400])',\n",
       " '0.rnns.0.module.bias_ih_l0: torch.Size([4608])',\n",
       " '0.rnns.0.module.bias_hh_l0: torch.Size([4608])',\n",
       " '0.rnns.1.weight_hh_l0_raw: torch.Size([4608, 1152])',\n",
       " '0.rnns.1.module.weight_ih_l0: torch.Size([4608, 1152])',\n",
       " '0.rnns.1.module.bias_ih_l0: torch.Size([4608])',\n",
       " '0.rnns.1.module.bias_hh_l0: torch.Size([4608])',\n",
       " '0.rnns.2.weight_hh_l0_raw: torch.Size([1600, 400])',\n",
       " '0.rnns.2.module.weight_ih_l0: torch.Size([1600, 1152])',\n",
       " '0.rnns.2.module.bias_ih_l0: torch.Size([1600])',\n",
       " '0.rnns.2.module.bias_hh_l0: torch.Size([1600])',\n",
       " '1.decoder.weight: torch.Size([16880, 400])',\n",
       " '1.decoder.bias: torch.Size([16880])']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{k}: {v.shape}' for k,v in learn.model.state_dict().items()]\n",
    "# for some reason state_dict includes encoder (embedding) weight, but opt.param_lists or model.parameters don't\n",
    "# because weighs of embedding (encoder) and weight of last linear layer is the same\n",
    "# because of 'tie_weights': look at awdlstm.py, in awd_lstm_lm_config 'tie_weights' is True\n",
    "# For language model, tie_weights will make embedding weight == last layer linear weight\n",
    "# Why? More efficient training. This is mentioned in AWD LSTM paper by Stephen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0188,  0.0143,  0.0664,  ...,  0.0572,  0.0979, -0.0883],\n",
       "        [ 0.0886, -0.0824,  0.0024,  ...,  0.0121, -0.0513, -0.0572],\n",
       "        [ 0.0262, -0.0667,  0.0044,  ...,  0.0031,  0.0521, -0.0231],\n",
       "        ...,\n",
       "        [ 0.0502, -0.0522, -0.0105,  ..., -0.0584,  0.0650,  0.0326],\n",
       "        [-0.0859,  0.0849, -0.0026,  ..., -0.0770,  0.0981,  0.0587],\n",
       "        [ 0.0428,  0.0166,  0.0893,  ...,  0.0448,  0.0556,  0.0442]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[0].encoder.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0188,  0.0143,  0.0664,  ...,  0.0572,  0.0979, -0.0883],\n",
       "        [ 0.0886, -0.0824,  0.0024,  ...,  0.0121, -0.0513, -0.0572],\n",
       "        [ 0.0262, -0.0667,  0.0044,  ...,  0.0031,  0.0521, -0.0231],\n",
       "        ...,\n",
       "        [ 0.0502, -0.0522, -0.0105,  ..., -0.0584,  0.0650,  0.0326],\n",
       "        [-0.0859,  0.0849, -0.0026,  ..., -0.0770,  0.0981,  0.0587],\n",
       "        [ 0.0428,  0.0166,  0.0893,  ...,  0.0448,  0.0556,  0.0442]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model.state_dict()['0.encoder.weight'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_equal(learn.model.state_dict()['0.encoder.weight'].data, learn.model[0].encoder.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0188,  0.0143,  0.0664,  ...,  0.0572,  0.0979, -0.0883],\n",
       "        [ 0.0886, -0.0824,  0.0024,  ...,  0.0121, -0.0513, -0.0572],\n",
       "        [ 0.0262, -0.0667,  0.0044,  ...,  0.0031,  0.0521, -0.0231],\n",
       "        ...,\n",
       "        [ 0.0502, -0.0522, -0.0105,  ..., -0.0584,  0.0650,  0.0326],\n",
       "        [-0.0859,  0.0849, -0.0026,  ..., -0.0770,  0.0981,  0.0587],\n",
       "        [ 0.0428,  0.0166,  0.0893,  ...,  0.0448,  0.0556,  0.0442]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[1].decoder.weight.data # last layer linear weight\n",
    "# same as embedding weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_equal(learn.model.state_dict()['0.encoder.weight'].data, learn.model[1].decoder.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x7f1a096dbc30'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(id(learn.model[0].encoder.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x7f1a096dbc30'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(id(learn.model[1].decoder.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([16880, 400]), torch.Size([16880])]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[getattr(i,'shape') for i in learn.opt.param_lists[3]] \n",
    "# matrix weight + bias of last linear layer (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([4608, 1152]),\n",
       " torch.Size([4608, 400]),\n",
       " torch.Size([4608]),\n",
       " torch.Size([4608])]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (0): WeightDropout(\n",
    "#        (module): LSTM(400, 1152, batch_first=True)\n",
    "#      )\n",
    "\n",
    "[getattr(i,'shape') for i in learn.opt.param_lists[0]] # 1st LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Weights of an LSTM unidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = nn.LSTM(400, 1152, bias=True, bidirectional=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0154, -0.0289, -0.0189,  ..., -0.0088,  0.0129, -0.0005],\n",
       "         [ 0.0147,  0.0234, -0.0261,  ...,  0.0021, -0.0199, -0.0066],\n",
       "         [ 0.0122, -0.0047,  0.0102,  ..., -0.0054,  0.0280,  0.0257],\n",
       "         ...,\n",
       "         [-0.0137,  0.0106,  0.0207,  ..., -0.0227,  0.0077,  0.0251],\n",
       "         [ 0.0158,  0.0088,  0.0237,  ...,  0.0218, -0.0261, -0.0080],\n",
       "         [ 0.0017,  0.0107, -0.0004,  ..., -0.0087,  0.0027, -0.0047]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0095,  0.0015, -0.0041,  ..., -0.0149, -0.0061,  0.0075],\n",
       "         [-0.0145, -0.0124, -0.0137,  ..., -0.0154,  0.0172,  0.0203],\n",
       "         [-0.0255, -0.0040,  0.0278,  ..., -0.0156, -0.0256, -0.0002],\n",
       "         ...,\n",
       "         [ 0.0093,  0.0231, -0.0046,  ...,  0.0017, -0.0092, -0.0159],\n",
       "         [ 0.0188, -0.0189, -0.0195,  ..., -0.0237, -0.0179,  0.0262],\n",
       "         [ 0.0191, -0.0118, -0.0157,  ..., -0.0025, -0.0293, -0.0082]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0160,  0.0267,  0.0284,  ...,  0.0209, -0.0049,  0.0090],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0094,  0.0098, -0.0009,  ...,  0.0104,  0.0169,  0.0030],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(temp.parameters()) #weight_ih_l0, weight hh_l0 and two biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4608, 1152]), torch.Size([4608, 400]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.weight_hh_l0.shape, temp.weight_ih_l0.shape \n",
    "\n",
    "# ~LSTM.weight_ih_l[k] – the learnable input-hidden weights of the \\text{k}^{th}k \n",
    "# th\n",
    "#   layer (W_ii|W_if|W_ig|W_io), of shape (4*hidden_size, input_size) for k = 0. Otherwise, the shape is (4*hidden_size, num_directions * hidden_size)\n",
    "\n",
    "# ~LSTM.weight_hh_l[k] – the learnable hidden-hidden weights of the \\text{k}^{th}k \n",
    "# th\n",
    "#   layer (W_hi|W_hf|W_hg|W_ho), of shape (4*hidden_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4608"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4*1152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([4608, 1152]),\n",
       " torch.Size([4608, 1152]),\n",
       " torch.Size([4608]),\n",
       " torch.Size([4608])]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[getattr(i,'shape') for i in learn.opt.param_lists[1]] # 2nd LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1600, 400]),\n",
       " torch.Size([1600, 1152]),\n",
       " torch.Size([1600]),\n",
       " torch.Size([1600])]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[getattr(i,'shape') for i in learn.opt.param_lists[2]] # 3rd LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#4) [{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05},{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05},{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05},{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.opt.hypers # list of hyperparams for each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### quick review on slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice(None, 1, None)\n",
      "slice(None, 1, None)\n",
      "slice(1, None, None)\n",
      "slice(1, 2, None)\n",
      "slice(1, 2, 3)\n",
      "slice(None, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "# slice(start, stop, step)\n",
    "print(slice(1))\n",
    "print(slice(None,1))\n",
    "print(slice(1,None))\n",
    "print(slice(1,2))\n",
    "print(slice(1,2,3))\n",
    "print(slice(None,2,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(range(10))[slice(None)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [0],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2, 3],\n",
       " [0, 1, 2, 3, 4],\n",
       " [0, 1, 2, 3, 4, 5],\n",
       " [0, 1, 2, 3, 4, 5, 6],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8]]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(range(10))[slice(i)] for i in range(10)] # [:0],[:1],[:2]..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [3, 4, 5, 6, 7, 8, 9],\n",
       " [4, 5, 6, 7, 8, 9],\n",
       " [5, 6, 7, 8, 9],\n",
       " [6, 7, 8, 9],\n",
       " [7, 8, 9],\n",
       " [8, 9],\n",
       " [9]]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(range(10))[slice(i,None)] for i in range(10)] # [0:],[1:],[2:] ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9]]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(range(10))[slice(i,i+2)] for i in range(10)] # [0:2],[1:3], ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10))[slice(0,7,2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.169965</td>\n",
       "      <td>6.045080</td>\n",
       "      <td>0.118188</td>\n",
       "      <td>422.031403</td>\n",
       "      <td>02:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# learn.fit_one_cycle(1, lr, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.153887</td>\n",
       "      <td>5.969858</td>\n",
       "      <td>0.119671</td>\n",
       "      <td>391.450165</td>\n",
       "      <td>02:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.682713</td>\n",
       "      <td>4.455638</td>\n",
       "      <td>0.261569</td>\n",
       "      <td>86.111069</td>\n",
       "      <td>02:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.234314</td>\n",
       "      <td>4.185904</td>\n",
       "      <td>0.289397</td>\n",
       "      <td>65.752914</td>\n",
       "      <td>02:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "learn.fit_one_cycle(3, lr, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Re-check learnable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# learn.opt.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn.opt.state_dict()['state']) # save grad_avg and sqr_avg?? for each learnable params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0414,  0.0972,  0.1735,  ...,  0.0482,  0.2040, -0.1077],\n",
       "        [ 0.0446, -0.1130, -0.0317,  ...,  0.0368,  0.0045, -0.0316],\n",
       "        [ 0.7861,  0.0180, -0.0094,  ..., -0.0839,  0.3047, -0.1075],\n",
       "        ...,\n",
       "        [ 0.0302, -0.1054, -0.0251,  ..., -0.0073,  0.1326,  0.0775],\n",
       "        [-0.1252,  0.0521, -0.0341,  ..., -0.0532,  0.1394,  0.0756],\n",
       "        [-0.0021, -0.0180,  0.0514,  ...,  0.0674,  0.1087,  0.0644]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[0].encoder.weight.data # weight is updated everywhere. Good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.to_fp32().save(mdl_path/lm_fns[0], with_opt=False) \n",
    "# save the state_dict (all possible learnable parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(mdl_path/(lm_fns[1] + '.pkl')):\n",
    "    os.remove(mdl_path/(lm_fns[1] + '.pkl'))\n",
    "#     print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(mdl_path/(lm_fns[1] + '.pkl'), 'wb') as f:\n",
    "    pickle.dump(learn.dls.vocab, f) # save list of strings, which are vocabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### try drop_mult 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.453883</td>\n",
       "      <td>6.472377</td>\n",
       "      <td>0.101275</td>\n",
       "      <td>647.020081</td>\n",
       "      <td>02:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = language_model_learner(dls, \n",
    "                               AWD_LSTM, \n",
    "                               metrics=[accuracy, Perplexity()],\n",
    "                               drop_mult=0.5,\n",
    "                               pretrained=False,\n",
    "                               path=path).to_fp16()\n",
    "\n",
    "lr = 1e-2\n",
    "lr *= bs/48\n",
    "lr\n",
    "\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(1, lr, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/quantran/.fastai/data/viwiki/models\n"
     ]
    }
   ],
   "source": [
    "mdl_path = path/'models'\n",
    "print(mdl_path)\n",
    "mdl_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lm_fns = [f'vi_wt', f'vi_wt_vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# learn.to_fp32().save(mdl_path/lm_fns[0], with_opt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# learn.dls.vocab.save(mdl_path/(lm_fns[1] + '.pkl'))\n",
    "# with open(mdl_path/(lm_fns[1] + '.pkl'), 'wb') as f:\n",
    "#     pickle.dump(learn.dls.vocab, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### try original wikitext param training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "config = awd_lstm_lm_config.copy()\n",
    "config.update({'input_p': 0.6, 'output_p': 0.4, 'weight_p': 0.5, 'embed_p': 0.1, 'hidden_p': 0.2})\n",
    "model = get_language_model(AWD_LSTM, len(dls.vocab), config=config)\n",
    "opt_func = partial(Adam, wd=0.1, eps=1e-7)\n",
    "cbs = [MixedPrecision(clip=0.1), ModelResetter, RNNRegularizer(alpha=2, beta=1)]\n",
    "learn = Learner(dls, model, \n",
    "                loss_func=CrossEntropyLossFlat(), \n",
    "                opt_func=opt_func, \n",
    "                cbs=cbs, metrics=[accuracy, Perplexity()]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>202909.375000</td>\n",
       "      <td>9.725590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16740.558594</td>\n",
       "      <td>03:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 5e-03, moms=(0.8,0.7,0.8), div=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Finetuning LM with sentiment analysis data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## prepare datablock and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df.loc[pd.isna(train_df.comment),'comment']='NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_df.loc[pd.isna(test_df.comment),'comment']='NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_000000</td>\n",
       "      <td>Dung dc sp tot cam on \\nshop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_000001</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_000002</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_000003</td>\n",
       "      <td>:(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_000004</td>\n",
       "      <td>Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý :((</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  \\\n",
       "0  train_000000   \n",
       "1  train_000001   \n",
       "2  train_000002   \n",
       "3  train_000003   \n",
       "4  train_000004   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  comment  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                       Dung dc sp tot cam on \\nshop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                       Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                 Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất   \n",
       "3  :(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                  Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý :((   \n",
       "\n",
       "   label  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    1.0  \n",
       "4    1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([train_df,test_df], sort=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>test_010976</td>\n",
       "      <td>Thời gian giao hàng rất nhanh.ngon.mà cay quá... Chất lượng sản phẩm tuyệt vời</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>test_010977</td>\n",
       "      <td>Sản phẩm hơi cũ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>test_010978</td>\n",
       "      <td>Sản phẩm chắc chắn nhưng k bóng bằng trong hình</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>test_010979</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời có mùi thơm rất dễ chịu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10980</th>\n",
       "      <td>test_010980</td>\n",
       "      <td>như quảng cáo. sim rất tốt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  \\\n",
       "10976  test_010976   \n",
       "10977  test_010977   \n",
       "10978  test_010978   \n",
       "10979  test_010979   \n",
       "10980  test_010980   \n",
       "\n",
       "                                                                               comment  \\\n",
       "10976   Thời gian giao hàng rất nhanh.ngon.mà cay quá... Chất lượng sản phẩm tuyệt vời   \n",
       "10977                                                                  Sản phẩm hơi cũ   \n",
       "10978                                  Sản phẩm chắc chắn nhưng k bóng bằng trong hình   \n",
       "10979                            Chất lượng sản phẩm tuyệt vời có mùi thơm rất dễ chịu   \n",
       "10980                                                       như quảng cáo. sim rất tốt   \n",
       "\n",
       "       label  \n",
       "10976    NaN  \n",
       "10977    NaN  \n",
       "10978    NaN  \n",
       "10979    NaN  \n",
       "10980    NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_sen = TextDataLoaders.from_df(df, path=path, text_col='comment', \n",
    "                                  is_lm=True, \n",
    "                                  valid_pct=0.1,\n",
    "                                  seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj giày đẹp nhưng chắc đi nhanh hỏng xxrep 3 😂 xxbos xxmaj bảo hỗn hợp nhưng toàn là xxunk kẹo dâu chắc được tầm chục cái @@ xxbos xxmaj nhấn tần vài lần là bọt tung xxunk thích ơi là thích xxbos xxmaj chất lượng sản phẩm rất kém . xxmaj rất không đáng tiền xxbos xxmaj giao hàng rất nhanh lần này gà hơi bị vụng cơm cháy nát</td>\n",
       "      <td>xxmaj giày đẹp nhưng chắc đi nhanh hỏng xxrep 3 😂 xxbos xxmaj bảo hỗn hợp nhưng toàn là xxunk kẹo dâu chắc được tầm chục cái @@ xxbos xxmaj nhấn tần vài lần là bọt tung xxunk thích ơi là thích xxbos xxmaj chất lượng sản phẩm rất kém . xxmaj rất không đáng tiền xxbos xxmaj giao hàng rất nhanh lần này gà hơi bị vụng cơm cháy nát và</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxmaj shop phục vụ rất kém mình đặt 4 bộ thì 1 bộ giao sai mẫu 1 bộ giao thiếu mũ . xxmaj liên hệ với shop nói mình đồng ý nhận bộ sai xxunk chỉ yêu cầu shop gửi mũ cho mình chứ mình không trả hàng lại xxunk đọc tin nhắn rồi i m lặng không đáng bao nhiêu tiền nhưng làm ăn mất uy tín quá xxbos đóng gói</td>\n",
       "      <td>shop phục vụ rất kém mình đặt 4 bộ thì 1 bộ giao sai mẫu 1 bộ giao thiếu mũ . xxmaj liên hệ với shop nói mình đồng ý nhận bộ sai xxunk chỉ yêu cầu shop gửi mũ cho mình chứ mình không trả hàng lại xxunk đọc tin nhắn rồi i m lặng không đáng bao nhiêu tiền nhưng làm ăn mất uy tín quá xxbos đóng gói sản</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxbos xxmaj mình đặt giao ngày thứ 3 vừa rồi thì thấy thiếu postcard và lịch nên liên hệ cho tiki ngay thế mà nói xem lại rồi xxunk ba ngày vẫn chưa thấy gọi lại ! xxmaj mong tiki khắc phục sự cố này xxbos xxmaj good product quality \\n▁ xxmaj excellent service by seller \\n▁ xxmaj fast delivery xxbos xxmaj xấu . xxmaj toàn dính vào đi mấy ngày là</td>\n",
       "      <td>xxmaj mình đặt giao ngày thứ 3 vừa rồi thì thấy thiếu postcard và lịch nên liên hệ cho tiki ngay thế mà nói xem lại rồi xxunk ba ngày vẫn chưa thấy gọi lại ! xxmaj mong tiki khắc phục sự cố này xxbos xxmaj good product quality \\n▁ xxmaj excellent service by seller \\n▁ xxmaj fast delivery xxbos xxmaj xấu . xxmaj toàn dính vào đi mấy ngày là bung</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_sen.show_batch(max_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vi_wt', 'vi_wt_vocab']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_fns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Load params and vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('/home/quantran/.fastai/data/viwiki/models/vi_wt.pth'),\n",
       " Path('/home/quantran/.fastai/data/viwiki/models/vi_wt_vocab.pkl')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[mdl_path/(lm_fns[0]+'.pth'),mdl_path/(lm_fns[1] + '.pkl')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Recreating def load_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wgts = torch.load(mdl_path/(lm_fns[0]+'.pth'), map_location = lambda storage,loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16880, 400]), torch.Size([4608, 1152]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgts['0.encoder.weight'].shape,wgts['0.rnns.0.weight_hh_l0_raw'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn_sen = language_model_learner(dls_sen, \n",
    "                               AWD_LSTM, \n",
    "                               metrics=[accuracy, Perplexity()],\n",
    "                               drop_mult=1.0,\n",
    "                               pretrained_fnames=lm_fns,\n",
    "                               path=path).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# bs=64\n",
    "# bs=24\n",
    "bs=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "lr *= bs/48."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5128"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls_sen.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(5128, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(5128, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=5128, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_sen.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['torch.Size([4608, 1152]): False',\n",
       " 'torch.Size([4608, 400]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([4608, 1152]): False',\n",
       " 'torch.Size([4608, 1152]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([1600, 400]): False',\n",
       " 'torch.Size([1600, 1152]): False',\n",
       " 'torch.Size([1600]): False',\n",
       " 'torch.Size([1600]): False',\n",
       " 'torch.Size([5128, 400]): True',\n",
       " 'torch.Size([5128]): True']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"{getattr(i,'shape')}: {i.requires_grad}\" for l in learn_sen.opt.param_lists for i in l]\n",
    "# all requires_grad true b/c unfreeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.629779</td>\n",
       "      <td>4.114153</td>\n",
       "      <td>0.319868</td>\n",
       "      <td>61.200378</td>\n",
       "      <td>00:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.226692</td>\n",
       "      <td>3.956623</td>\n",
       "      <td>0.331434</td>\n",
       "      <td>52.280468</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.043056</td>\n",
       "      <td>3.915927</td>\n",
       "      <td>0.335153</td>\n",
       "      <td>50.195576</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_sen.fit_one_cycle(3, lr*10, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.970504</td>\n",
       "      <td>3.848961</td>\n",
       "      <td>0.341873</td>\n",
       "      <td>46.944244</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.876658</td>\n",
       "      <td>3.764037</td>\n",
       "      <td>0.350300</td>\n",
       "      <td>43.122166</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.775550</td>\n",
       "      <td>3.710275</td>\n",
       "      <td>0.355639</td>\n",
       "      <td>40.865040</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.702173</td>\n",
       "      <td>3.653225</td>\n",
       "      <td>0.362710</td>\n",
       "      <td>38.598965</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.634814</td>\n",
       "      <td>3.627688</td>\n",
       "      <td>0.365209</td>\n",
       "      <td>37.625713</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.563126</td>\n",
       "      <td>3.611554</td>\n",
       "      <td>0.367025</td>\n",
       "      <td>37.023540</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.509881</td>\n",
       "      <td>3.606653</td>\n",
       "      <td>0.367896</td>\n",
       "      <td>36.842525</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.499975</td>\n",
       "      <td>3.606580</td>\n",
       "      <td>0.367998</td>\n",
       "      <td>36.839863</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_sen.unfreeze()\n",
    "learn_sen.fit_one_cycle(8, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn_sen.save_encoder('finetuned_sen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Check how word embedding and hidden state are loaded to sentiment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or this https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-10-422d87c3340c\n",
    "# https://nlp.fast.ai/\n",
    "# watch https://www.youtube.com/watch?v=vnOpEwmtFJ8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## prepare text clas datablock and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# bs=64\n",
    "# bs=24\n",
    "bs=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df.loc[pd.isna(train_df.comment),'comment']='NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_000000</td>\n",
       "      <td>Dung dc sp tot cam on \\nshop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_000001</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_000002</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_000003</td>\n",
       "      <td>:(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_000004</td>\n",
       "      <td>Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý :((</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  \\\n",
       "0  train_000000   \n",
       "1  train_000001   \n",
       "2  train_000002   \n",
       "3  train_000003   \n",
       "4  train_000004   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  comment  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                       Dung dc sp tot cam on \\nshop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                       Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                 Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất   \n",
       "3  :(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                  Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý :((   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.576863\n",
       "1    0.423137\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sen_db = DataBlock(blocks=(TextBlock.from_df('comment', seq_len=72, vocab=dls_sen.vocab), CategoryBlock),\n",
    "                      get_x=ColReader('text'), # fixed value\n",
    "                      get_y=ColReader('label'),\n",
    "                      splitter=RandomSplitter(valid_pct=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting-up type transforms pipelines\n",
      "Collecting items from                  id  \\\n",
      "0      train_000000   \n",
      "1      train_000001   \n",
      "2      train_000002   \n",
      "3      train_000003   \n",
      "4      train_000004   \n",
      "...             ...   \n",
      "16082  train_016082   \n",
      "16083  train_016083   \n",
      "16084  train_016084   \n",
      "16085  train_016085   \n",
      "16086  train_016086   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       comment  \\\n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Dung dc sp tot cam on \\nshop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời   \n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh   \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất   \n",
      "3                                                                                                                       :(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...   \n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý :((   \n",
      "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ...   \n",
      "16082                                                                                                                                                                                                                                                                                                                                                                                                       Chẳng biết là Shop có biết đọc hay không mua ốp có mỗi 3 mầu xanh - đen - đỏ. Ngta đã inbox hỏi rõ là còn hàng không kêu có mà đặt 2 cái 1 đen 1 xanh ghi chú rõ xong gửi 1 đỏ 1 xanh chán đời - về học lại chữ đi   \n",
      "16083  Cuốn này mỏng. Đọc một buổi sáng là hết. Thú thật nó làm tôi hơi thất vọng có thể vì tôi đã kì vọng hơi cao vào tác phẩm Hàn Quốc đầu tiên trong đời. Nhưng thôi tôi sẽ cố gắng nhận xét khách quan nhất có thể.\\nTuy đặt vào tình huống đau buồn - sau sự ra đi của một cậu học sinh mới mười sáu tuổi - nhưng Tôi đã chết vào một ngày nào đó không quá u ám nặng nề. Thay vì khai thác tột cùng nỗi đau và mất mát, tác giả cố gắng xoa dịu nó, hàn gắn nó bằng những kí ức tươi đẹp, những suy tư giản dị, gần gũi và những tình cảm chân thành. Truyện kể theo lời nhân vật Yoo Mi - bạn thân nhất của cậu bé đ...   \n",
      "16084                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Mang êm chân. Đẹp    \n",
      "16085                                                 Tôi đã nhận đc hàng.Sau đây là vài lời muốn nói.\\nMã code để check hàng chính hãng không tồn tại trên trang web của hãng. Mặc dù chính tôi cào nó ra. Có dấu hiệu đã bị mở hộp, vỏ ngoài lem lem.\\nTôi đã tin tưởng vào mã code, vì nhiều lần mua hàng của digiworl, nhưng đến hôm nay tikitrading đã làm mất hình ảnh đó.\\nMón đồ không quá đắt đỏ mua được sự gian dối của tikitrading quá là hời cho tôi.\\nNếu đây là món hàng vài chục triệu thì sao ?\\nTất nhiên tôi sẽ làm sáng toả mọi chuyện trên các diễn đàn công nghệ.\\nOK xem như tôi đặt niềm tin nhầm chỗ.   \n",
      "16086                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Hình vậy mà túi xấu qá kém chất lg qá   \n",
      "\n",
      "       label  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          1  \n",
      "4          1  \n",
      "...      ...  \n",
      "16082      1  \n",
      "16083      1  \n",
      "16084      0  \n",
      "16085      1  \n",
      "16086      1  \n",
      "\n",
      "[16087 rows x 3 columns]\n",
      "Found 16087 items\n",
      "2 datasets of sizes 14479,1608\n",
      "Setting up Pipeline: ColReader -> Tokenizer -> Numericalize\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Pipeline: ColReader -> Categorize\n",
      "\n",
      "Building one sample\n",
      "  Pipeline: ColReader -> Tokenizer -> Numericalize\n",
      "    starting from\n",
      "      id                                                                                                                  train_003187\n",
      "label                                                                                                                          0\n",
      "text           [xxbos, xxmaj, shop, phục, vụ, rất, tốt, đây, là, lần, thứ, 2, mua, hàng, ở, shop, r, và, sẽ, ủng, hộ, shop, dài]\n",
      "text_length                                                                                                                   23\n",
      "Name: 3187, dtype: object\n",
      "    applying ColReader gives\n",
      "      (#23) ['xxbos','xxmaj','shop','phục','vụ','rất','tốt','đây','là','lần'...]\n",
      "    applying Tokenizer gives\n",
      "      (#23) ['xxbos','xxmaj','shop','phục','vụ','rất','tốt','đây','là','lần'...]\n",
      "    applying Numericalize gives\n",
      "      TensorText of size 23\n",
      "  Pipeline: ColReader -> Categorize\n",
      "    starting from\n",
      "      id                                                                                                                  train_003187\n",
      "label                                                                                                                          0\n",
      "text           [xxbos, xxmaj, shop, phục, vụ, rất, tốt, đây, là, lần, thứ, 2, mua, hàng, ở, shop, r, và, sẽ, ủng, hộ, shop, dài]\n",
      "text_length                                                                                                                   23\n",
      "Name: 3187, dtype: object\n",
      "    applying ColReader gives\n",
      "      0\n",
      "    applying Categorize gives\n",
      "      TensorCategory(0)\n",
      "\n",
      "Final sample: (TensorText([  2,   8,  14,  48,  45,  10,  32, 237,  33,  69, 267,  70,  25,  13,\n",
      "        153,  14, 558,  19,  72,  98,  95,  14, 121]), TensorCategory(0))\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up after_item: Pipeline: ToTensor\n",
      "Setting up before_batch: Pipeline: partial\n",
      "Setting up after_batch: Pipeline: \n",
      "\n",
      "Building one batch\n",
      "Applying item_tfms to the first sample:\n",
      "  Pipeline: ToTensor\n",
      "    starting from\n",
      "      (TensorText of size 23, TensorCategory(0))\n",
      "    applying ToTensor gives\n",
      "      (TensorText of size 23, TensorCategory(0))\n",
      "\n",
      "Adding the next 1 samples\n",
      "\n",
      "Applying before_batch to the list of samples\n",
      "  Pipeline: partial\n",
      "    starting from\n",
      "      [(TensorText of size 23, TensorCategory(0)), (TensorText of size 107, TensorCategory(1))]\n",
      "    applying partial gives\n",
      "      [(TensorText of size 107, TensorCategory(0)), (TensorText of size 107, TensorCategory(1))]\n",
      "\n",
      "Collating items in a batch\n",
      "\n",
      "No batch_tfms to apply\n"
     ]
    }
   ],
   "source": [
    "sen_db.summary(train_df,bs=2)\n",
    "# note: there is before_batch (partial func) that probably does the padding and make sure \n",
    "# tensor size is equal among batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_clas = sen_db.dataloaders(train_df, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: partial"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls_clas.before_batch # maybe in text dataloader definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dls_clas = TextDataLoaders.from_df(train_df, path=path, text_col='comment', \n",
    "#                                    text_vocab = dls_sen.vocab,\n",
    "#                                    label_col='label',\n",
    "#                                   valid_pct=0.1,\n",
    "#                                   seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj cuốn này mỏng . đọc một buổi sáng là hết . xxmaj thú thật nó làm tôi hơi thất vọng có thể vì tôi đã kì vọng hơi cao vào tác phẩm xxmaj hàn xxmaj quốc đầu tiên trong đời . xxmaj nhưng thôi tôi sẽ cố gắng nhận xét khách quan nhất có thể . \\n xxmaj tuy đặt vào tình huống đau buồn - sau sự ra đi của một cậu học sinh mới mười sáu tuổi - nhưng xxmaj tôi đã chết vào một ngày nào đó không quá u ám nặng nề . xxmaj thay vì khai thác tột cùng nỗi đau và mất mát , tác giả cố gắng xxunk dịu nó , hàn gắn nó bằng những kí ức tươi đẹp , những suy tư giản dị , gần gũi và những tình cảm chân thành . xxmaj truyện kể theo lời</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_clas.show_batch(max_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## study dataloaders and tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " 'xxup',\n",
       " 'xxmaj',\n",
       " '.']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls_clas.vocab[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [0,1]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls_clas.vocab[1] # y labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp_i = iter(dls_clas.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y = next(temp_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 741]), torch.Size([128]))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorText([[   2,    8,  262,  ..., 1022,   44,    9],\n",
       "        [   1,    1,    1,  ...,    1,    1,    1],\n",
       "        [   1,    1,    1,  ...,    1,    1,    1],\n",
       "        ...,\n",
       "        [   1,    1,    1,  ...,    1,    1,    1],\n",
       "        [   1,    1,    1,  ...,    1,    1,    1],\n",
       "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note: how padding works: https://dev.fast.ai/text.data#Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj cuốn này mỏng . đọc một buổi sáng là hết . xxmaj thú thật nó làm tôi hơi thất vọng có thể vì tôi đã kì vọng hơi cao vào tác phẩm xxmaj hàn xxmaj quốc đầu tiên trong đời . xxmaj nhưng thôi tôi sẽ cố gắng nhận xét khách quan nhất có thể . \\n xxmaj tuy đặt vào tình huống đau buồn - sau sự ra đi của một cậu học sinh mới mười sáu tuổi - nhưng xxmaj tôi đã chết vào một ngày nào đó không quá u ám nặng nề . xxmaj thay vì khai thác tột cùng nỗi đau và mất mát , tác giả cố gắng xxunk dịu nó , hàn gắn nó bằng những kí ức tươi đẹp , những suy tư giản dị , gần gũi và những tình cảm chân thành . xxmaj truyện kể theo lời nhân vật xxmaj yoo xxmaj mi - bạn thân nhất của cậu bé đã chết - nên từng kí ức lại càng xxunk xxunk , từng tiếng cười lại càng giòn tan đến nao lòng . \\n đúng như lời giới thiệu , truyện mở đầu bằng bi kịch nhưng không kết thúc trong đau thương , mà ngược lại gieo vào lòng ta những hi vọng . xxmaj cái chết mang lại cho ta nhiều hơn những gì ta tưởng . xxmaj ta biết yêu cuộc sống hơn . xxmaj ta biết trân trọng những người xung quanh ta hơn . xxmaj ta nhận ra sự tồn tại của ta không hề vô nghĩa . xxup và ta cũng thấy được thế giới này có ý nghĩa lớn lao với ta thế nào . \\n xxmaj bởi vì , chẳng phải cậu xxmaj jae xxmaj joon đã từng giả chết để được sống tốt hơn đó sao ? \\n\\n đọc truyện , đôi lúc tôi thấy giật mình bởi những chi tiết mà có lẽ chính tác giả khi viết còn chẳng buồn để ý đến . xxmaj jae xxmaj joon đã học lớp tám rồi mà vẫn trong sáng đến kì xxunk . xxup cô giáo chủ nhiệm lớp tám sa sả những lời chẳng ra gì vào mặt xxmaj yoo xxmaj mi . xxmaj yoo xxmaj mi lớn lên cách biệt , mặc cảm , nổi loạn vì cha mẹ ly dị , và rằng xung quanh cô bé chẳng có ai phải trải qua điều đó cả . xxmaj hay mẹ của xxmaj jae xxmaj joon dễ dàng phát bệnh mỗi khi cậu làm bài kiểm tra không tốt … xxmaj tôi chưa từng thực sự tiếp xúc với con người xxmaj hàn xxmaj quốc bao giờ , nên không thể hiểu được họ . xxmaj xxunk xxmaj xxunk \" \" nâng cấp \" \" những chi tiết đó thì không nói làm gì , nhưng nếu tất cả đều là thực tế ở quốc gia đông á kia ? xxmaj phải chăng tôi đã thoáng thấy một đất nước có kinh tế phát triển quá nhanh , nhanh đến mức xã hội không xxunk theo nổi , và hệ xxunk là sinh ra những con người cô đơn , yếu đuối trở nên bi quan một cách dễ dàng , vẫn mang đầy những tư tưởng định kiến ? đáng nói hơn , những điều đó được viết ra bằng một giọng văn xxunk nhiên như thể tất cả đều rất bình thường , là chuyện đương nhiên , trong hoàn cảnh như vậy lẽ tất yếu con người phải cư xử như vậy , không bàn cãi … xxup và tôi tự hỏi , đó là bước tiến hay bước lùi trong việc bảo vệ con người ? \\n\\n xxup có hai điểm khiến tôi chưa hài lòng về cuốn sách này . \\n xxmaj thứ nhất là , xây dựng nhân vật thiên về kể lể nhiều hơn là để nhân vật tự xxunk lộ bản thân , nên cảm giác các nhân vật cứ nhàn nhạt , không tạo ấn tượng sâu sắc . \\n xxmaj thứ hai là , truyện không bắt được người đọc phải suy ngẫm , gấp cuốn sách lại nội dung truyện cứ thế trôi xxunk tuột , không đọng lại gì nhiều . \\n xxmaj nhưng đối với một tác phẩm dành cho thiếu niên như vậy cũng đủ để nhận những lời khen xứng đáng .'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([dls_clas.vocab[0][i] for i in x[0].cpu().data.numpy()]) # no padding here at 1st item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxbos xxmaj cuốn sách này của xxup tờ xxmaj pi mình không mua mà đọc được nó khi một người bạn giới thiệu và cho mượn .khi đọc xong cuốn sách này thì mình cảm thấy một điều là chưa đủ . \\n xxmaj tác giả chưa đủ trải , câu chuyện chưa đủ ngấm . xxmaj các bạn trẻ khi đọc vào có thể cảm thấy , ừ tác phẩm này rất đời , rất thực ấy chứ . xxmaj nhưng với mình như thế vẫn là chưa đủ cho một tác phẩm mang tính phản ánh xã hội . xxmaj khi mà tác giả mượn những câu chuyện thường ngày , mượn những điều gần gũi , chân thực với mỗi chúng ta để xxunk lộ , cắt lát nhiều khía cạnh cuộc sống thì mình thấy tác giả phải đủ trải hay ít nhất là đủ hiểu về những điều ấy đã . xxmaj những câu chuyện này , những cảm xúc này tác giả kể lại chỉ với một cách nhìn của người ngoài cuộc , điều đó là lẽ dĩ nhiên . xxmaj mình không nói viết văn là phải viết những thứ bản thân đã trải nghiệm nhưng xxunk chốt là thực sự cảm hóa được những gì mình viết ra . xxmaj nhưng ở đây tác giả chưa làm được điều đó , hoặc là mình chưa thể cảm nhận được điều đó . xxmaj cách nhìn trung lập y như khi bạn buôn bán một câu chuyện của người nào đó xung quanh mình . xxup nó chưa đủ sức gợi cũng chưa thể bật lên những cảm xúc cần thiết phải có , ta thấy như tác giả chỉ là kể lại một câu chuyện thường ngày , hay một câu chuyện quen mà chúng ta vẫn hay nghe đó thôi . \\n xxmaj chính vì những câu chuyện này chỉ mang tính kể nên có bạn nhận xét là nó xxup trào xxup phúng thì mình không đồng ý . xxup nó chưa đủ thấm chưa đủ sâu để được gọi là trào phúng . xxmaj khi nào mà ta đọc những câu chuyện kể thường ngày tưởng chứng chẳng thể hiện ra được cái gì nhưng ngay từ bản chất nó đã là một sự lên án , tố cáo những mặt xấu xã hội đó mới gọi là trào phúng . xxmaj giống như khi bạn đọc xxup số đỏ , xxmaj lão xxmaj xxunk , xxmaj chí xxmaj xxunk , … đấy cũng chỉ là câu chuyện bình thường , con người bình thường của cả cái xã hội thời ấy nhưng tin chắc bạn thấm được nhiều hơn những điều bình thường ấy . \\n đó cũng là lý giải cho tại sao những tác phẩm ấy có một sức sống lâu bền cùng năm tháng . \\n xxmaj nói chung thì mình vẫn ủng hộ và mong xxup tờ xxmaj pi có thể viết tiếp và trau dồi bản thân hơn để có những tác phẩm đời hơn nữa . ! xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([dls_clas.vocab[0][i] for i in x[1].cpu().data.numpy()]) # padding starts at 2nd item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 5])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(temp_i)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   2, 1133,  264,  118,   66],\n",
       "         [   2,   20,  659,  976, 3590],\n",
       "         [   2, 2849,  693,  538,  591],\n",
       "         [   2,   40,  680,   38, 1160],\n",
       "         [   2,    8,   13,  118,   66]], device='cuda:0'),\n",
       " tensor([[   2,    0,    1,    1,    1],\n",
       "         [   2,   38,    1,    1,    1],\n",
       "         [   2, 1026,    1,    1,    1],\n",
       "         [   2, 1299,    1,    1,    1],\n",
       "         [   2, 4384,    1,    1,    1]], device='cuda:0'))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5],x[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos giay kg giống hình'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([dls_clas.vocab[0][i] for i in x[0].cpu().data.numpy()]) # no padding here at 1st item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos được xxpad xxpad xxpad'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([dls_clas.vocab[0][i] for i in x[-4].cpu().data.numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SortedDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai2.text.data.SortedDL"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dls_clas.train) #inherit TfmdDL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataLoader that goes throught the item in the order given by sort_func\n",
    "\n",
    "res is the result of sort_func applied on all elements of the dataset. You can pass it if available to make the init faster by avoiding an initial pass over the whole dataset. If shuffle is True, this will shuffle a bit the results of the sort **to have items of roughly the same size in batches**, but not in the exact sorted order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: partial"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls_clas.before_batch # this is pad_input_chunk function\n",
    "\n",
    "# 'before_batch': partial(pad_input_chunk, seq_len=seq_len)\n",
    "# https://dev.fast.ai/text.data#SortedDL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## datablock tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai2.data.block.DataBlock"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vnmese_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sen_db = DataBlock(blocks=(TextBlock.from_df('comment', seq_len=72, vocab=dls_sen.vocab), CategoryBlock),\n",
    "#                       get_x=ColReader('text'), # fixed value\n",
    "#                       get_y=ColReader('label'),\n",
    "#                       splitter=RandomSplitter(valid_pct=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sen_db.type_tfms) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Tokenizer: (str,object) -> encodes\n",
       "(Path,object) -> encodes (object,object) -> decodes,Numericalize: (object,object) -> encodes (object,object) -> decodes]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_db.type_tfms[0] # tokenizer and numerialize tfms for X pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [Categorize: (object,object) -> encodes (object,object) -> decodes]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_db.type_tfms[1] # categorize for y pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [ToTensor: (PILMask,object) -> encodes\n",
       "(PILBase,object) -> encodes ]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_db.default_item_tfms #default item tfm (for dataloaders' after_item pipeline) for PILBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#0) []"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_db.default_batch_tfms #default batch item tfm (for dataloaders' after_batch pipeline\n",
    "# normall it will be IntToFloatTensor, but token should be int so nothing is here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#1) [ToTensor: (PILMask,object) -> encodes\n",
       " (PILBase,object) -> encodes ],\n",
       " (#0) [])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_db.item_tfms,sen_db.batch_tfms \n",
    "# nothing different from default_item_tfms and default_batch_tfms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## datasets and its tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1608, 14479)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls_clas.valid.dataset),len(dls_clas.train.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dsets = dls_clas.train.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, 2)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dsets[0]),len(dsets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_ds = dls_clas.train_ds\n",
    "\n",
    "val_ds = dls_clas.valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, fastai2.data.core.TfmdLists, fastai2.data.core.TfmdLists)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds.tls),type(train_ds.tls[0]),type(train_ds.tls[1]) # 2 tfmdlist, 1 for X train, 1 for y train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Pipeline: ColReader -> Tokenizer -> Numericalize,\n",
       " Pipeline: ColReader -> Tokenizer -> Numericalize)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0].tfms,val_ds.tls[0].tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Pipeline: ColReader -> Categorize, Pipeline: ColReader -> Categorize)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[1].tfms,val_ds.tls[1].tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8903</th>\n",
       "      <td>train_008903</td>\n",
       "      <td>1</td>\n",
       "      <td>[xxbos, xxmaj, trả, tiền, nhưng, ko, giao, hàng]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>train_002526</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, xxmaj, rất, đẹp, và, chắc, chắn, .]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>train_000191</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, xxmaj, chất, lượng, sản, phẩm, tuyệt, vời, \\n\\n ▁, đóng, gói, sản, phẩm, rất, đẹp, và, chắc, chắn, \\n , đóng, gói, sản, phẩm, rất, đẹp, và, chắc, chắn]</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>train_009999</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, xxmaj, giao, hàng, rất, nhanh, (, chỉ, sau, 1, ngày, )]</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3447</th>\n",
       "      <td>train_003447</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, xxmaj, hỏi, shop, có, hủ, ko, xxrep, 3, ?, xxmaj, shop, nói, có, và, cho, mình, 1, cái, bịch, túi, zip, to, chà, bá, :, xxrep, 5, )]</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>train_005110</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, xxmaj, gởi, ko, đúng, màu]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8418</th>\n",
       "      <td>train_008418</td>\n",
       "      <td>1</td>\n",
       "      <td>[xxbos, xxmaj, mua, 3, cái, áo, cùng, là, size, m, mà, lại, có, 3, cỡ, khác, nhau, ., xxmaj, mọi, người, mua, hàng, lưu, ý, size, không, đúng, thực, tế, xíu, nào, cả, nha, ., xxmaj, shop, phục, vụ, rất, kém, xxmaj, rất, không, đáng, tiền]</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6051</th>\n",
       "      <td>train_006051</td>\n",
       "      <td>1</td>\n",
       "      <td>[xxbos, xxmaj, máy, ko, sạc, được, chỉ, chạy, được, khi, bỏ, bin, thôi]</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>train_001267</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, xxmaj, ok, nazz]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11303</th>\n",
       "      <td>train_011303</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, ăn, ngon, ,, xxmaj, chất, lượng, sản, phẩm, tuyệt, vời, \\n, xxmaj, shop, phục, vụ, tốt]</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14479 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  label  \\\n",
       "8903   train_008903      1   \n",
       "2526   train_002526      0   \n",
       "191    train_000191      0   \n",
       "9999   train_009999      0   \n",
       "3447   train_003447      0   \n",
       "...             ...    ...   \n",
       "5110   train_005110      0   \n",
       "8418   train_008418      1   \n",
       "6051   train_006051      1   \n",
       "1267   train_001267      0   \n",
       "11303  train_011303      0   \n",
       "\n",
       "                                                                                                                                                                                                                                                 text  \\\n",
       "8903                                                                                                                                                                                                 [xxbos, xxmaj, trả, tiền, nhưng, ko, giao, hàng]   \n",
       "2526                                                                                                                                                                                                      [xxbos, xxmaj, rất, đẹp, và, chắc, chắn, .]   \n",
       "191                                                                                   [xxbos, xxmaj, chất, lượng, sản, phẩm, tuyệt, vời, \\n\\n ▁, đóng, gói, sản, phẩm, rất, đẹp, và, chắc, chắn, \\n , đóng, gói, sản, phẩm, rất, đẹp, và, chắc, chắn]   \n",
       "9999                                                                                                                                                                                  [xxbos, xxmaj, giao, hàng, rất, nhanh, (, chỉ, sau, 1, ngày, )]   \n",
       "3447                                                                                                     [xxbos, xxmaj, hỏi, shop, có, hủ, ko, xxrep, 3, ?, xxmaj, shop, nói, có, và, cho, mình, 1, cái, bịch, túi, zip, to, chà, bá, :, xxrep, 5, )]   \n",
       "...                                                                                                                                                                                                                                               ...   \n",
       "5110                                                                                                                                                                                                               [xxbos, xxmaj, gởi, ko, đúng, màu]   \n",
       "8418   [xxbos, xxmaj, mua, 3, cái, áo, cùng, là, size, m, mà, lại, có, 3, cỡ, khác, nhau, ., xxmaj, mọi, người, mua, hàng, lưu, ý, size, không, đúng, thực, tế, xíu, nào, cả, nha, ., xxmaj, shop, phục, vụ, rất, kém, xxmaj, rất, không, đáng, tiền]   \n",
       "6051                                                                                                                                                                          [xxbos, xxmaj, máy, ko, sạc, được, chỉ, chạy, được, khi, bỏ, bin, thôi]   \n",
       "1267                                                                                                                                                                                                                         [xxbos, xxmaj, ok, nazz]   \n",
       "11303                                                                                                                                                 [xxbos, ăn, ngon, ,, xxmaj, chất, lượng, sản, phẩm, tuyệt, vời, \\n, xxmaj, shop, phục, vụ, tốt]   \n",
       "\n",
       "       text_length  \n",
       "8903             8  \n",
       "2526             8  \n",
       "191             28  \n",
       "9999            12  \n",
       "3447            29  \n",
       "...            ...  \n",
       "5110             6  \n",
       "8418            46  \n",
       "6051            13  \n",
       "1267             4  \n",
       "11303           17  \n",
       "\n",
       "[14479 rows x 4 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0].items \n",
    "# no transform applied yet, but note that texts have already been 'ColReader' and 'Tokenizer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorText([  2,   8, 114,  36,  34,  28,  17,  13]), 8)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0][0],len(train_ds.tls[0][0]) # when indexed, tfms are applied (last one: Numericalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxbos', 'xxmaj', 'trả', 'tiền', 'nhưng', 'ko', 'giao', 'hàng']"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[train_ds.vocab[0][i] for i in train_ds.tls[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define sentiment clas learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.5, \n",
    "                                     metrics=[accuracy,F1Score()],\n",
    "                                    seq_len=72,\n",
    "                                    path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/quantran/.fastai/data/viwiki')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_clas.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas = learn_clas.load_encoder('finetuned_sen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05333333333333333"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=2e-2\n",
    "lr *= bs/48\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(fastai2.text.learner.TextLearner, fastai2.text.models.core.SequentialRNN, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(learn_clas),type(learn_clas.model),len(learn_clas.model) # no more LMLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceEncoder(\n",
       "  (module): AWD_LSTM(\n",
       "    (encoder): Embedding(5128, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(5128, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_clas.model[0] # same as LMLearner model\n",
    "\n",
    "# The model uses a SentenceEncoder, \n",
    "# which means the texts are passed seq_len tokens at a time, \n",
    "# and WILL ONLY COMPUTE THE GRADIENTS on the last max_len steps (default to 1440)\n",
    "\n",
    "# This will take care of the question: some reviews are long, how to know we have \n",
    "# fetched an entire review before gradient can be computed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoolingLinearClassifier(\n",
       "  (layers): Sequential(\n",
       "    (0): LinBnDrop(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): LinBnDrop(\n",
       "      (0): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=50, out_features=2, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_clas.model[1] # not linear decoder\n",
    "# 1200 is 400*3, or (the size of hidden state activation of last LSTM) * 3\n",
    "# which includes: [last_hidden, max_pool, avg_pool]\n",
    "# learn how that is calculated: http://dev.fast.ai/text.models.core#masked_concat_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### param groups and weight shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn_clas.opt.param_lists) # 5 layers total for discriminative fine tuning\n",
    "# since no longer doing 'tie_weight': the word embedding weight is now separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5128"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls_clas.vocab[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5128, 400])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_clas.opt.param_lists[0][0].shape # the word embedding weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['torch.Size([5128, 400]): False',\n",
       " 'torch.Size([4608, 1152]): False',\n",
       " 'torch.Size([4608, 400]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([4608, 1152]): False',\n",
       " 'torch.Size([4608, 1152]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([1600, 400]): False',\n",
       " 'torch.Size([1600, 1152]): False',\n",
       " 'torch.Size([1600]): False',\n",
       " 'torch.Size([1600]): False',\n",
       " 'torch.Size([1200]): True',\n",
       " 'torch.Size([1200]): True',\n",
       " 'torch.Size([50, 1200]): True',\n",
       " 'torch.Size([50]): True',\n",
       " 'torch.Size([50]): True',\n",
       " 'torch.Size([2, 50]): True']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"{getattr(i,'shape')}: {i.requires_grad}\" for l in learn_clas.opt.param_lists for i in l]\n",
    "# all requires_grad true b/c unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn_clas.model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.module.encoder.weight: torch.Size([5128, 400])',\n",
       " '0.module.encoder_dp.emb.weight: torch.Size([5128, 400])',\n",
       " '0.module.rnns.0.weight_hh_l0_raw: torch.Size([4608, 1152])',\n",
       " '0.module.rnns.0.module.weight_ih_l0: torch.Size([4608, 400])',\n",
       " '0.module.rnns.0.module.bias_ih_l0: torch.Size([4608])',\n",
       " '0.module.rnns.0.module.bias_hh_l0: torch.Size([4608])',\n",
       " '0.module.rnns.1.weight_hh_l0_raw: torch.Size([4608, 1152])',\n",
       " '0.module.rnns.1.module.weight_ih_l0: torch.Size([4608, 1152])',\n",
       " '0.module.rnns.1.module.bias_ih_l0: torch.Size([4608])',\n",
       " '0.module.rnns.1.module.bias_hh_l0: torch.Size([4608])',\n",
       " '0.module.rnns.2.weight_hh_l0_raw: torch.Size([1600, 400])',\n",
       " '0.module.rnns.2.module.weight_ih_l0: torch.Size([1600, 1152])',\n",
       " '0.module.rnns.2.module.bias_ih_l0: torch.Size([1600])',\n",
       " '0.module.rnns.2.module.bias_hh_l0: torch.Size([1600])',\n",
       " '1.layers.0.0.weight: torch.Size([1200])',\n",
       " '1.layers.0.0.bias: torch.Size([1200])',\n",
       " '1.layers.0.0.running_mean: torch.Size([1200])',\n",
       " '1.layers.0.0.running_var: torch.Size([1200])',\n",
       " '1.layers.0.0.num_batches_tracked: torch.Size([])',\n",
       " '1.layers.0.2.weight: torch.Size([50, 1200])',\n",
       " '1.layers.1.0.weight: torch.Size([50])',\n",
       " '1.layers.1.0.bias: torch.Size([50])',\n",
       " '1.layers.1.0.running_mean: torch.Size([50])',\n",
       " '1.layers.1.0.running_var: torch.Size([50])',\n",
       " '1.layers.1.0.num_batches_tracked: torch.Size([])',\n",
       " '1.layers.1.2.weight: torch.Size([2, 50])']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{k}: {v.shape}' for k,v in learn_clas.model.state_dict().items()]\n",
    "# for some reason state_dict includes encoder (embedding) weight, but opt.param_lists or model.parameters don't\n",
    "# because weighs of embedding (encoder) and weight of last linear layer is the same\n",
    "# because of 'tie_weights': look at awdlstm.py, in awd_lstm_lm_config 'tie_weights' is True\n",
    "# For language model, tie_weights will make embedding weight == last layer linear weight\n",
    "# Why? More efficient training. This is mentioned in AWD LSTM paper by Stephen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.389166</td>\n",
       "      <td>0.272311</td>\n",
       "      <td>0.876244</td>\n",
       "      <td>0.867067</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.361879</td>\n",
       "      <td>0.259818</td>\n",
       "      <td>0.891169</td>\n",
       "      <td>0.881195</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.373139</td>\n",
       "      <td>0.248702</td>\n",
       "      <td>0.896144</td>\n",
       "      <td>0.883947</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.fit_one_cycle(3, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.save(f'vi_clas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.332855</td>\n",
       "      <td>0.263983</td>\n",
       "      <td>0.878731</td>\n",
       "      <td>0.852608</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.236296</td>\n",
       "      <td>0.214972</td>\n",
       "      <td>0.909826</td>\n",
       "      <td>0.896650</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.freeze_to(-2)\n",
    "learn_clas.fit_one_cycle(2, slice(lr/(2.6**4),lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.259469</td>\n",
       "      <td>0.235889</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.900690</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.201866</td>\n",
       "      <td>0.244321</td>\n",
       "      <td>0.913557</td>\n",
       "      <td>0.903001</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.freeze_to(-3)\n",
    "learn_clas.fit_one_cycle(2, slice(lr/2/(2.6**4),lr/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.save(f'vi_clas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.161196</td>\n",
       "      <td>0.448453</td>\n",
       "      <td>0.907960</td>\n",
       "      <td>0.896648</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.unfreeze()\n",
    "learn_clas.fit_one_cycle(1, slice(lr/10/(2.6**4),lr/10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
