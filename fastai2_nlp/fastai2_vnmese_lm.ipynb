{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/home/quantran/.fastai/data/viwiki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/quantran/.fastai/data/viwiki')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/quantran/.fastai/data/viwiki/docs')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path/'docs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Prepare df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_lol(path): # make list of list containing file name and file content\n",
    "    name = path.stem\n",
    "    with open(path, 'r',encoding=\"utf-8\") as temp:\n",
    "        data = temp.read()\n",
    "    return [name,data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Công nghệ pháp lý\n",
      "\n",
      "Công nghệ pháp lý, còn được gọi là Legal Tech , đề cập đến việc sử dụng công nghệ và phần mềm nhằm cung cấp dịch vụ pháp lý. Các công ty Legal Tech nói chung là các công ty khởi nghiệp được thành lập với mục đích phá vỡ thị trường pháp lý bảo thủ theo truyền thống.\n",
      "\n",
      "Theo truyền thống, công nghệ pháp lý đề cập đến việc ứng dụng công nghệ và phần mềm để giúp các công ty luật quản lý nghiệp vụ, lưu trữ tài liệu, thanh toán, kế toán và khám phá điện tử. Từ năm 2011, Legal Tech đã phát triển để liên kết nhiều hơn với các công ty khởi nghiệp công nghệ phá vỡ việc thực hành pháp luật bằng cách cho mọi người truy cập vào phần mềm trực tuyến làm giảm hoặc trong một số trường hợp loại bỏ sự cần thiết phải hỏi ý kiến luật sư hoặc kết nối mọi người với luật sư hiệu quả hơn thông qua trực tuyến thị trường và các trang web phù hợp với luật sư.\n",
      "\n",
      "Ngành công nghiệp pháp lý được coi là bảo thủ và truyền thống, với Law Technology Today lưu ý rằng \"trong 50 năm, trải nghiệm của khách hàng tại hầu hết các công ty luật hầu như không thay đổi\". Lý do cho điều này bao gồm thực tế là các công ty luật phải đối mặt với các ưu đãi cắt giảm chi phí yếu hơn so với các ngành nghề khác (vì họ giao việc giải ngân trực tiếp cho khách hàng của họ) và được coi là không thích rủi ro (vì một lỗi công nghệ nhỏ có thể gây hậu quả tài chính đáng kể cho khách hàng).\n",
      "\n",
      "Tuy nhiên, sự tăng trưởng của việc thuê các doanh nghiệp tư vấn nội bộ và độ phức tạp ngày càng tăng của họ, cùng với sự phát triển của email, đã dẫn đến việc khách hàng đặt ra áp lực chi phí và thời gian ngày càng tăng lên cho luật sư của họ. Ngoài ra, ngày càng có nhiều khuyến khích để luật sư trở thành người có năng lực về công nghệ, với việc bỏ phiếu của Hiệp hội Luật sư Hoa Kỳ vào tháng 8 năm 2012 để sửa đổi Quy tắc ứng xử chuyên nghiệp để yêu cầu luật sư tuân thủ \"lợi ích và rủi ro liên quan đến công nghệ liên quan\", và sự bão hòa của thị trường khiến nhiều luật sư tìm kiếm những cách thức tiên tiến hơn để cạnh tranh. Sự tăng trưởng theo cấp số nhân của khối lượng tài liệu (chủ yếu là email) phải được xem xét cho các vụ kiện tụng đã thúc đẩy đáng kể việc áp dụng công nghệ được sử dụng trong Khám phá Điện tử, với các yếu tố của ngôn ngữ máy và trí tuệ nhân tạo được kết hợp và các dịch vụ đám mây đã được các công ty luật áp dụng.  \n",
      "\n",
      "Trường Luật Stanford đã thành lập CodeX, Trung tâm Tin học Pháp lý, một trung tâm nghiên cứu liên ngành, cũng bao gồm các công ty được bắt đầu bởi các sinh viên luật và các nhà khoa học máy tính. Một số công ty đã ra khỏi chương trình bao gồm Lex Machina và Legal.io.\n",
      "\n",
      "\n",
      "\n",
      "Tại Việt Nam, tuy LegalTech vẫn còn mới mẻ, nhưng Việt Nam cũng là một thị trường tiềm năng để phát triển ngành này đến từ sự phức tạp trong hệ thống quy định pháp luật, nhu cầu áp dụng luật của doanh nghiệp, sự phát triển của ngành tư vấn luật và tiềm năng sáng tạo của các startup.\n",
      "\n",
      "Việc áp dụng công nghệ không chỉ giúp doanh nghiệp dễ dàng tiếp cận, cập nhật được các chính sách mới mà còn giúp giảm thiểu việc ban hành trùng lặp, chồng chéo các chính sách.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = make_lol((path/'docs').ls()[2])\n",
    "print(temp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77456"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((path/'docs').ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = parallel(make_lol,(path/'docs').ls(),n_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(results,columns=['fname','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77451</th>\n",
       "      <td>Ronda Rousey</td>\n",
       "      <td>Ronda Rousey\\n\\nRonda Jean Rousey ( sinh ngày 1 tháng 2 năm 1987) là một nữ võ sĩ MMA, vận động viên judo, và diễn viên người Mỹ. Cô hiện đang tham gia WWE Raw.\\n\\nRousey là nữ vận động viên đầu tiên của Mỹ giành huy chương judo Olympic (huy chương đồng) ở Thế vận hội Mùa hè 2008. Cô là cựu quán quân UFC nữ hạng gà, cũng như là quán quân nữ hạng gà Strikeforce cuối cùng. Cô từng giành 12 chiến thắng MMA liên tiếp, trong đó có sáu chiến thắng ở Ultimate Fighting Championship (UFC), trước khi để thua trận đầu tiên trước Holly Holm vào tháng 11 năm 2015; cô thắng 11 trận trong hiệp 1, 9 trong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77452</th>\n",
       "      <td>Ngựa cỏ bùn</td>\n",
       "      <td>Ngựa cỏ bùn\\n\\nNgựa cỏ bùn hay Cǎonímǎ (chữ Hán: , phiên âm Hán-Việt: \"thảo nê mã\") là một Internet meme tại Trung Quốc được sử dụng rộng rãi như một dạng biểu tượng nhằm phản đối kiểm duyệt Internet tại Trung Quốc đang ngày càng tăng. Đây là lối chơi chữ với cum từ trong tiếng Trung phổ thông \"cào nǐ mā\" (chữ Hán: , phiên âm Hán-Việt: \"tháo nễ ma\"), nghĩa đen tức là \"địt mẹ mày\" (từ Cǎo/草 là từ \"cấu\" trong từ \"giao cấu\"; ní/泥, tức là từ \"nị\", chỉ ngôi thứ 2, là bạn, mày và từ mǎ/马 là từ \"ma\" hay \"ma ma\" có nghĩa là mẹ hay vú nuôi), và là một trong danh sách 10 sinh vật thần thoại được tạo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77453</th>\n",
       "      <td>Gettext</td>\n",
       "      <td>Gettext\\n\\nTrong điện toán, gettext là một hệ thống quốc tế hóa và bản địa hóa (i18n) thường dùng cho việc viết các ứng dụng đa ngôn ngữ trên các hệ điều hành tương tự Unix. Việc triển khai gettext thường được sử dụng phổ biến nhất là GNU gettext, phát hành bởi GNU Project năm 1995.\\n\\ngettext ban đầu được viết bởi Sun Microsystems vào đầu những năm 1990. GNU Project phát hành GNU gettext, một phần mềm tự do triển khai hệ thống vào năm 1995.\\n\\nMã nguồn được sửa đổi đầu tiên để sử dụng các lệnh gọi GNU gettext. Với phần lớn ngôn ngữ lập trình, việc này được thực hiện bằng cách bao các chuỗ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77454</th>\n",
       "      <td>Rosanna Pansino</td>\n",
       "      <td>Rosanna Pansino\\n\\nRosanna Pansino (sinh ngày 8 tháng 6 năm 1985) là một thợ làm bánh, nữ diễn viên, tác giả và nhân vật YouTube người Mỹ. Cô được biết đến nhiều nhất qua series nấu ăn \"Nerdy Nummies\", một trong những chương trình làm bánh nổi tiếng nhất trên YouTube. Cô cũng thủ vai Violet trong series hoạt hình trên YouTube \"Broken Quest\" và vai The Jet Setter trong series \"Escape the Night\" trên YouTube. Cô có tổ tiên là người Ý, Croatia, Đức và Ireland.\\n\\nPansino ban đầu muốn theo đuổi sự nghiệp làm diễn viên. Cô từng đóng những vai diễn nhỏ trong các tập của \"Parks and Recreation\" và...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77455</th>\n",
       "      <td>Hyperbol</td>\n",
       "      <td>Hyperbol\\n\\nTrong toán học, hyperbol hay hypecbol (từ tiếng Hy Lạp: ὑπερβολή, nghĩa đen là \"vượt quá\" hay \"thái quá\") là một kiểu Đường cô-nic, được định nghĩa là đường giao của một mặt nón với một mặt phẳng cắt cả hai nửa của hình nón.\\n\\nĐường hyperbol còn được định nghĩa là quỹ tích của những điểm trong mặt phẳng có giá trị tuyết đối của hiệu khoảng cách tới hai điểm cố định là một hằng số bằng 2\"a\". \"a\" đồng thời cũng bằng độ dài bán trục lớn của Hyberbol. Hai điểm cố định đó gọi là hai tiêu điểm của hyperbol. Đường thẳng đi qua hai tiêu điểm này được gọi là trục thực của hyberbol và t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 fname  \\\n",
       "77451     Ronda Rousey   \n",
       "77452      Ngựa cỏ bùn   \n",
       "77453          Gettext   \n",
       "77454  Rosanna Pansino   \n",
       "77455         Hyperbol   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          text  \n",
       "77451  Ronda Rousey\\n\\nRonda Jean Rousey ( sinh ngày 1 tháng 2 năm 1987) là một nữ võ sĩ MMA, vận động viên judo, và diễn viên người Mỹ. Cô hiện đang tham gia WWE Raw.\\n\\nRousey là nữ vận động viên đầu tiên của Mỹ giành huy chương judo Olympic (huy chương đồng) ở Thế vận hội Mùa hè 2008. Cô là cựu quán quân UFC nữ hạng gà, cũng như là quán quân nữ hạng gà Strikeforce cuối cùng. Cô từng giành 12 chiến thắng MMA liên tiếp, trong đó có sáu chiến thắng ở Ultimate Fighting Championship (UFC), trước khi để thua trận đầu tiên trước Holly Holm vào tháng 11 năm 2015; cô thắng 11 trận trong hiệp 1, 9 trong...  \n",
       "77452  Ngựa cỏ bùn\\n\\nNgựa cỏ bùn hay Cǎonímǎ (chữ Hán: , phiên âm Hán-Việt: \"thảo nê mã\") là một Internet meme tại Trung Quốc được sử dụng rộng rãi như một dạng biểu tượng nhằm phản đối kiểm duyệt Internet tại Trung Quốc đang ngày càng tăng. Đây là lối chơi chữ với cum từ trong tiếng Trung phổ thông \"cào nǐ mā\" (chữ Hán: , phiên âm Hán-Việt: \"tháo nễ ma\"), nghĩa đen tức là \"địt mẹ mày\" (từ Cǎo/草 là từ \"cấu\" trong từ \"giao cấu\"; ní/泥, tức là từ \"nị\", chỉ ngôi thứ 2, là bạn, mày và từ mǎ/马 là từ \"ma\" hay \"ma ma\" có nghĩa là mẹ hay vú nuôi), và là một trong danh sách 10 sinh vật thần thoại được tạo...  \n",
       "77453  Gettext\\n\\nTrong điện toán, gettext là một hệ thống quốc tế hóa và bản địa hóa (i18n) thường dùng cho việc viết các ứng dụng đa ngôn ngữ trên các hệ điều hành tương tự Unix. Việc triển khai gettext thường được sử dụng phổ biến nhất là GNU gettext, phát hành bởi GNU Project năm 1995.\\n\\ngettext ban đầu được viết bởi Sun Microsystems vào đầu những năm 1990. GNU Project phát hành GNU gettext, một phần mềm tự do triển khai hệ thống vào năm 1995.\\n\\nMã nguồn được sửa đổi đầu tiên để sử dụng các lệnh gọi GNU gettext. Với phần lớn ngôn ngữ lập trình, việc này được thực hiện bằng cách bao các chuỗ...  \n",
       "77454  Rosanna Pansino\\n\\nRosanna Pansino (sinh ngày 8 tháng 6 năm 1985) là một thợ làm bánh, nữ diễn viên, tác giả và nhân vật YouTube người Mỹ. Cô được biết đến nhiều nhất qua series nấu ăn \"Nerdy Nummies\", một trong những chương trình làm bánh nổi tiếng nhất trên YouTube. Cô cũng thủ vai Violet trong series hoạt hình trên YouTube \"Broken Quest\" và vai The Jet Setter trong series \"Escape the Night\" trên YouTube. Cô có tổ tiên là người Ý, Croatia, Đức và Ireland.\\n\\nPansino ban đầu muốn theo đuổi sự nghiệp làm diễn viên. Cô từng đóng những vai diễn nhỏ trong các tập của \"Parks and Recreation\" và...  \n",
       "77455  Hyperbol\\n\\nTrong toán học, hyperbol hay hypecbol (từ tiếng Hy Lạp: ὑπερβολή, nghĩa đen là \"vượt quá\" hay \"thái quá\") là một kiểu Đường cô-nic, được định nghĩa là đường giao của một mặt nón với một mặt phẳng cắt cả hai nửa của hình nón.\\n\\nĐường hyperbol còn được định nghĩa là quỹ tích của những điểm trong mặt phẳng có giá trị tuyết đối của hiệu khoảng cách tới hai điểm cố định là một hằng số bằng 2\"a\". \"a\" đồng thời cũng bằng độ dài bán trục lớn của Hyberbol. Hai điểm cố định đó gọi là hai tiêu điểm của hyperbol. Đường thẳng đi qua hai tiêu điểm này được gọi là trục thực của hyberbol và t...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# result_df.to_csv(path/'alltext.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df = pd.read_csv(path/'alltext.csv',encoding='utf-8')\n",
    "result_df = pd.read_csv(path/'alltext.csv',encoding='utf-8',nrows=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnmese_lm = DataBlock(blocks=TextBlock.from_df('text', is_lm=True),\n",
    "                    get_x=ColReader('text'),\n",
    "                    splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs=64\n",
    "# bs=24\n",
    "bs=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = vnmese_lm.dataloaders(result_df, bs=bs, seq_len=72)\n",
    "# dls.show_batch(max_n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16880"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xxunk', 'xxpad', 'xxbos', 'xxeos', 'xxfld', 'xxrep', 'xxwrep', 'xxup', 'xxmaj', ',', '.', 'và', 'của', '\"', 'là', 'được', 'các', 'một', '\\n\\n', 'trong', 'có', 'năm', 'đã', ')', '(', 'với', 'cho', 'người', 'vào', 'ở', 'không', 'thành', 'từ', 'những', 'khi', 'công', 'tháng', 'đến', '-', 'này', 'ngày', 'tại', 'sau', 'quân', 'đó', 'quốc', 'để', 'ông', 'đầu', 'sự', 'ra', 'thể', 'chính', 'bị', 'về', 'như', 'số', 'nam', 'trên', 'trung', 'lại', 'gia', 'cũng', 'nhà', 'chiến', 'làm', 'đại', 'học', 'động', 'bộ', 'dân', 'theo', 'nhiều', 'nhất', ':', 'việt', 'nước', 'hiện', 'hai', '3', 'phát', 'việc', 'thời', 'thế', 'nhân', 'hành', 'chỉ', 'anh', 'do', 'pháp', 'khác', 'cùng', 'định', 'đồng', 'nó', 'quan', 'bản', 'con', 'hội', 'cuộc']\n"
     ]
    }
   ],
   "source": [
    "print(dls.vocab[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malas', 'donepezil', 'cholinesterase', 'żurakowski', '好', 'き', 'で', 'す', 'takumi', '-photphoryl', 'trochiliformes', 'cypselomorphae', 'blust', 'gujarat', '1.450', 'mxml', 'fayette', 'rocn', 'meeker', 'spitz', 'tatopoulos', 'cnestidium', 'plantes', 'haüy', 'buffon', 'mlền', 'gambiez', 'linarès', 'đă', 'hadhramaut', 'cdc', 'lidia', 'sundar', '嘉順宮', 'l3', 'autosomal', 'engebi', 'veldarad', 'veldt', 'bounnhang', 'vorachith', 'có:<br', 'vnukovo', 'nordaustlandet', 'hopen', 'grumant', 'schengen', 'beloved', 'invisibles', 'baste', 'powter', 'furtado', 'timberlake', 'flexjet', 'eternalblue', 'aiesecer', 'gv', 'youthspeak', 'shindong', 'goong', 'moeyan', 'peleus', 'priam', 'inu', 'monoxide', 'hbco', 'u-110', 'lettera', 'pbdos', 'pence', 'scara', 'toys', 'sketrobo', 'ngõa', 'eustatius', 'saba', 'tncmđch', 'vázquez', 'ayllón', 'spartina', 'nps', 'programmer', 'squeaker', 'ély', 'nolting', 'maneli', 'karnow', 'rattigan', 'iwamoto', 'komi', 'tocantins', 'beginnings', 'starmen.net', 'xxfake', 'xxfake', 'xxfake', 'xxfake', 'xxfake', 'xxfake', 'xxfake']\n"
     ]
    }
   ],
   "source": [
    "print(dls.vocab[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(dls, \n",
    "                               AWD_LSTM, \n",
    "                               metrics=[accuracy, Perplexity()],\n",
    "                               drop_mult=1.0,\n",
    "                               pretrained=False,\n",
    "                               path=path).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026666666666666665"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "lr *= bs/48\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.691417</td>\n",
       "      <td>6.470623</td>\n",
       "      <td>0.102445</td>\n",
       "      <td>645.885986</td>\n",
       "      <td>02:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(1, lr, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try drop_mult 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.453883</td>\n",
       "      <td>6.472377</td>\n",
       "      <td>0.101275</td>\n",
       "      <td>647.020081</td>\n",
       "      <td>02:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = language_model_learner(dls, \n",
    "                               AWD_LSTM, \n",
    "                               metrics=[accuracy, Perplexity()],\n",
    "                               drop_mult=0.5,\n",
    "                               pretrained=False,\n",
    "                               path=path).to_fp16()\n",
    "\n",
    "lr = 1e-2\n",
    "lr *= bs/48\n",
    "lr\n",
    "\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(1, lr, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/quantran/.fastai/data/viwiki/models\n"
     ]
    }
   ],
   "source": [
    "mdl_path = path/'models'\n",
    "print(mdl_path)\n",
    "mdl_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_fns = [f'vi_wt', f'vi_wt_vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.to_fp32().save(mdl_path/lm_fns[0], with_opt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.dls.vocab.save(mdl_path/(lm_fns[1] + '.pkl'))\n",
    "# with open(mdl_path/(lm_fns[1] + '.pkl'), 'wb') as f:\n",
    "#     pickle.dump(learn.dls.vocab, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## try original wikitext param training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "config = awd_lstm_lm_config.copy()\n",
    "config.update({'input_p': 0.6, 'output_p': 0.4, 'weight_p': 0.5, 'embed_p': 0.1, 'hidden_p': 0.2})\n",
    "model = get_language_model(AWD_LSTM, len(dls.vocab), config=config)\n",
    "opt_func = partial(Adam, wd=0.1, eps=1e-7)\n",
    "cbs = [MixedPrecision(clip=0.1), ModelResetter, RNNRegularizer(alpha=2, beta=1)]\n",
    "learn = Learner(dls, model, \n",
    "                loss_func=CrossEntropyLossFlat(), \n",
    "                opt_func=opt_func, \n",
    "                cbs=cbs, metrics=[accuracy, Perplexity()]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>202909.375000</td>\n",
       "      <td>9.725590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16740.558594</td>\n",
       "      <td>03:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 5e-03, moms=(0.8,0.7,0.8), div=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning with sentiment analysis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df.loc[pd.isna(train_df.comment),'comment']='NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_df.loc[pd.isna(test_df.comment),'comment']='NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_000000</td>\n",
       "      <td>Dung dc sp tot cam on \\nshop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_000001</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_000002</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_000003</td>\n",
       "      <td>:(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_000004</td>\n",
       "      <td>Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý :((</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  \\\n",
       "0  train_000000   \n",
       "1  train_000001   \n",
       "2  train_000002   \n",
       "3  train_000003   \n",
       "4  train_000004   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  comment  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                       Dung dc sp tot cam on \\nshop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                       Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                 Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất   \n",
       "3  :(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                  Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý :((   \n",
       "\n",
       "   label  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    1.0  \n",
       "4    1.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([train_df,test_df], sort=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>test_010976</td>\n",
       "      <td>Thời gian giao hàng rất nhanh.ngon.mà cay quá... Chất lượng sản phẩm tuyệt vời</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>test_010977</td>\n",
       "      <td>Sản phẩm hơi cũ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>test_010978</td>\n",
       "      <td>Sản phẩm chắc chắn nhưng k bóng bằng trong hình</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>test_010979</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời có mùi thơm rất dễ chịu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10980</th>\n",
       "      <td>test_010980</td>\n",
       "      <td>như quảng cáo. sim rất tốt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  \\\n",
       "10976  test_010976   \n",
       "10977  test_010977   \n",
       "10978  test_010978   \n",
       "10979  test_010979   \n",
       "10980  test_010980   \n",
       "\n",
       "                                                                               comment  \\\n",
       "10976   Thời gian giao hàng rất nhanh.ngon.mà cay quá... Chất lượng sản phẩm tuyệt vời   \n",
       "10977                                                                  Sản phẩm hơi cũ   \n",
       "10978                                  Sản phẩm chắc chắn nhưng k bóng bằng trong hình   \n",
       "10979                            Chất lượng sản phẩm tuyệt vời có mùi thơm rất dễ chịu   \n",
       "10980                                                       như quảng cáo. sim rất tốt   \n",
       "\n",
       "       label  \n",
       "10976    NaN  \n",
       "10977    NaN  \n",
       "10978    NaN  \n",
       "10979    NaN  \n",
       "10980    NaN  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj máy massage 5 mút mà giao có 4 thiếu không đảm bảo gói hàng sơ sài nhìn không thiện cảm . xxup rẻ đi kèm chất lượng - xxmaj nhắn tin phản hồi sp thì ăn nói thiếu tôn trọng .. xxbos xxmaj chất lượng tạm được xxmaj shop phục vụ rất tốt xxmaj thời gian giao hàng rất nhanh xxbos xxmaj shop phục vụ rất tốt đóng gói sản</td>\n",
       "      <td>xxmaj máy massage 5 mút mà giao có 4 thiếu không đảm bảo gói hàng sơ sài nhìn không thiện cảm . xxup rẻ đi kèm chất lượng - xxmaj nhắn tin phản hồi sp thì ăn nói thiếu tôn trọng .. xxbos xxmaj chất lượng tạm được xxmaj shop phục vụ rất tốt xxmaj thời gian giao hàng rất nhanh xxbos xxmaj shop phục vụ rất tốt đóng gói sản phẩm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gian để đọc nó . xxmaj một cuốn sách không dễ đọc không dành cho các bà mẹ bận xxunk . xxmaj mình đã đọc nửa cuốn sách và không đọng lại trong đầu mình xxunk chút gì cả sách viết không trọng tâm khá lan man . xxmaj tuy bố cục ở mỗi bài viết nhìn ban đầu trông khá chặt chẽ nhưng lại không cần thiết và dài dòng .</td>\n",
       "      <td>để đọc nó . xxmaj một cuốn sách không dễ đọc không dành cho các bà mẹ bận xxunk . xxmaj mình đã đọc nửa cuốn sách và không đọng lại trong đầu mình xxunk chút gì cả sách viết không trọng tâm khá lan man . xxmaj tuy bố cục ở mỗi bài viết nhìn ban đầu trông khá chặt chẽ nhưng lại không cần thiết và dài dòng . xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mình dừng luôn xxbos xxmaj như cái địt k vừa cổ xe vs tốn xxunk quá xxbos xxmaj sản phẩm rất kém bẩn thân máy bị hở trục động cơ bị lệch mặt đáy bị mất 2 đế cao su chống trượt . xxmaj trả lời tin nhắn hỗ trợ chậm . xxmaj shop ko nhiệt tình thiếu thiện cảm . :( xxbos xxmaj chất lượng sản phẩm tuyệt vời . xxmaj</td>\n",
       "      <td>dừng luôn xxbos xxmaj như cái địt k vừa cổ xe vs tốn xxunk quá xxbos xxmaj sản phẩm rất kém bẩn thân máy bị hở trục động cơ bị lệch mặt đáy bị mất 2 đế cao su chống trượt . xxmaj trả lời tin nhắn hỗ trợ chậm . xxmaj shop ko nhiệt tình thiếu thiện cảm . :( xxbos xxmaj chất lượng sản phẩm tuyệt vời . xxmaj rất</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_sen = TextDataLoaders.from_df(df, path=path, text_col='comment', \n",
    "                                  is_lm=True, \n",
    "                                  valid_pct=0.1,\n",
    "                                  seed=42)\n",
    "dls_sen.show_batch(max_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vi_wt', 'vi_wt_vocab']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_sen = language_model_learner(dls_sen, \n",
    "                               AWD_LSTM, \n",
    "                               metrics=[accuracy, Perplexity()],\n",
    "                               drop_mult=1.0,\n",
    "                               pretrained_fnames=lm_fns,\n",
    "                               path=path).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "lr *= bs/48."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.152511</td>\n",
       "      <td>6.019076</td>\n",
       "      <td>0.067690</td>\n",
       "      <td>411.198425</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.058696</td>\n",
       "      <td>5.990380</td>\n",
       "      <td>0.067661</td>\n",
       "      <td>399.566528</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_sen.fit_one_cycle(2, lr*10, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.036370</td>\n",
       "      <td>5.988560</td>\n",
       "      <td>0.067676</td>\n",
       "      <td>398.839935</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.851128</td>\n",
       "      <td>5.646402</td>\n",
       "      <td>0.090719</td>\n",
       "      <td>283.270386</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.631660</td>\n",
       "      <td>5.454767</td>\n",
       "      <td>0.120689</td>\n",
       "      <td>233.870316</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.468768</td>\n",
       "      <td>5.241914</td>\n",
       "      <td>0.158550</td>\n",
       "      <td>189.031525</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.267761</td>\n",
       "      <td>5.027405</td>\n",
       "      <td>0.200832</td>\n",
       "      <td>152.536713</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.145017</td>\n",
       "      <td>4.926765</td>\n",
       "      <td>0.218511</td>\n",
       "      <td>137.932571</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.077459</td>\n",
       "      <td>4.887059</td>\n",
       "      <td>0.233612</td>\n",
       "      <td>132.563156</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5.060335</td>\n",
       "      <td>4.879044</td>\n",
       "      <td>0.235192</td>\n",
       "      <td>131.504837</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_sen.unfreeze()\n",
    "learn_sen.fit_one_cycle(8, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn_sen.save_encoder('finetuned_sen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: prepare for backward lm + sent classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('fastai2': conda)",
   "language": "python",
   "name": "python37664bitfastai2conda023d9f2c3b894be385b0b3b80e252fc1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
