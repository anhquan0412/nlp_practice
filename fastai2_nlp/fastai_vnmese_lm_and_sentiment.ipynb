{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/home/quan/.fastai/data/viwiki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/quan/.fastai/data/viwiki')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/quan/.fastai/data/viwiki/docs')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path/'docs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/quan/.fastai/data/viwiki/models\n"
     ]
    }
   ],
   "source": [
    "mdl_path = path/'models'\n",
    "print(mdl_path)\n",
    "mdl_path.mkdir(exist_ok=True)\n",
    "lm_fns = [f'vi_wt', f'vi_wt_vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [Path('/home/quan/.fastai/data/viwiki/docs/Doug Emhoff.txt'),Path('/home/quan/.fastai/data/viwiki/docs/HMS Myngs (R06).txt'),Path('/home/quan/.fastai/data/viwiki/docs/Xuân La (phường).txt'),Path('/home/quan/.fastai/data/viwiki/docs/Cung điện Goldstein.txt'),Path('/home/quan/.fastai/data/viwiki/docs/Tứ khố toàn thư.txt')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'docs').ls()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note! Dataset: we have a list of txt files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Prepare df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_lol(path): # make list of list containing file name and file content\n",
    "    name = path.stem\n",
    "    with open(path, 'r',encoding=\"utf-8\") as temp:\n",
    "        data = temp.read()\n",
    "    return [name,data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doug Emhoff\n",
      "\n",
      "Douglas Craig Emhoff (sinh ngày 13 tháng 10 năm 1964) là một luật sư người Mỹ và là chồng của Phó Tổng thống đắc cử Kamala Harris. Ông sẽ trở thành \"Đệ nhị Phu quân\" đầu tiên trong lịch sử Mỹ và là người phối ngẫu gốc Do Thái đầu tiên của một phó tổng thống.\n",
      "\n",
      "Emhoff sinh ra tại quận Brooklyn của Thành phố New York, là con trai của bố mẹ gốc Do Thái là bà Barbara (nhũ danh Kanzer) và ông Michael Emhoff. Ông có một anh trai là Andy Emhoff và một em gái là Jamie Emhoff. Ông sống ở New Jersey từ năm 1969 đến năm 1981 trước khi cùng gia đình chuyển đến California năm 17 tuổi. Emhoff lấy bằng Cử nhân Văn học tại Đại học Bang California tại Northridge và bằng Tiến sĩ Luật từ Trường Luật Gould thuộc Viện Đại học Nam California vào năm 1990.\n",
      "\n",
      "Emhoff đã kết hôn 16 năm với người vợ đầu là bà Kerstin Emhoff (nhũ danh Mackin). Họ có hai con, Cole và Ella. Sau khi cuộc hôn nhân thứ nhất kết thúc, ông kết hôn với bà Kamala Harris vào ngày 22 tháng 8 năm 2014, tại Santa Barbara, California. Lúc này bà Kamala đang giữ chức Tổng chưởng lý của tiểu bang California. Tính đến tháng 8 năm 2019, Emhoff và Harris có tổng tài sản ròng ước tính là 5,8 triệu đô la.\n",
      "\n",
      "Kamala Harris là ứng cử viên trong cuộc bầu cử sơ bộ Tổng thống Đảng Dân chủ năm 2020 trước khi rút lui vào tháng 12 năm 2019. Harris được chọn là ứng cử viên phó tổng thống tranh cử cùng Joe Biden cho cuộc bầu cử tổng thống Hoa Kỳ năm 2020 vào ngày 11 tháng 8 năm 2020, khiến Emhoff trở thành người đàn ông thứ ba trong lịch sử Hoa Kỳ trở thành vợ hoặc chồng của một ứng viên phó tổng thống. Khi Harris nhậm chức, Emhoff sẽ trở thành Đệ nhị Phu quân đầu tiên của Hoa Kỳ. Ông cũng sẽ là người phối ngẫu gốc Do Thái đầu tiên của một phó tổng thống Hoa Kỳ.\n",
      "\n",
      "Trong vai trò là Đệ nhị Phu quân, Emhoff sẽ tập trung vào việc đảm bảo việc tiếp cận công lý và đại diện pháp lý trở nên bình đẳng hơn.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = make_lol((path/'docs').ls()[0])\n",
    "print(temp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82346"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((path/'docs').ls()) # number of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Note: doing things in parallel\n",
    "??parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# results = parallel(make_lol,(path/'docs').ls())\n",
    "\n",
    "# result_df = pd.DataFrame(results,columns=['fname','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82341</th>\n",
       "      <td>Vấn đề môi trường ở Indonesia</td>\n",
       "      <td>Vấn đề môi trường ở Indonesia\\n\\nthumb|360px|Các nhân viên cứu hỏa Indonesia đang cố gắng để ngăn chặn lửa rừng ở Nam Kalimantan (2015).\\n\\nCác vấn đề môi trường ở Indonesia liên quan đến mật độ dân số cao và công nghiệp hóa nhanh, và chúng thường được ưu tiên thấp hơn do mức nghèo đói cao và quản lý nguồn lực có hạn chế.\\n\\nCác vấn đề bao gồm nạn phá rừng quy mô lớn (phần lớn là bất hợp pháp) và các vụ cháy rừng liên quan gây ra sương mù dầy đặc ở các khu vực phía Tây Indonesia, Malaysia và Singapore; khai thác quá mức các nguồn tài nguyên biển; và các vấn đề về môi trường liên quan đến q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82342</th>\n",
       "      <td>Cát Vinh</td>\n",
       "      <td>Cát Vinh\\n\\nCát Vinh (, ? – 528) thủ lĩnh khởi nghĩa nông dân Hà Bắc, là lực lượng lớn mạnh nhất trong phong trào Lục Trấn khởi nghĩa phản kháng nhà Bắc Ngụy.\\n\\nBan đầu Cát Vinh là Trấn tướng của trấn Hoài Sóc. Theo phép của nhà Bắc Ngụy, Trấn tướng đều lấy quý tộc Tiên Ti đảm nhiệm, từ đó suy đoán ông cũng là người Tiên Ti.\\n\\nTháng giêng năm Hiếu Xương thứ 2 (526), nguyên Hoài Sóc trấn binh Tiên Vu Tu Lễ tại thành Tả Nhân, Định Châu lãnh đạo khởi nghĩa. Hoài Sóc trấn tướng Cát Vinh tham gia khởi nghĩa.\\n\\nTháng 8, Nguyên Hồng Nghiệp làm phản, giết Tiên Vu Tu Lễ, xin hàng triều đình. Cát...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82343</th>\n",
       "      <td>Pye Wacket</td>\n",
       "      <td>Pye Wacket\\n\\nPye Wacket là mật danh của một tên lửa không đối không dạng thấu kính thử nghiệm được chi nhánh Convair của tập đoàn General Dynamics phát triển vào năm 1957. Dự định là một tên lửa phòng thủ cho máy bay ném bom B-70 Valkyrie Mach 3, chương trình đã cho thấy thử nghiệm đường ống gió khí động học rộng rãi và có vẻ đầy hứa hẹn; tuy nhiên việc hủy bỏ B-70 đã loại bỏ yêu cầu đối với tên lửa, và dự án này cũng bị hủy bỏ luôn.\\n\\nDự án \"Pye Wacket\", được chính thức gọi là Chương trình Lenticular Defense Missile (LDM) và theo số dự án WS-740A, được thành lập vào năm 1958 để đáp ứng ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82344</th>\n",
       "      <td>Giải cờ vua M-Tel</td>\n",
       "      <td>Giải cờ vua M-Tel\\n\\nGiải cờ vua M-Tel, tên chính thức tiếng Bulgaria: М-Тел Мастърс, tiếng Anh M-Tel Masters là một giải cờ vua thường niên được tổ chức từ năm 2005 đến 2009 tại Sofia, thủ đô của Bulgaria. Giải đấu lấy tên theo nhà tài trợ và cũng là nhà tổ chức, công ty mạng di động hàng đầu của Bulgaria M-Tel. Mỗi năm giải mời 6 đại kiện tướng hàng đầu (thường có hệ số điểm Elo trên 2700) tham dự, thi đấu theo thể thức vòng tròn 2 lượt. Địa điểm thi đấu tại khách sạn 5 sao Grand Hotel Sofia. Do những khó khăn về kinh tế, cũng như một số lý do khách quan nên giải đấu không còn được tổ ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82345</th>\n",
       "      <td>Salzburg</td>\n",
       "      <td>Salzburg\\n\\nSalzburg ( ; ; nghĩa đen là \"Salt Fortress\" hay \"Pháo đài muối\"; tiếng Bayern: \"Soizbuag\") là thủ phủ của tiểu bang cùng tên thuộc Cộng hòa Áo. Với 150.269 dân cư, Salzburg là thành phố lớn thứ tư của Áo sau Viên, Graz và Linz.\\n\\nThị trấn nằm trên địa điểm của khu định cư La Mã trước đây của \"Iuvavum\". Salzburg được thành lập như một tòa giám mục vào năm 696 và trở thành trụ sở của tổng giám mục vào năm 798. Nguồn thu nhập chính của nó là khai thác và buôn bán muối và đôi khi là khai thác vàng. Pháo đài Hohensalzburg, một trong những pháo đài thời trung cổ lớn nhất ở châu Âu, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               fname  \\\n",
       "82341  Vấn đề môi trường ở Indonesia   \n",
       "82342                       Cát Vinh   \n",
       "82343                     Pye Wacket   \n",
       "82344              Giải cờ vua M-Tel   \n",
       "82345                       Salzburg   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          text  \n",
       "82341  Vấn đề môi trường ở Indonesia\\n\\nthumb|360px|Các nhân viên cứu hỏa Indonesia đang cố gắng để ngăn chặn lửa rừng ở Nam Kalimantan (2015).\\n\\nCác vấn đề môi trường ở Indonesia liên quan đến mật độ dân số cao và công nghiệp hóa nhanh, và chúng thường được ưu tiên thấp hơn do mức nghèo đói cao và quản lý nguồn lực có hạn chế.\\n\\nCác vấn đề bao gồm nạn phá rừng quy mô lớn (phần lớn là bất hợp pháp) và các vụ cháy rừng liên quan gây ra sương mù dầy đặc ở các khu vực phía Tây Indonesia, Malaysia và Singapore; khai thác quá mức các nguồn tài nguyên biển; và các vấn đề về môi trường liên quan đến q...  \n",
       "82342  Cát Vinh\\n\\nCát Vinh (, ? – 528) thủ lĩnh khởi nghĩa nông dân Hà Bắc, là lực lượng lớn mạnh nhất trong phong trào Lục Trấn khởi nghĩa phản kháng nhà Bắc Ngụy.\\n\\nBan đầu Cát Vinh là Trấn tướng của trấn Hoài Sóc. Theo phép của nhà Bắc Ngụy, Trấn tướng đều lấy quý tộc Tiên Ti đảm nhiệm, từ đó suy đoán ông cũng là người Tiên Ti.\\n\\nTháng giêng năm Hiếu Xương thứ 2 (526), nguyên Hoài Sóc trấn binh Tiên Vu Tu Lễ tại thành Tả Nhân, Định Châu lãnh đạo khởi nghĩa. Hoài Sóc trấn tướng Cát Vinh tham gia khởi nghĩa.\\n\\nTháng 8, Nguyên Hồng Nghiệp làm phản, giết Tiên Vu Tu Lễ, xin hàng triều đình. Cát...  \n",
       "82343  Pye Wacket\\n\\nPye Wacket là mật danh của một tên lửa không đối không dạng thấu kính thử nghiệm được chi nhánh Convair của tập đoàn General Dynamics phát triển vào năm 1957. Dự định là một tên lửa phòng thủ cho máy bay ném bom B-70 Valkyrie Mach 3, chương trình đã cho thấy thử nghiệm đường ống gió khí động học rộng rãi và có vẻ đầy hứa hẹn; tuy nhiên việc hủy bỏ B-70 đã loại bỏ yêu cầu đối với tên lửa, và dự án này cũng bị hủy bỏ luôn.\\n\\nDự án \"Pye Wacket\", được chính thức gọi là Chương trình Lenticular Defense Missile (LDM) và theo số dự án WS-740A, được thành lập vào năm 1958 để đáp ứng ...  \n",
       "82344  Giải cờ vua M-Tel\\n\\nGiải cờ vua M-Tel, tên chính thức tiếng Bulgaria: М-Тел Мастърс, tiếng Anh M-Tel Masters là một giải cờ vua thường niên được tổ chức từ năm 2005 đến 2009 tại Sofia, thủ đô của Bulgaria. Giải đấu lấy tên theo nhà tài trợ và cũng là nhà tổ chức, công ty mạng di động hàng đầu của Bulgaria M-Tel. Mỗi năm giải mời 6 đại kiện tướng hàng đầu (thường có hệ số điểm Elo trên 2700) tham dự, thi đấu theo thể thức vòng tròn 2 lượt. Địa điểm thi đấu tại khách sạn 5 sao Grand Hotel Sofia. Do những khó khăn về kinh tế, cũng như một số lý do khách quan nên giải đấu không còn được tổ ch...  \n",
       "82345  Salzburg\\n\\nSalzburg ( ; ; nghĩa đen là \"Salt Fortress\" hay \"Pháo đài muối\"; tiếng Bayern: \"Soizbuag\") là thủ phủ của tiểu bang cùng tên thuộc Cộng hòa Áo. Với 150.269 dân cư, Salzburg là thành phố lớn thứ tư của Áo sau Viên, Graz và Linz.\\n\\nThị trấn nằm trên địa điểm của khu định cư La Mã trước đây của \"Iuvavum\". Salzburg được thành lập như một tòa giám mục vào năm 696 và trở thành trụ sở của tổng giám mục vào năm 798. Nguồn thu nhập chính của nó là khai thác và buôn bán muối và đôi khi là khai thác vàng. Pháo đài Hohensalzburg, một trong những pháo đài thời trung cổ lớn nhất ở châu Âu, ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# result_df.to_csv(path/'alltext.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build LM wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df = pd.read_csv(path/'alltext.csv',encoding='utf-8')\n",
    "result_df = pd.read_csv(path/'alltext.csv',encoding='utf-8',nrows=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnmese_lm = DataBlock(blocks=TextBlock.from_df('text', is_lm=True),\n",
    "                    get_x=ColReader('text'),\n",
    "                    splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs=64\n",
    "# bs=24\n",
    "bs=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "dls = vnmese_lm.dataloaders(result_df, bs=bs, seq_len=72)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxup hms xxmaj swiftsure ( 08 ) \\n\\n xxup hms \" swiftsure \" ( 08 ) là một tàu tuần dương hạng nhẹ lớp \" xxunk \" được chế tạo cho xxmaj hải quân xxmaj hoàng gia xxmaj anh xxmaj quốc trong xxmaj chiến tranh xxmaj thế giới thứ hai . xxup nó được đặt lườn bởi hãng xxmaj vickers xxmaj armstrong tại newcastle - on - tyne vào ngày 22</td>\n",
       "      <td>xxup hms xxmaj swiftsure ( 08 ) \\n\\n xxup hms \" swiftsure \" ( 08 ) là một tàu tuần dương hạng nhẹ lớp \" xxunk \" được chế tạo cho xxmaj hải quân xxmaj hoàng gia xxmaj anh xxmaj quốc trong xxmaj chiến tranh xxmaj thế giới thứ hai . xxup nó được đặt lườn bởi hãng xxmaj vickers xxmaj armstrong tại newcastle - on - tyne vào ngày 22 tháng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>, còn gọi là địa hào . xxmaj ngoại hình của nó bị đường đứt gãy khống chế , phần lớn có hình dạng sợi hẹp và dài , rìa mép của bồn địa gãy lún do vách đá đứt gãy hợp thành , độ dốc cao gần như thẳng đứng , đường biên thông thường là đường đứt gãy . xxmaj trôi qua theo thời gian , trong bồn địa gãy</td>\n",
       "      <td>còn gọi là địa hào . xxmaj ngoại hình của nó bị đường đứt gãy khống chế , phần lớn có hình dạng sợi hẹp và dài , rìa mép của bồn địa gãy lún do vách đá đứt gãy hợp thành , độ dốc cao gần như thẳng đứng , đường biên thông thường là đường đứt gãy . xxmaj trôi qua theo thời gian , trong bồn địa gãy lún</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>như một cách thể hiện sự kính trọng với xxmaj mike xxunk , thần tượng lúc nhỏ của anh và cũng mặc áo số 8 . \\n\\n xxmaj vào mùa giải 2006 - 07 , xxmaj kobe lần thứ 9 được chọn vào đội hình xxmaj các siêu sao xxup nba ( nba all - stars ) , và vào ngày 18 tháng 2 , xxmaj kobe ghi 31 điểm , có</td>\n",
       "      <td>một cách thể hiện sự kính trọng với xxmaj mike xxunk , thần tượng lúc nhỏ của anh và cũng mặc áo số 8 . \\n\\n xxmaj vào mùa giải 2006 - 07 , xxmaj kobe lần thứ 9 được chọn vào đội hình xxmaj các siêu sao xxup nba ( nba all - stars ) , và vào ngày 18 tháng 2 , xxmaj kobe ghi 31 điểm , có 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quyền ly khai khỏi liên bang để xây dựng quốc gia riêng độc lập . xxmaj vương quốc xxmaj chăm xxmaj pa đã trải qua nhiều triều đại với nhiều lần dời đô từ bắc vào nam và ngược lại . \\n\\n xxmaj theo sử thi người xxmaj chăm , dân tộc chính của xxmaj chăm xxmaj pa là tộc người xxmaj chăm được chia thành hai nhóm : xxmaj chăm ở</td>\n",
       "      <td>ly khai khỏi liên bang để xây dựng quốc gia riêng độc lập . xxmaj vương quốc xxmaj chăm xxmaj pa đã trải qua nhiều triều đại với nhiều lần dời đô từ bắc vào nam và ngược lại . \\n\\n xxmaj theo sử thi người xxmaj chăm , dân tộc chính của xxmaj chăm xxmaj pa là tộc người xxmaj chăm được chia thành hai nhóm : xxmaj chăm ở phía</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## TextBlock datablock summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.data.block.DataBlock"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vnmese_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Setting up after_item: Pipeline: ToTensor\n",
    "# Setting up before_batch: Pipeline: \n",
    "# Setting up after_batch: Pipeline: \n",
    "\n",
    "# Building one batch\n",
    "# Applying item_tfms to the first sample:\n",
    "#   Pipeline: ToTensor\n",
    "#     starting from\n",
    "#       (TensorText of size 726)\n",
    "#     applying ToTensor gives\n",
    "#       (TensorText of size 726)\n",
    "\n",
    "# Adding the next 1 samples\n",
    "\n",
    "# No before_batch transform to apply\n",
    "\n",
    "# Collating items in a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vnmese_lm.summary(result_df, bs=2)\n",
    "# TODO: in LM, for some reason the sequences in a batch aren’t padded to be of equal length \n",
    "# while making a LM. I know they are made equal when building the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note! The tokenizer here, is it suitable for other language such as Vietnamese?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Study LM dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.data.core.DataLoaders"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17280"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xxunk', 'xxpad', 'xxbos', 'xxeos', 'xxfld', 'xxrep', 'xxwrep', 'xxup', 'xxmaj', ',', '.', 'và', 'của', '\"', 'là', 'được', 'một', '\\n\\n', 'các', 'trong', 'có', 'năm', 'đã', ')', '(', 'với', 'cho', 'người', 'vào', 'ở', 'những', 'thành', 'không', 'từ', 'tháng', 'khi', 'đến', 'này', 'ngày', 'công', '-', 'sau', 'tại', 'đầu', 'đó', 'ông', 'để', 'sự', 'về', 'ra', 'thể', 'như', 'quốc', 'bị', 'chính', 'số', 'quân', 'lại', 'trên', 'nhà', 'cũng', ':', 'nam', 'gia', 'nhiều', 'trung', 'theo', 'bộ', 'làm', 'đại', 'động', 'nhất', 'việc', 'học', 'hiện', 'thời', 'chiến', 'anh', 'hai', '3', 'nó', 'cùng', 'chỉ', 'thế', 'con', 'phát', 'bản', 'khác', 'định', 'đồng', 'nhân', 'dân', 'do', 'quan', 'họ', 'hành', 'nước', 'còn', 'hơn', 'sử']\n"
     ]
    }
   ],
   "source": [
    "print(dls.vocab[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cdi', 'lignin', 'hoai', 'surabaja', 'heitler', 'hewett', 'whitten', 'sackets', 'fulton', 'colchinium', 'mng', 'volodymyr', 'macaire', 'garneau', 'asi', 'yanqui', 'u.x.o', 'plc', 'tnr', 'satchō', 'vờn', 'ahli', 'maleate', 'galsworthy', 'aoun', 'chamillionaire', 'tu-22m3', 'chievo', 'e13', 'cauca', 'uribe', 'rojas', 'lleras', 'sarir', 'cargo', 'tunner', 'sabado', 'roto', 'palo', 'mủ', 'dcis', 'milovan', 'spn', 'akane', 'yasu', 'bcg', 'mantoux', 'x5', 'ichthyopsida', 'adreno', 'processor', '617', 'chamakh', 'pacman', 'turya', 'dromostanolone', 'virilization', '2α', 'undong', 'platinumgames', 'noatun', 'rodin', 'otero', 'briand', 'complementary', 'polysilicon', 'hecht', 'upstate', 'catawba', 'mays', 'amber', 'mahaffey', 'coefficient', 'ginoza', 'kagari', 'shogo', 'ubukata', 'fukami', 'hayakawa', 'doping', 'paulina', 'porizkova', 'bottom', 'antm', 'samatha', 'dd25', 'ops-50', 'mk-15', 'hajar', 'khayyám', 'woodbridge', 'lanna', 'cagayan', 'province', 'ifugao', 'sápmi', 'perla', 'facteur', 'aqps', 'xxfake']\n"
     ]
    }
   ],
   "source": [
    "print(dls.vocab[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<fastai.text.data.LMDataLoader at 0x7f923108dd30>,\n",
       " <fastai.text.data.LMDataLoader at 0x7f911bdd74f0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.train,dls.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y = dls.train.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 72)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape # (bs,bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LMTensorText([[    2,     8,   226,  ...,   196,    10,     8],\n",
       "        [    8,  1422,    11,  ...,     8,  1422,   635],\n",
       "        [    8, 13037,     8,  ...,   733,     8, 13447],\n",
       "        ...,\n",
       "        [  113,   102,   468,  ...,    44,    14,    15],\n",
       "        [  619,    42,     8,  ...,    18,  2376,  1666],\n",
       "        [    8,   338,    14,  ...,     8,   428,   252]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x # LMTensorText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(fastai.text.data.LMTensorText, 'torch.cuda.LongTensor')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x),x.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 72)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorText([[ 645,    8,   85,  ...,  111,   31,  146],\n",
       "        [ 112,   46,   36,  ...,  183,  840,    8],\n",
       "        [  18,   67,  467,  ...,  624,  181,  119],\n",
       "        ...,\n",
       "        [   8, 1625,    7,  ...,    8,  244, 1348],\n",
       "        [1067,   10,    7,  ...,  191,   32,  290],\n",
       "        [ 290,  258,  322,  ...,   22,   68,   39]], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y # move each row of x to the right by 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "check bptt (seq_len) size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp_i = iter(dls.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 72) (128, 72)\n"
     ]
    }
   ],
   "source": [
    "temp_x,temp_y = next(temp_i)\n",
    "print(temp_x.shape,temp_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 72) (128, 72)\n"
     ]
    }
   ],
   "source": [
    "temp_x,temp_y = next(temp_i)\n",
    "print(temp_x.shape,temp_y.shape)\n",
    "# bptt not changing during LM model.\n",
    "# though there might be a param somewhere to set up variable bptt length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj phong trào xxmaj cần xxmaj vương \\n\\n xxmaj phong trào xxmaj cần xxmaj vương ( chữ xxmaj nôm : xxunk ) nổ ra vào cuối thế kỷ 19 do đại thần nhà xxmaj nguyễn là xxmaj tôn xxmaj thất xxmaj thuyết nhân danh vị hoàng đế trẻ tuổi vua xxmaj hàm xxmaj nghi đề xướng trước nạn xâm lược của thực dân xxmaj pháp . \\n\\n xxmaj tại triều đình</td>\n",
       "      <td>xxmaj phong trào xxmaj cần xxmaj vương \\n\\n xxmaj phong trào xxmaj cần xxmaj vương ( chữ xxmaj nôm : xxunk ) nổ ra vào cuối thế kỷ 19 do đại thần nhà xxmaj nguyễn là xxmaj tôn xxmaj thất xxmaj thuyết nhân danh vị hoàng đế trẻ tuổi vua xxmaj hàm xxmaj nghi đề xướng trước nạn xâm lược của thực dân xxmaj pháp . \\n\\n xxmaj tại triều đình xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tế ban đầu đặt tiêu chuẩn cho tên miền chấp nhận . xxmaj quốc tế hóa tên miền là một giải pháp kỹ thuật để dịch các tên được viết bằng các tập lệnh gốc ngôn ngữ thành biểu diễn văn bản xxup ascii tương thích với xxup hệ thống tên miền . xxmaj tên miền quốc tế hóa chỉ có thể được sử dụng với các ứng dụng được thiết kế</td>\n",
       "      <td>ban đầu đặt tiêu chuẩn cho tên miền chấp nhận . xxmaj quốc tế hóa tên miền là một giải pháp kỹ thuật để dịch các tên được viết bằng các tập lệnh gốc ngôn ngữ thành biểu diễn văn bản xxup ascii tương thích với xxup hệ thống tên miền . xxmaj tên miền quốc tế hóa chỉ có thể được sử dụng với các ứng dụng được thiết kế riêng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vắn \" , \" kim xxmaj tiền \" , \" long xxup hổ xxmaj hội \" . ông nội ông là xxmaj trần xxmaj quang xxmaj diệm ( năm xxmaj diệm ) , cha ông là xxmaj trần xxmaj quang xxmaj chiêu ( bảy xxmaj triều ) , cô là xxmaj trần xxmaj ngọc xxmaj viện ( tức xxmaj ba xxmaj viện , người đã sáng lập gánh cải lương đồng xxup</td>\n",
       "      <td>\" , \" kim xxmaj tiền \" , \" long xxup hổ xxmaj hội \" . ông nội ông là xxmaj trần xxmaj quang xxmaj diệm ( năm xxmaj diệm ) , cha ông là xxmaj trần xxmaj quang xxmaj chiêu ( bảy xxmaj triều ) , cô là xxmaj trần xxmaj ngọc xxmaj viện ( tức xxmaj ba xxmaj viện , người đã sáng lập gánh cải lương đồng xxup nữ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxmaj thứ sử . \\n\\n đời đường xxmaj cao tông , ông được đổi thành xxup tả vệ đại tướng quân . xxmaj khoảng năm 655 - 657 , ông lĩnh chức xxmaj hành quân tổng quản , dẫn binh xuất chinh xxmaj tây đột xxmaj quyết . xxmaj tuy nhiên , trong quá trình hành quân , quân đường tàn sát thường dân , người đột xxmaj quyết phẫn nộ ,</td>\n",
       "      <td>thứ sử . \\n\\n đời đường xxmaj cao tông , ông được đổi thành xxup tả vệ đại tướng quân . xxmaj khoảng năm 655 - 657 , ông lĩnh chức xxmaj hành quân tổng quản , dẫn binh xuất chinh xxmaj tây đột xxmaj quyết . xxmaj tuy nhiên , trong quá trình hành quân , quân đường tàn sát thường dân , người đột xxmaj quyết phẫn nộ , quyết</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.train.show_batch(max_n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datablock tfms \n",
    "\n",
    "block tfms to be added at the end of  X dataset pipeline  +  after_item pipeline +  after_batch pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vnmese_lm.type_tfms) # only 1 type tfms for X \n",
    "# since 'blocks' param provide only 1: DataBlock(blocks=TextBlock.from_df('text', is_lm=True),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [[Tokenizer:\n",
       "encodes: (Path,object) -> encodes\n",
       "(str,object) -> encodes\n",
       "decodes: (object,object) -> decodes\n",
       ", Numericalize:\n",
       "encodes: (object,object) -> encodes\n",
       "decodes: (object,object) -> decodes\n",
       "]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnmese_lm.type_tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer:\n",
       "encodes: (Path,object) -> encodes\n",
       "(str,object) -> encodes\n",
       "decodes: (object,object) -> decodes"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnmese_lm.type_tfms[0][0] # Tokenizer transform. Will be in X pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Numericalize: (object,object) -> encodes (object,object) -> decodes"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnmese_lm.type_tfms[0][1] # Numericalize transform. Will be in X pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [ToTensor:\n",
       "encodes: (PILMask,object) -> encodes\n",
       "(PILBase,object) -> encodes\n",
       "decodes: ]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnmese_lm.default_item_tfms #default item tfm (for dataloaders' after_item pipeline) for PILBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#0) []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnmese_lm.default_batch_tfms #default batch item tfm (for dataloaders' after_batch pipeline\n",
    "# normally it will be IntToFloatTensor, but token should be kept as int, so no tfm here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#1) [ToTensor:\n",
       "encodes: (PILMask,object) -> encodes\n",
       "(PILBase,object) -> encodes\n",
       "decodes: ],\n",
       " (#0) [])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnmese_lm.item_tfms,vnmese_lm.batch_tfms \n",
    "# nothing different from default_item_tfms and default_batch_tfms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and its tfms (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 1600)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.valid.dataset),len(dls.train.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = dls.train.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dsets[0]),len(dsets[0]) # tuple of 1 since there's no label y yet (LM model)\n",
    "# reminder: fastai dataset return X and y. This dataset is for train set (there will be one for validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((595,), (710,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets[0][0].shape,dsets[1][0].shape # different wiki article has different length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dls.train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = dls.valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(fastai.data.core.Datasets, fastai.data.core.Datasets)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dsets),type(train_ds) # same shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((595,), (710,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0][0].shape,train_ds[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, fastai.data.core.TfmdLists)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds.tls) # 1 tfmdlist for train, again because no label y yet\n",
    "# reminder: dataset will consist of 2 TfmdLists, one for X and one for y\n",
    "# Each TfmdList contains the data and also the transformation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.data.core.TfmdLists"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_ds.tls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: ColReader -- {'cols': 'text', 'pref': '', 'suff': '', 'label_delim': None} -> Tokenizer -> Numericalize"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0].tfms # or train_ds.tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: ColReader -- {'cols': 'text', 'pref': '', 'suff': '', 'label_delim': None} -> Tokenizer -> Numericalize"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds.tls[0].tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0x7fb2158c7c40', '0x7fb26e476a00')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(id(train_ds.tls[0].tfms)),hex(id(val_ds.tls[0].tfms)) # 2 different pipelines though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>Adobe Premiere Pro</td>\n",
       "      <td>[xxbos, xxmaj, adobe, xxmaj, premiere, xxmaj, pro, \\n\\n, xxmaj, adobe, xxmaj, premiere, xxmaj, pro, (, còn, gọi, là, xxmaj, premiere, xxmaj, pro, ), là, một,   , ứng, dụng, chỉnh, sửa, video, theo,  , thời, gian, được, xxmaj, adobe, xxmaj, systems, phát, triển, và, được, phát, hành, như, là, một, phần, của, chương, trình, cấp, phép, xxmaj, adobe, xxmaj, creative, xxmaj, cloud, ., xxmaj, lần, đầu, tiên, đưa, ra, vào, năm, 2003, ,, xxmaj, adobe, xxmaj, premiere, xxmaj, pro, là, sự, kế, thừa, của, xxmaj, adobe, xxmaj, premiere, (, phát, hành, lần, đầu, tiên, trong, năm, 1991, ), ., xxmaj, chư...</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>Bắc Las Vegas, Nevada</td>\n",
       "      <td>[xxbos, xxmaj, bắc, xxmaj, las, xxmaj, vegas, ,, xxmaj, nevada, \\n\\n, xxmaj, bắc, xxmaj, las, xxmaj, vegas, (, tiếng, xxmaj, anh, :, \", north, xxmaj, las, xxmaj, vegas, \", ), là, một, thành, phố, trong, xxmaj, quận, xxmaj, clark, ,, xxmaj, nevada, ,, xxmaj, hoa, xxup, kỳ, ., xxmaj, theo, điều, cuộc, điều, tra, dân, số, năm, 2, xxrep, 3, 0, ,, thành, phố, có, tổng, dân, số, 115.488, ,, với, một, số, dân, theo, ước, tính, của, xxmaj, cục, điều, tra, dân, số, năm, 2006, là, 197.567, người, ,, và, theo, ước, tính, của, xxmaj, quận, xxmaj, clark, là, ...]</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>Màn gương trong mờ</td>\n",
       "      <td>[xxbos, xxmaj, màn, gương, trong, mờ, \\n\\n, xxmaj, màn, gương, trong, mờ, (, pellicle, mirror, ), (, số, ít, của, \", pellis, \", ,, da, hoặc, màng, ), là, một, gương, bán, trong, suốt, siêu, mỏng, ,, siêu, nhẹ, được, sử, dụng, trong, đường, truyền, tia, sáng, của, một, dụng, cụ, quang, học, ,, tách, chùm, ánh, sáng, thành, hai, chùm, riêng, biệt, ,, cả, hai, đều, giảm, cường, độ, ánh, sáng, ., xxmaj, việc, tách, chùm, cho, phép, sử, dụng, đồng, thời, cho, nhiều, mục, đích, ., độ, mỏng, của, gương, thực, tế, giúp, loại, bỏ, chùm, tia, hoặc, ...]</td>\n",
       "      <td>1078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>Đô sát viện</td>\n",
       "      <td>[xxbos, đô, sát, viện, \\n\\n, đô, sát, viện, (, 都察院, ,, xxmaj, censorate, ), là, cơ, quan, tối, cao, trong, các, triều, đại, xxmaj, trung, xxmaj, quốc, và, xxmaj, việt, xxmaj, nam, xưa, ,, với, trọng, trách, thay, mặt, vua, giám, sát, ,, đàn, hặc, và, kiến, nghị, mọi, hoạt, động, của, quan, lại, các, cấp, ,, lẫn, trọng, trách, giám, sát, việc, thi, hành, luật, pháp, và, thực, hiện, nghiêm, chỉnh, các, quy, tắc, triều, đình, ban, hành, từ, trung, ương, đến, địa, phương, ., đô, sát, viện, là, cơ, quan, độc, lập, tại, trung, ương, ,, trực, thuộc, ...]</td>\n",
       "      <td>944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>Hạ thân nhiệt</td>\n",
       "      <td>[xxbos, xxup, hạ, thân, nhiệt, \\n\\n, xxup, hạ, thân, nhiệt, hay, giảm, thân, nhiệt, được, định, nghĩa, là, nhiệt, độ, cơ, thể, dưới, ở, người, ., xxmaj, các, triệu, chứng, phụ, thuộc, vào, nhiệt, độ, ., xxmaj, trong, hạ, thân, nhiệt, nhẹ, có, diễn, ra, run, rẩy, và, rối, loạn, tâm, thần, ., xxmaj, trong, giảm, thân, nhiệt, vừa, phải, run, rẩy, dừng, lại, và, sự, nhầm, lẫn, tinh, thần, tăng, lên, ., xxmaj, trong, tình, trạng, hạ, thân, nhiệt, nghiêm, trọng, ,, có, thể, có, sự, cởi, quần, áo, nghịch, lý, ,, trong, đó, một, người, cởi, bỏ, quần, ...]</td>\n",
       "      <td>5983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>Howard Carter</td>\n",
       "      <td>[xxbos, xxmaj, howard, xxmaj, carter, \\n\\n, xxmaj, howard, xxmaj, carter, (, 9, tháng, 5, năm, 1874, -, 2, tháng, 3, năm, 1939, ), là, một, nhà, khảo, cổ, học, và, nhà, xxmaj, ai, xxmaj, cập, học, người, xxmaj, anh, ,, là, người, chủ, chốt, trong, việc, khám, phá, lăng, mộ, của, xxmaj, pharaon, xxmaj, vương, triều, thứ, xxmaj, mười, xxmaj, tám, của, xxmaj, ai, xxmaj, cập, xxmaj, tutankhamun, vào, tháng, 11, năm, 1922, ., \\n\\n, xxmaj, howard, xxmaj, carter, được, sinh, ra, tại, xxmaj, london, ,, xxmaj, anh, ., ông, là, con, trai, của, xxmaj, samuel, xxmaj, carter, ,, một, ...]</td>\n",
       "      <td>1124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>Tấn công Barcelona 2017</td>\n",
       "      <td>[xxbos, xxmaj, tấn, công, xxmaj, barcelona, 2017, \\n\\n, xxmaj, cuộc, tấn, công, xxmaj, barcelona, năm, 2017, xảy, ra, vào, ngày, 17, tháng, 8, năm, 2017, tại, xxmaj, la, xxmaj, rambla, ,, xxmaj, barcelona, khi, một, chiếc, xe, tải, đâm, vào, những, người, đi, bộ, ,, làm, chết, 13, người, và, làm, bị, thương, ít, nhất, 100, người, (, 17, người, bị, thương, nặng, ,, 2, người, trong, tình, trạng, nghiêm, trọng, ,, 1, là, người, đức, đã, chết, sau, đó, ), ., xxmaj, các, nạn, nhân, tổng, cộng, là, từ, 34, nước, .,  , xxmaj, hai, nghi, phạm, sau, đó, ...]</td>\n",
       "      <td>3059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Quan hệ Hàn Quốc – Việt Nam</td>\n",
       "      <td>[xxbos, xxmaj, quan, hệ, xxmaj, hàn, xxmaj, quốc, –, xxmaj, việt, xxmaj, nam, \\n\\n, xxmaj, quan, hệ, xxmaj, hàn, xxmaj, quốc, –, xxmaj, việt, xxmaj, nam, là, mối, quan, hệ, ngoại, giao, được, thiết, lập, chính, thức, giữa, xxmaj, cộng, hòa, xã, hội, chủ, nghĩa, xxmaj, việt, xxmaj, nam, và, đại, xxmaj, hàn, xxmaj, dân, xxmaj, quốc, ,, hai, quốc, gia, tuy, khác, nhau, về, địa, lý, ,, thể, chế, chính, trị, cũng, như, ý, thức, hệ, nhưng, lại, có, rất, nhiều, nét, tương, đồng, về, con, người, ,, lịch, sử, và, văn, hóa, ., xxmaj, khác, với, xxmaj, quan, ...]</td>\n",
       "      <td>2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>Đảo Gough</td>\n",
       "      <td>[xxbos, đảo, xxmaj, gough, \\n\\n, đảo, xxmaj, gough, là, một, hòn, đảo, núi, lửa, ở, phía, nam, đại, xxmaj, tây, xxmaj, dương, ., xxup, nó, là, một, hòn, đảo, thuộc, nhóm, đảo, xxmaj, tristan, da, xxmaj, cunha, và, một, phần, của, xxmaj, saint, xxmaj, helena, ,, xxmaj, ascension, và, xxmaj, tristan, da, xxmaj, cunha, ,, lãnh, thổ, hải, ngoại, thuộc, xxmaj, anh, ., xxmaj, hòn, đảo, không, có, người, ở, ,, ngoại, trừ, các, nhân, viên, của, một, trạm, dự, báo, thời, tiết, (, thường, là, 6, người, ), theo, một, chương, trình, về, môi, trường, tự, nhiên, ở, xxmaj, ...]</td>\n",
       "      <td>1032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>Chùa Dâu</td>\n",
       "      <td>[xxbos, xxmaj, chùa, xxmaj, dâu, \\n\\n, xxmaj, chùa, xxmaj, dâu, ,, còn, có, tên, là, xxmaj, diên, ứng, (, 延應寺, ), ,, xxmaj, pháp, xxmaj, vân, (, 法雲寺, ), ,, hay, xxup, cổ, xxmaj, châu, ,, là, một, ngôi, chùa, nằm, ở, xã, xxmaj, thanh, xxmaj, khương, ,, huyện, xxmaj, thuận, xxmaj, thành, ,, tỉnh, xxmaj, bắc, xxmaj, ninh, ,, cách, xxup, hà, xxmaj, nội, khoảng, 30, km, ., đây, là, trung, tâm, xxmaj, phật, giáo, cổ, xưa, nhất, của, xxmaj, việt, xxmaj, nam, ., xxmaj, chùa, còn, được, người, dân, gọi, với, những, tên, gọi, khác, nhau, như, chùa, ...]</td>\n",
       "      <td>2076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            fname  \\\n",
       "1332           Adobe Premiere Pro   \n",
       "837         Bắc Las Vegas, Nevada   \n",
       "1767           Màn gương trong mờ   \n",
       "564                   Đô sát viện   \n",
       "1505                Hạ thân nhiệt   \n",
       "...                           ...   \n",
       "1067                Howard Carter   \n",
       "687       Tấn công Barcelona 2017   \n",
       "225   Quan hệ Hàn Quốc – Việt Nam   \n",
       "1703                    Đảo Gough   \n",
       "1246                     Chùa Dâu   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         text  \\\n",
       "1332  [xxbos, xxmaj, adobe, xxmaj, premiere, xxmaj, pro, \\n\\n, xxmaj, adobe, xxmaj, premiere, xxmaj, pro, (, còn, gọi, là, xxmaj, premiere, xxmaj, pro, ), là, một,   , ứng, dụng, chỉnh, sửa, video, theo,  , thời, gian, được, xxmaj, adobe, xxmaj, systems, phát, triển, và, được, phát, hành, như, là, một, phần, của, chương, trình, cấp, phép, xxmaj, adobe, xxmaj, creative, xxmaj, cloud, ., xxmaj, lần, đầu, tiên, đưa, ra, vào, năm, 2003, ,, xxmaj, adobe, xxmaj, premiere, xxmaj, pro, là, sự, kế, thừa, của, xxmaj, adobe, xxmaj, premiere, (, phát, hành, lần, đầu, tiên, trong, năm, 1991, ), ., xxmaj, chư...   \n",
       "837                                              [xxbos, xxmaj, bắc, xxmaj, las, xxmaj, vegas, ,, xxmaj, nevada, \\n\\n, xxmaj, bắc, xxmaj, las, xxmaj, vegas, (, tiếng, xxmaj, anh, :, \", north, xxmaj, las, xxmaj, vegas, \", ), là, một, thành, phố, trong, xxmaj, quận, xxmaj, clark, ,, xxmaj, nevada, ,, xxmaj, hoa, xxup, kỳ, ., xxmaj, theo, điều, cuộc, điều, tra, dân, số, năm, 2, xxrep, 3, 0, ,, thành, phố, có, tổng, dân, số, 115.488, ,, với, một, số, dân, theo, ước, tính, của, xxmaj, cục, điều, tra, dân, số, năm, 2006, là, 197.567, người, ,, và, theo, ước, tính, của, xxmaj, quận, xxmaj, clark, là, ...]   \n",
       "1767                                                    [xxbos, xxmaj, màn, gương, trong, mờ, \\n\\n, xxmaj, màn, gương, trong, mờ, (, pellicle, mirror, ), (, số, ít, của, \", pellis, \", ,, da, hoặc, màng, ), là, một, gương, bán, trong, suốt, siêu, mỏng, ,, siêu, nhẹ, được, sử, dụng, trong, đường, truyền, tia, sáng, của, một, dụng, cụ, quang, học, ,, tách, chùm, ánh, sáng, thành, hai, chùm, riêng, biệt, ,, cả, hai, đều, giảm, cường, độ, ánh, sáng, ., xxmaj, việc, tách, chùm, cho, phép, sử, dụng, đồng, thời, cho, nhiều, mục, đích, ., độ, mỏng, của, gương, thực, tế, giúp, loại, bỏ, chùm, tia, hoặc, ...]   \n",
       "564                                                 [xxbos, đô, sát, viện, \\n\\n, đô, sát, viện, (, 都察院, ,, xxmaj, censorate, ), là, cơ, quan, tối, cao, trong, các, triều, đại, xxmaj, trung, xxmaj, quốc, và, xxmaj, việt, xxmaj, nam, xưa, ,, với, trọng, trách, thay, mặt, vua, giám, sát, ,, đàn, hặc, và, kiến, nghị, mọi, hoạt, động, của, quan, lại, các, cấp, ,, lẫn, trọng, trách, giám, sát, việc, thi, hành, luật, pháp, và, thực, hiện, nghiêm, chỉnh, các, quy, tắc, triều, đình, ban, hành, từ, trung, ương, đến, địa, phương, ., đô, sát, viện, là, cơ, quan, độc, lập, tại, trung, ương, ,, trực, thuộc, ...]   \n",
       "1505                                                [xxbos, xxup, hạ, thân, nhiệt, \\n\\n, xxup, hạ, thân, nhiệt, hay, giảm, thân, nhiệt, được, định, nghĩa, là, nhiệt, độ, cơ, thể, dưới, ở, người, ., xxmaj, các, triệu, chứng, phụ, thuộc, vào, nhiệt, độ, ., xxmaj, trong, hạ, thân, nhiệt, nhẹ, có, diễn, ra, run, rẩy, và, rối, loạn, tâm, thần, ., xxmaj, trong, giảm, thân, nhiệt, vừa, phải, run, rẩy, dừng, lại, và, sự, nhầm, lẫn, tinh, thần, tăng, lên, ., xxmaj, trong, tình, trạng, hạ, thân, nhiệt, nghiêm, trọng, ,, có, thể, có, sự, cởi, quần, áo, nghịch, lý, ,, trong, đó, một, người, cởi, bỏ, quần, ...]   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...   \n",
       "1067                   [xxbos, xxmaj, howard, xxmaj, carter, \\n\\n, xxmaj, howard, xxmaj, carter, (, 9, tháng, 5, năm, 1874, -, 2, tháng, 3, năm, 1939, ), là, một, nhà, khảo, cổ, học, và, nhà, xxmaj, ai, xxmaj, cập, học, người, xxmaj, anh, ,, là, người, chủ, chốt, trong, việc, khám, phá, lăng, mộ, của, xxmaj, pharaon, xxmaj, vương, triều, thứ, xxmaj, mười, xxmaj, tám, của, xxmaj, ai, xxmaj, cập, xxmaj, tutankhamun, vào, tháng, 11, năm, 1922, ., \\n\\n, xxmaj, howard, xxmaj, carter, được, sinh, ra, tại, xxmaj, london, ,, xxmaj, anh, ., ông, là, con, trai, của, xxmaj, samuel, xxmaj, carter, ,, một, ...]   \n",
       "687                                               [xxbos, xxmaj, tấn, công, xxmaj, barcelona, 2017, \\n\\n, xxmaj, cuộc, tấn, công, xxmaj, barcelona, năm, 2017, xảy, ra, vào, ngày, 17, tháng, 8, năm, 2017, tại, xxmaj, la, xxmaj, rambla, ,, xxmaj, barcelona, khi, một, chiếc, xe, tải, đâm, vào, những, người, đi, bộ, ,, làm, chết, 13, người, và, làm, bị, thương, ít, nhất, 100, người, (, 17, người, bị, thương, nặng, ,, 2, người, trong, tình, trạng, nghiêm, trọng, ,, 1, là, người, đức, đã, chết, sau, đó, ), ., xxmaj, các, nạn, nhân, tổng, cộng, là, từ, 34, nước, .,  , xxmaj, hai, nghi, phạm, sau, đó, ...]   \n",
       "225                                            [xxbos, xxmaj, quan, hệ, xxmaj, hàn, xxmaj, quốc, –, xxmaj, việt, xxmaj, nam, \\n\\n, xxmaj, quan, hệ, xxmaj, hàn, xxmaj, quốc, –, xxmaj, việt, xxmaj, nam, là, mối, quan, hệ, ngoại, giao, được, thiết, lập, chính, thức, giữa, xxmaj, cộng, hòa, xã, hội, chủ, nghĩa, xxmaj, việt, xxmaj, nam, và, đại, xxmaj, hàn, xxmaj, dân, xxmaj, quốc, ,, hai, quốc, gia, tuy, khác, nhau, về, địa, lý, ,, thể, chế, chính, trị, cũng, như, ý, thức, hệ, nhưng, lại, có, rất, nhiều, nét, tương, đồng, về, con, người, ,, lịch, sử, và, văn, hóa, ., xxmaj, khác, với, xxmaj, quan, ...]   \n",
       "1703                                [xxbos, đảo, xxmaj, gough, \\n\\n, đảo, xxmaj, gough, là, một, hòn, đảo, núi, lửa, ở, phía, nam, đại, xxmaj, tây, xxmaj, dương, ., xxup, nó, là, một, hòn, đảo, thuộc, nhóm, đảo, xxmaj, tristan, da, xxmaj, cunha, và, một, phần, của, xxmaj, saint, xxmaj, helena, ,, xxmaj, ascension, và, xxmaj, tristan, da, xxmaj, cunha, ,, lãnh, thổ, hải, ngoại, thuộc, xxmaj, anh, ., xxmaj, hòn, đảo, không, có, người, ở, ,, ngoại, trừ, các, nhân, viên, của, một, trạm, dự, báo, thời, tiết, (, thường, là, 6, người, ), theo, một, chương, trình, về, môi, trường, tự, nhiên, ở, xxmaj, ...]   \n",
       "1246                                                    [xxbos, xxmaj, chùa, xxmaj, dâu, \\n\\n, xxmaj, chùa, xxmaj, dâu, ,, còn, có, tên, là, xxmaj, diên, ứng, (, 延應寺, ), ,, xxmaj, pháp, xxmaj, vân, (, 法雲寺, ), ,, hay, xxup, cổ, xxmaj, châu, ,, là, một, ngôi, chùa, nằm, ở, xã, xxmaj, thanh, xxmaj, khương, ,, huyện, xxmaj, thuận, xxmaj, thành, ,, tỉnh, xxmaj, bắc, xxmaj, ninh, ,, cách, xxup, hà, xxmaj, nội, khoảng, 30, km, ., đây, là, trung, tâm, xxmaj, phật, giáo, cổ, xưa, nhất, của, xxmaj, việt, xxmaj, nam, ., xxmaj, chùa, còn, được, người, dân, gọi, với, những, tên, gọi, khác, nhau, như, chùa, ...]   \n",
       "\n",
       "      text_length  \n",
       "1332          595  \n",
       "837           710  \n",
       "1767         1078  \n",
       "564           944  \n",
       "1505         5983  \n",
       "...           ...  \n",
       "1067         1124  \n",
       "687          3059  \n",
       "225          2673  \n",
       "1703         1032  \n",
       "1246         2076  \n",
       "\n",
       "[1600 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0].items \n",
    "# texts have already been 'ColReader' and 'Tokenizer', but not Numericalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorText([   2,    8, 4227,    8, 4555])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0][0][:5]\n",
    "# when indexed, tfms are applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds.tls[0][0]) # 595 tokens for this wiki article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorText([    2,     8,  4227,     8,  4555,     8,  4156,    17,     8,  4227,\n",
       "            8,  4555,     8,  4156,    24,    97,   200,    14,     8,  4555,\n",
       "            8,  4156,    23,    14,    16,  2940,   399,   110,  1113,   982,\n",
       "          733,    66,   166,    75,   254,    15,     8,  4227,     8,  5309,\n",
       "           85,   305,    11,    15,    85,    95,    51,    14,    16,   116,\n",
       "           12,   354,   143,   212,   544,     8,  4227,     8,  8518,     8,\n",
       "         8187,    10,     8,   208,    43,   124,   337,    49,    28,    21,\n",
       "         1242,     9,     8,  4227,     8,  4555,     8,  4156,    14,    47,\n",
       "          299,   797,    12,     8,  4227,     8,  4555,    24,    85,    95,\n",
       "          208,    43,   124,    19,    21,  1533,    23,    10,     8,   354,\n",
       "          143,   472,   215,   218,   132,  1113,   982,   733,   686,   275,\n",
       "            9,    19,    35,   166,     8,  4227,     8,  4555,     8, 16654,\n",
       "          472,    36,   252,   300,   218,   132,    27,   300,   347,    10,\n",
       "           17,     7,  5781,    22,  1002,    99,   110,     8,  4227,     8,\n",
       "         4555,    10,     8,    60,    19,    21,   925,     9,     7,  2471,\n",
       "           60,   237,   150,   347,     8,  4555,    10,     7,    80,    22,\n",
       "           15,    99,   110,    46,   982,    30,    67,   195,     9,    51,\n",
       "            8,  9801,     8,  2997,     9,   166,     8,  8688,     8,  3304,\n",
       "            8,     0,     9,    11,     8,  8369,     9,    11,    18,   822,\n",
       "          360,   182,    51,     8,  3509,  1251,     8,     0,     8,  2251,\n",
       "           10,    17,     8,  4555,     8,  4156,    14,   116,  1189,    22,\n",
       "           15,   245,   299,    57,    12,     8,  4227,     8,  4555,     9,\n",
       "           11,    22,    49,   619,    28,    21,  1242,    10,     8,  4555,\n",
       "            8,  4156,   554,   367,    33,   579,    86,    28,    21,  1242,\n",
       "           11,    41,    37,     9,    19,    35,     8,  4555,   235,   554,\n",
       "           36,   579,    86,   109,    44,    10,     8,  4555,   166,    14,\n",
       "           16,    19,    30,   208,    43,   124,   258,   175,   681,    58,\n",
       "            0,    24,  1616,    40, 10421,     0,  3610,    23,    25,   208,\n",
       "           43,   124,    85,    95,    58,     8,  4815,    19,    21,  1533,\n",
       "           10,     8,  4227,    16,    75,   254,   790,    32,   694,   432,\n",
       "          644,  1434,     8,  4815,    41,   315,   579,    86,    12,     8,\n",
       "         4555,    10,    17,     8,  4555,     8,  4156,   694,   432,  1113,\n",
       "          982,   733,   126,   297,   127,   142,   159,    36,     0,  3044,\n",
       "            0,     9,   159,   215,     0,   477,   214,   621,   593,     9,\n",
       "           19,   113,    78,     7,     0,    11,     7,     0,    10,     8,\n",
       "         1113,   982,   276,   323,     9,   694,   432,     7,     0,  3091,\n",
       "          166,    11,   276,   323,     0,  1901,    20,     0,   166,     8,\n",
       "         4156,  3084,    40,   447,   794,   435,    26,    80,    46,   106,\n",
       "          381,   666,   550,   261,    30,    15,   694,   432,   128, 15566,\n",
       "          177,     0,     9,   694,   432,    16,   793,    18,   733,    11,\n",
       "          194,   328,   276,   323,   550,    11,   584,    58,   113,   188,\n",
       "          158,    95, 10601,     9,    11,     8,  1399,    10,     8,    35,\n",
       "           99,   110,    25,     8,     0,  1251,     8,  2662,   614,   667,\n",
       "         1007,     9,    80,   694,   432,  1113,   982,  3437,    25,   585,\n",
       "          273,   538,   357,   455,  3437,    99,   110,  1109,   108,  8084,\n",
       "            9,    19,    35,    68,    26,   403,    90,   619,   729,    11,\n",
       "          123,   158,  1113,    10,  5605,     8,    16,   252,   212,   579,\n",
       "           86,     8,  4227,     8,  4555,     8, 16654,   660,    28,    27,\n",
       "          347,    58,     8,  1399,    11, 10601,    10,     8,    25,     8,\n",
       "         4555,     8,  4156,   660,   252,   860,   218,   132,   686,   275,\n",
       "            9,    80,    20,   577,    83,    98,     8,  4555,     8, 16654,\n",
       "          203,   187,    64,  1100,   694,   432,     9,  1411,   771,   987,\n",
       "            9,     0,     9,  2265,     0,     9,  9161,     9,  7835,     0,\n",
       "          931,     9,  8274,  3091,     0,  8043,    11,     0,     0,    10,\n",
       "            8,  4555,     8,     0,    20,     8, 10764,     9,    26,  1335,\n",
       "          839,    98,     7,  1740,    11,     8,  2967,    40,  1461,   166,\n",
       "            8,  7318,   161,  1171,   526,     9,    11,     0,    26,   503,\n",
       "          115,    40,    46,    40,   737,   438,   276,    10,     8, 10764,\n",
       "          166,    22,  2452,    25,    72,    85,    95,    12,     8,  4227,\n",
       "          166,     8,  8518,     8,  8187])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0][0]\n",
    "# when indexed, tfms are applied (last one: Numericalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxpad'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_ds.tls[0][1]:\n",
    "    if i == train_ds.vocab[1]: \n",
    "        print('there is padding')\n",
    "        break\n",
    "        \n",
    "# print nothing => no padding apply yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found 2000 items\n",
    "# 2 datasets of sizes 1600,400\n",
    "# Setting up Pipeline: ColReader -> Tokenizer -> Numericalize\n",
    "\n",
    "# Building one sample\n",
    "#   Pipeline: ColReader -> Tokenizer -> Numericalize\n",
    "#     starting from\n",
    "#       fname                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Lâm Tế Nghĩa Huyền\n",
    "# text           [xxbos, xxmaj, lâm, xxup, tế, xxmaj, nghĩa, xxmaj, huyền, \\n\\n, xxmaj, lâm, xxup, tế, xxmaj, nghĩa, xxmaj, huyền, (, zh, ., \", línjì, yìxuán, \", /, \", lin, -, chi, i, -, hsüan, \", 臨濟義玄, ,, ja, ., \", rinzai, gigen, \", ), ,, ?, -866, /, 867, ,, là, một, vị, xxmaj, thiền, sư, xxmaj, trung, xxmaj, quốc, ,, là, xxup, tổ, khai, dòng, thiền, xxmaj, lâm, xxup, tế, ., xxup, sư, là, môn, đệ, xuất, sắc, nhất, của, xxmaj, thiền, sư, xxmaj, hoàng, xxup, bá, xxmaj, hi, xxmaj, vận, ., xxmaj, môn, đệ, đắc, pháp, danh, tiếng, của, ...]\n",
    "# text_length                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1083\n",
    "# Name: 842, dtype: object\n",
    "#     applying ColReader gives\n",
    "#       (#1083) ['xxbos','xxmaj','lâm','xxup','tế','xxmaj','nghĩa','xxmaj','huyền','\\n\\n'...]\n",
    "#     applying Tokenizer gives\n",
    "#       (#1083) ['xxbos','xxmaj','lâm','xxup','tế','xxmaj','nghĩa','xxmaj','huyền','\\n\\n'...]\n",
    "#     applying Numericalize gives\n",
    "#       TensorText of size 1083\n",
    "\n",
    "# Final sample: (TensorText([  2,   8, 685,  ...,   8, 917,  10]),)\n",
    "\n",
    "\n",
    "# Setting up after_item: Pipeline: ToTensor\n",
    "# Setting up before_batch: Pipeline: \n",
    "# Setting up after_batch: Pipeline: \n",
    "\n",
    "# Building one batch\n",
    "# Applying item_tfms to the first sample:\n",
    "#   Pipeline: ToTensor\n",
    "#     starting from\n",
    "#       (TensorText of size 1083)\n",
    "#     applying ToTensor gives\n",
    "#       (TensorText of size 1083)\n",
    "\n",
    "# Adding the next 1 samples\n",
    "\n",
    "# No before_batch transform to apply\n",
    "\n",
    "# Collating items in a batch\n",
    "# Error! It's not possible to collate your items in a batch\n",
    "# Could not collate the 0-th members of your tuples because got the following shapes\n",
    "# torch.Size([1083]),torch.Size([1403])\n",
    "\n",
    "# TODO: in LM, for some reason the sequences in a batch aren’t padded to be of equal length \n",
    "# while making a LM. I know they are made equal when building the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LM learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### define learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(dls, \n",
    "                               AWD_LSTM, \n",
    "                               metrics=[accuracy, Perplexity()],\n",
    "                               drop_mult=1.0,\n",
    "                               pretrained=False,\n",
    "                               path=path).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026666666666666665"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "lr *= bs/48\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(fastai.text.learner.LMLearner, fastai.text.models.core.SequentialRNN)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(learn),type(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AWD_LSTM(\n",
       "   (encoder): Embedding(17280, 400, padding_idx=1)\n",
       "   (encoder_dp): EmbeddingDropout(\n",
       "     (emb): Embedding(17280, 400, padding_idx=1)\n",
       "   )\n",
       "   (rnns): ModuleList(\n",
       "     (0): WeightDropout(\n",
       "       (module): LSTM(400, 1152, batch_first=True)\n",
       "     )\n",
       "     (1): WeightDropout(\n",
       "       (module): LSTM(1152, 1152, batch_first=True)\n",
       "     )\n",
       "     (2): WeightDropout(\n",
       "       (module): LSTM(1152, 400, batch_first=True)\n",
       "     )\n",
       "   )\n",
       "   (input_dp): RNNDropout()\n",
       "   (hidden_dps): ModuleList(\n",
       "     (0): RNNDropout()\n",
       "     (1): RNNDropout()\n",
       "     (2): RNNDropout()\n",
       "   )\n",
       " ),\n",
       " LinearDecoder(\n",
       "   (decoder): Linear(in_features=400, out_features=17280, bias=True)\n",
       "   (output_dp): RNNDropout()\n",
       " ))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[0],learn.model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze() # == learn.opt.freeze_to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.optimizer.Optimizer"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(learn.opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': [{},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {'do_wd': False}],\n",
       " 'hypers': (#4) [{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05},{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05},{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05},{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05}]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.opt.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Param groups and weight shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn.opt.param_lists) # 4 layers total, for discriminative fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['torch.Size([4608, 1152]): True',\n",
       " 'torch.Size([4608, 400]): True',\n",
       " 'torch.Size([4608]): True',\n",
       " 'torch.Size([4608]): True',\n",
       " 'torch.Size([4608, 1152]): True',\n",
       " 'torch.Size([4608, 1152]): True',\n",
       " 'torch.Size([4608]): True',\n",
       " 'torch.Size([4608]): True',\n",
       " 'torch.Size([1600, 400]): True',\n",
       " 'torch.Size([1600, 1152]): True',\n",
       " 'torch.Size([1600]): True',\n",
       " 'torch.Size([1600]): True',\n",
       " 'torch.Size([17280, 400]): True',\n",
       " 'torch.Size([17280]): True']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"{getattr(i,'shape')}: {i.requires_grad}\" for l in learn.opt.param_lists for i in l]\n",
    "# all requires_grad true b/c unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn.model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.encoder.weight: torch.Size([17280, 400])',\n",
       " '0.encoder_dp.emb.weight: torch.Size([17280, 400])',\n",
       " '0.rnns.0.weight_hh_l0_raw: torch.Size([4608, 1152])',\n",
       " '0.rnns.0.module.weight_ih_l0: torch.Size([4608, 400])',\n",
       " '0.rnns.0.module.bias_ih_l0: torch.Size([4608])',\n",
       " '0.rnns.0.module.bias_hh_l0: torch.Size([4608])',\n",
       " '0.rnns.1.weight_hh_l0_raw: torch.Size([4608, 1152])',\n",
       " '0.rnns.1.module.weight_ih_l0: torch.Size([4608, 1152])',\n",
       " '0.rnns.1.module.bias_ih_l0: torch.Size([4608])',\n",
       " '0.rnns.1.module.bias_hh_l0: torch.Size([4608])',\n",
       " '0.rnns.2.weight_hh_l0_raw: torch.Size([1600, 400])',\n",
       " '0.rnns.2.module.weight_ih_l0: torch.Size([1600, 1152])',\n",
       " '0.rnns.2.module.bias_ih_l0: torch.Size([1600])',\n",
       " '0.rnns.2.module.bias_hh_l0: torch.Size([1600])',\n",
       " '1.decoder.weight: torch.Size([17280, 400])',\n",
       " '1.decoder.bias: torch.Size([17280])']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{k}: {v.shape}' for k,v in learn.model.state_dict().items()]\n",
    "# for some reason state_dict includes encoder (embedding) weight, but opt.param_lists or model.parameters don't\n",
    "# because weights of embedding (encoder) and weight of last linear layer is the same\n",
    "# because of 'tie_weights': look at awdlstm.py, in awd_lstm_lm_config 'tie_weights' is True\n",
    "# For language model, tie_weights will make embedding weight == last layer linear weight\n",
    "# Why? More efficient training. This is mentioned in AWD LSTM paper by Stephen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0243, -0.0295,  0.0454,  ...,  0.0690, -0.0007, -0.0248],\n",
       "        [-0.0952, -0.0149, -0.0250,  ...,  0.0776, -0.0633,  0.0437],\n",
       "        [ 0.0186,  0.0550, -0.0260,  ..., -0.0273, -0.0308, -0.0785],\n",
       "        ...,\n",
       "        [-0.0417, -0.0625, -0.0766,  ..., -0.0098,  0.0520, -0.0479],\n",
       "        [-0.0876,  0.0207,  0.0060,  ...,  0.0654,  0.0883,  0.0505],\n",
       "        [ 0.0072,  0.0172, -0.0932,  ...,  0.0109, -0.0129,  0.0368]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[0].encoder.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0243, -0.0295,  0.0454,  ...,  0.0690, -0.0007, -0.0248],\n",
       "        [-0.0952, -0.0149, -0.0250,  ...,  0.0776, -0.0633,  0.0437],\n",
       "        [ 0.0186,  0.0550, -0.0260,  ..., -0.0273, -0.0308, -0.0785],\n",
       "        ...,\n",
       "        [-0.0417, -0.0625, -0.0766,  ..., -0.0098,  0.0520, -0.0479],\n",
       "        [-0.0876,  0.0207,  0.0060,  ...,  0.0654,  0.0883,  0.0505],\n",
       "        [ 0.0072,  0.0172, -0.0932,  ...,  0.0109, -0.0129,  0.0368]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model.state_dict()['0.encoder.weight'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_equal(learn.model.state_dict()['0.encoder.weight'].data, \n",
    "          learn.model[0].encoder.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0243, -0.0295,  0.0454,  ...,  0.0690, -0.0007, -0.0248],\n",
       "        [-0.0952, -0.0149, -0.0250,  ...,  0.0776, -0.0633,  0.0437],\n",
       "        [ 0.0186,  0.0550, -0.0260,  ..., -0.0273, -0.0308, -0.0785],\n",
       "        ...,\n",
       "        [-0.0417, -0.0625, -0.0766,  ..., -0.0098,  0.0520, -0.0479],\n",
       "        [-0.0876,  0.0207,  0.0060,  ...,  0.0654,  0.0883,  0.0505],\n",
       "        [ 0.0072,  0.0172, -0.0932,  ...,  0.0109, -0.0129,  0.0368]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[1].decoder.weight.data # last layer linear weight\n",
    "# same as embedding weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_equal(learn.model.state_dict()['0.encoder.weight'].data, \n",
    "          learn.model[1].decoder.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x7fb215983740'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(id(learn.model[0].encoder.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x7fb215983740'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(id(learn.model[1].decoder.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn.opt.param_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([17280, 400]), torch.Size([17280])]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[getattr(i,'shape') for i in learn.opt.param_lists[3]] \n",
    "# matrix weight + bias of last linear layer (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([4608, 1152]),\n",
       " torch.Size([4608, 400]),\n",
       " torch.Size([4608]),\n",
       " torch.Size([4608])]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (0): WeightDropout(\n",
    "#        (module): LSTM(400, 1152, batch_first=True)\n",
    "#      )\n",
    "\n",
    "[getattr(i,'shape') for i in learn.opt.param_lists[0]] # 1st LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Weights of an LSTM unidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = nn.LSTM(400, 1152, bias=True, bidirectional=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0154, -0.0289, -0.0189,  ..., -0.0088,  0.0129, -0.0005],\n",
       "         [ 0.0147,  0.0234, -0.0261,  ...,  0.0021, -0.0199, -0.0066],\n",
       "         [ 0.0122, -0.0047,  0.0102,  ..., -0.0054,  0.0280,  0.0257],\n",
       "         ...,\n",
       "         [-0.0137,  0.0106,  0.0207,  ..., -0.0227,  0.0077,  0.0251],\n",
       "         [ 0.0158,  0.0088,  0.0237,  ...,  0.0218, -0.0261, -0.0080],\n",
       "         [ 0.0017,  0.0107, -0.0004,  ..., -0.0087,  0.0027, -0.0047]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0095,  0.0015, -0.0041,  ..., -0.0149, -0.0061,  0.0075],\n",
       "         [-0.0145, -0.0124, -0.0137,  ..., -0.0154,  0.0172,  0.0203],\n",
       "         [-0.0255, -0.0040,  0.0278,  ..., -0.0156, -0.0256, -0.0002],\n",
       "         ...,\n",
       "         [ 0.0093,  0.0231, -0.0046,  ...,  0.0017, -0.0092, -0.0159],\n",
       "         [ 0.0188, -0.0189, -0.0195,  ..., -0.0237, -0.0179,  0.0262],\n",
       "         [ 0.0191, -0.0118, -0.0157,  ..., -0.0025, -0.0293, -0.0082]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0160,  0.0267,  0.0284,  ...,  0.0209, -0.0049,  0.0090],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0094,  0.0098, -0.0009,  ...,  0.0104,  0.0169,  0.0030],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(temp.parameters()) #weight_ih_l0, weight hh_l0 and two biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4608, 400]), torch.Size([4608, 1152]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.weight_ih_l0.shape,temp.weight_hh_l0.shape\n",
    "\n",
    "# ~LSTM.weight_ih_l[k] – the learnable input-hidden weights of the kth layer \n",
    "# (W_ii|W_if|W_ig|W_io), of shape (4*hidden_size, input_size) for k = 0. \n",
    "# Otherwise, the shape is (4*hidden_size, num_directions * hidden_size)\n",
    "\n",
    "# ~LSTM.weight_hh_l[k] – the learnable hidden-hidden weights of the kth layer \n",
    "# (W_hi|W_hf|W_hg|W_ho), of shape (4*hidden_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4608"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4*1152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([4608, 1152]),\n",
       " torch.Size([4608, 1152]),\n",
       " torch.Size([4608]),\n",
       " torch.Size([4608])]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1): WeightDropout(\n",
    "#        (module): LSTM(1152, 1152, batch_first=True)\n",
    "#      )\n",
    "\n",
    "[getattr(i,'shape') for i in learn.opt.param_lists[1]] # 2nd LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1600, 400]),\n",
       " torch.Size([1600, 1152]),\n",
       " torch.Size([1600]),\n",
       " torch.Size([1600])]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (2): WeightDropout(\n",
    "# (module): LSTM(1152, 400, batch_first=True)\n",
    "# )\n",
    "    \n",
    "[getattr(i,'shape') for i in learn.opt.param_lists[2]] # 3rd LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#4) [{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05},{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05},{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05},{'wd': 0.01, 'sqr_mom': 0.99, 'lr': 0.001, 'mom': 0.9, 'eps': 1e-05}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.opt.hypers # list of hyperparams for each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### quick review on slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice(None, 1, None)\n",
      "slice(None, 1, None)\n",
      "slice(1, None, None)\n",
      "slice(1, 2, None)\n",
      "slice(1, 2, 3)\n",
      "slice(None, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "# slice(start, stop, step)\n",
    "print(slice(1))\n",
    "print(slice(None,1))\n",
    "print(slice(1,None))\n",
    "print(slice(1,2))\n",
    "print(slice(1,2,3))\n",
    "print(slice(None,2,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(range(10))[slice(None)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [0],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2, 3],\n",
       " [0, 1, 2, 3, 4],\n",
       " [0, 1, 2, 3, 4, 5],\n",
       " [0, 1, 2, 3, 4, 5, 6],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8]]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(range(10))[slice(i)] for i in range(10)] # [:0],[:1],[:2]..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [3, 4, 5, 6, 7, 8, 9],\n",
       " [4, 5, 6, 7, 8, 9],\n",
       " [5, 6, 7, 8, 9],\n",
       " [6, 7, 8, 9],\n",
       " [7, 8, 9],\n",
       " [8, 9],\n",
       " [9]]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(range(10))[slice(i,None)] for i in range(10)] # [0:],[1:],[2:] ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9]]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(range(10))[slice(i,i+2)] for i in range(10)] # [0:2],[1:3], ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10))[slice(0,7,2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.169965</td>\n",
       "      <td>6.045080</td>\n",
       "      <td>0.118188</td>\n",
       "      <td>422.031403</td>\n",
       "      <td>02:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# learn.fit_one_cycle(1, lr, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.806398</td>\n",
       "      <td>6.704211</td>\n",
       "      <td>0.097202</td>\n",
       "      <td>815.833862</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.696845</td>\n",
       "      <td>6.619418</td>\n",
       "      <td>0.097108</td>\n",
       "      <td>749.508484</td>\n",
       "      <td>01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.653021</td>\n",
       "      <td>6.539008</td>\n",
       "      <td>0.097211</td>\n",
       "      <td>691.600281</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "learn.fit_one_cycle(3, lr, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.727336</td>\n",
       "      <td>6.712237</td>\n",
       "      <td>0.097212</td>\n",
       "      <td>822.408630</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.591891</td>\n",
       "      <td>6.539766</td>\n",
       "      <td>0.097202</td>\n",
       "      <td>692.124817</td>\n",
       "      <td>01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.492364</td>\n",
       "      <td>6.423313</td>\n",
       "      <td>0.097212</td>\n",
       "      <td>616.040466</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "learn.fit_one_cycle(3, lr, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.153887</td>\n",
       "      <td>5.969858</td>\n",
       "      <td>0.119671</td>\n",
       "      <td>391.450165</td>\n",
       "      <td>02:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.682713</td>\n",
       "      <td>4.455638</td>\n",
       "      <td>0.261569</td>\n",
       "      <td>86.111069</td>\n",
       "      <td>02:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.234314</td>\n",
       "      <td>4.185904</td>\n",
       "      <td>0.289397</td>\n",
       "      <td>65.752914</td>\n",
       "      <td>02:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# learn.fit_one_cycle(3, lr, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Re-check learnable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# learn.opt.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn.opt.state_dict()['state']) # save grad_avg and sqr_avg?? for each learnable params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0336, -0.0886,  0.0438,  ...,  0.0551,  0.0465, -0.1152],\n",
       "        [-0.0913,  0.0067, -0.0356,  ...,  0.0381, -0.0388,  0.0329],\n",
       "        [ 0.2615,  0.1244, -0.0529,  ...,  0.0577,  0.0020, -0.1857],\n",
       "        ...,\n",
       "        [-0.0458, -0.0353, -0.0734,  ..., -0.0265,  0.0467, -0.0379],\n",
       "        [-0.0700,  0.0169,  0.0028,  ...,  0.0447,  0.0649,  0.0274],\n",
       "        [-0.0097,  0.0284, -0.0868,  ..., -0.0103, -0.0008,  0.0188]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[0].encoder.weight.data # weight is updated everywhere. Good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/quan/.fastai/data/viwiki/models')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vi_wt', 'vi_wt_vocab']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/quan/.fastai/data/viwiki/models/vi_wt.pth')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.to_fp32().save(mdl_path/lm_fns[0], with_opt=False) \n",
    "# save the state_dict (all possible learnable parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(mdl_path/(lm_fns[1] + '.pkl')):\n",
    "    os.remove(mdl_path/(lm_fns[1] + '.pkl'))\n",
    "#     print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17280"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn.dls.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(mdl_path/(lm_fns[1] + '.pkl'), 'wb') as f:\n",
    "    pickle.dump(learn.dls.vocab, f) # save list of strings, which are vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### try drop_mult 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.453883</td>\n",
       "      <td>6.472377</td>\n",
       "      <td>0.101275</td>\n",
       "      <td>647.020081</td>\n",
       "      <td>02:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = language_model_learner(dls, \n",
    "                               AWD_LSTM, \n",
    "                               metrics=[accuracy, Perplexity()],\n",
    "                               drop_mult=0.5,\n",
    "                               pretrained=False,\n",
    "                               path=path).to_fp16()\n",
    "\n",
    "lr = 1e-2\n",
    "lr *= bs/48\n",
    "lr\n",
    "\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(1, lr, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/quantran/.fastai/data/viwiki/models\n"
     ]
    }
   ],
   "source": [
    "mdl_path = path/'models'\n",
    "print(mdl_path)\n",
    "mdl_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lm_fns = [f'vi_wt', f'vi_wt_vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# learn.to_fp32().save(mdl_path/lm_fns[0], with_opt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# learn.dls.vocab.save(mdl_path/(lm_fns[1] + '.pkl'))\n",
    "# with open(mdl_path/(lm_fns[1] + '.pkl'), 'wb') as f:\n",
    "#     pickle.dump(learn.dls.vocab, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### try original wikitext param training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "config = awd_lstm_lm_config.copy()\n",
    "config.update({'input_p': 0.6, 'output_p': 0.4, 'weight_p': 0.5, 'embed_p': 0.1, 'hidden_p': 0.2})\n",
    "model = get_language_model(AWD_LSTM, len(dls.vocab), config=config)\n",
    "opt_func = partial(Adam, wd=0.1, eps=1e-7)\n",
    "cbs = [MixedPrecision(clip=0.1), ModelResetter, RNNRegularizer(alpha=2, beta=1)]\n",
    "learn = Learner(dls, model, \n",
    "                loss_func=CrossEntropyLossFlat(), \n",
    "                opt_func=opt_func, \n",
    "                cbs=cbs, metrics=[accuracy, Perplexity()]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>202909.375000</td>\n",
       "      <td>9.725590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16740.558594</td>\n",
       "      <td>03:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 5e-03, moms=(0.8,0.7,0.8), div=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning LM with sentiment analysis data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## prepare datablock and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df.loc[pd.isna(train_df.comment),'comment']='NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_df.loc[pd.isna(test_df.comment),'comment']='NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_000000</td>\n",
       "      <td>Dung dc sp tot cam on \\nshop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_000001</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_000002</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_000003</td>\n",
       "      <td>:(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_000004</td>\n",
       "      <td>Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý :((</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  \\\n",
       "0  train_000000   \n",
       "1  train_000001   \n",
       "2  train_000002   \n",
       "3  train_000003   \n",
       "4  train_000004   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  comment  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                       Dung dc sp tot cam on \\nshop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                       Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                 Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất   \n",
       "3  :(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                  Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý :((   \n",
       "\n",
       "   label  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    1.0  \n",
       "4    1.0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([train_df,test_df], sort=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "dls_sen = TextDataLoaders.from_df(df, path=path, text_col='comment', \n",
    "                                  is_lm=True, \n",
    "                                  valid_pct=0.1,\n",
    "                                  seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj giày đẹp nhưng chắc đi nhanh hỏng xxrep 3 😂 xxbos xxmaj bảo hỗn hợp nhưng toàn là xxunk kẹo dâu chắc được tầm chục cái @@ xxbos xxmaj nhấn tần vài lần là bọt tung xxunk thích ơi là thích xxbos xxmaj chất lượng sản phẩm rất kém . xxmaj rất không đáng tiền xxbos xxmaj giao hàng rất nhanh lần này gà hơi bị vụng cơm cháy nát</td>\n",
       "      <td>xxmaj giày đẹp nhưng chắc đi nhanh hỏng xxrep 3 😂 xxbos xxmaj bảo hỗn hợp nhưng toàn là xxunk kẹo dâu chắc được tầm chục cái @@ xxbos xxmaj nhấn tần vài lần là bọt tung xxunk thích ơi là thích xxbos xxmaj chất lượng sản phẩm rất kém . xxmaj rất không đáng tiền xxbos xxmaj giao hàng rất nhanh lần này gà hơi bị vụng cơm cháy nát và</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxmaj shop phục vụ rất kém mình đặt 4 bộ thì 1 bộ giao sai mẫu 1 bộ giao thiếu mũ . xxmaj liên hệ với shop nói mình đồng ý nhận bộ sai xxunk chỉ yêu cầu shop gửi mũ cho mình chứ mình không trả hàng lại xxunk đọc tin nhắn rồi i m lặng không đáng bao nhiêu tiền nhưng làm ăn mất uy tín quá xxbos đóng gói</td>\n",
       "      <td>shop phục vụ rất kém mình đặt 4 bộ thì 1 bộ giao sai mẫu 1 bộ giao thiếu mũ . xxmaj liên hệ với shop nói mình đồng ý nhận bộ sai xxunk chỉ yêu cầu shop gửi mũ cho mình chứ mình không trả hàng lại xxunk đọc tin nhắn rồi i m lặng không đáng bao nhiêu tiền nhưng làm ăn mất uy tín quá xxbos đóng gói sản</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxbos xxmaj mình đặt giao ngày thứ 3 vừa rồi thì thấy thiếu postcard và lịch nên liên hệ cho tiki ngay thế mà nói xem lại rồi xxunk ba ngày vẫn chưa thấy gọi lại ! xxmaj mong tiki khắc phục sự cố này xxbos xxmaj good product quality \\n▁ xxmaj excellent service by seller \\n▁ xxmaj fast delivery xxbos xxmaj xấu . xxmaj toàn dính vào đi mấy ngày là</td>\n",
       "      <td>xxmaj mình đặt giao ngày thứ 3 vừa rồi thì thấy thiếu postcard và lịch nên liên hệ cho tiki ngay thế mà nói xem lại rồi xxunk ba ngày vẫn chưa thấy gọi lại ! xxmaj mong tiki khắc phục sự cố này xxbos xxmaj good product quality \\n▁ xxmaj excellent service by seller \\n▁ xxmaj fast delivery xxbos xxmaj xấu . xxmaj toàn dính vào đi mấy ngày là bung</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_sen.show_batch(max_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load params and vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vi_wt', 'vi_wt_vocab']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('/home/quan/.fastai/data/viwiki/models/vi_wt.pth'),\n",
       " Path('/home/quan/.fastai/data/viwiki/models/vi_wt_vocab.pkl')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[mdl_path/(lm_fns[0]+'.pth'),mdl_path/(lm_fns[1] + '.pkl')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Recreating def load_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wgts = torch.load(mdl_path/(lm_fns[0]+'.pth'), map_location = lambda storage,loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([17280, 400]), torch.Size([4608, 1152]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgts['0.encoder.weight'].shape,wgts['0.rnns.0.weight_hh_l0_raw'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn_sen = language_model_learner(dls_sen, \n",
    "                               AWD_LSTM, \n",
    "                               metrics=[accuracy, Perplexity()],\n",
    "                               drop_mult=1.0,\n",
    "                               pretrained_fnames=lm_fns,\n",
    "                               path=path).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# bs=64\n",
    "# bs=24\n",
    "bs=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "lr *= bs/48."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5128"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls_sen.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(5128, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(5128, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=5128, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_sen.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['torch.Size([4608, 1152]): False',\n",
       " 'torch.Size([4608, 400]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([4608, 1152]): False',\n",
       " 'torch.Size([4608, 1152]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([1600, 400]): False',\n",
       " 'torch.Size([1600, 1152]): False',\n",
       " 'torch.Size([1600]): False',\n",
       " 'torch.Size([1600]): False',\n",
       " 'torch.Size([5128, 400]): True',\n",
       " 'torch.Size([5128]): True']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"{getattr(i,'shape')}: {i.requires_grad}\" for l in learn_sen.opt.param_lists for i in l]\n",
    "# only the head (last linear layer) is True, since we only finetune the head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.895545</td>\n",
       "      <td>5.534836</td>\n",
       "      <td>0.133145</td>\n",
       "      <td>253.366302</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.668543</td>\n",
       "      <td>5.379343</td>\n",
       "      <td>0.161419</td>\n",
       "      <td>216.879745</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.575931</td>\n",
       "      <td>5.338593</td>\n",
       "      <td>0.165864</td>\n",
       "      <td>208.219543</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_sen.fit_one_cycle(3, lr*10, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.190370</td>\n",
       "      <td>4.907573</td>\n",
       "      <td>0.247475</td>\n",
       "      <td>135.310577</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.974602</td>\n",
       "      <td>4.730784</td>\n",
       "      <td>0.267444</td>\n",
       "      <td>113.384468</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.768903</td>\n",
       "      <td>4.498777</td>\n",
       "      <td>0.289670</td>\n",
       "      <td>89.907097</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.530974</td>\n",
       "      <td>4.286935</td>\n",
       "      <td>0.310286</td>\n",
       "      <td>72.743156</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.364449</td>\n",
       "      <td>4.166526</td>\n",
       "      <td>0.321553</td>\n",
       "      <td>64.491013</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.278217</td>\n",
       "      <td>4.087682</td>\n",
       "      <td>0.328841</td>\n",
       "      <td>59.601589</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.200037</td>\n",
       "      <td>4.056414</td>\n",
       "      <td>0.331785</td>\n",
       "      <td>57.766796</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.176338</td>\n",
       "      <td>4.048688</td>\n",
       "      <td>0.332487</td>\n",
       "      <td>57.322224</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_sen.unfreeze()\n",
    "learn_sen.fit_one_cycle(8, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.629779</td>\n",
       "      <td>4.114153</td>\n",
       "      <td>0.319868</td>\n",
       "      <td>61.200378</td>\n",
       "      <td>00:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.226692</td>\n",
       "      <td>3.956623</td>\n",
       "      <td>0.331434</td>\n",
       "      <td>52.280468</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.043056</td>\n",
       "      <td>3.915927</td>\n",
       "      <td>0.335153</td>\n",
       "      <td>50.195576</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# learn_sen.fit_one_cycle(3, lr*10, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.970504</td>\n",
       "      <td>3.848961</td>\n",
       "      <td>0.341873</td>\n",
       "      <td>46.944244</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.876658</td>\n",
       "      <td>3.764037</td>\n",
       "      <td>0.350300</td>\n",
       "      <td>43.122166</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.775550</td>\n",
       "      <td>3.710275</td>\n",
       "      <td>0.355639</td>\n",
       "      <td>40.865040</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.702173</td>\n",
       "      <td>3.653225</td>\n",
       "      <td>0.362710</td>\n",
       "      <td>38.598965</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.634814</td>\n",
       "      <td>3.627688</td>\n",
       "      <td>0.365209</td>\n",
       "      <td>37.625713</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.563126</td>\n",
       "      <td>3.611554</td>\n",
       "      <td>0.367025</td>\n",
       "      <td>37.023540</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.509881</td>\n",
       "      <td>3.606653</td>\n",
       "      <td>0.367896</td>\n",
       "      <td>36.842525</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.499975</td>\n",
       "      <td>3.606580</td>\n",
       "      <td>0.367998</td>\n",
       "      <td>36.839863</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# learn_sen.unfreeze()\n",
    "# learn_sen.fit_one_cycle(8, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn_sen.save_encoder('finetuned_sen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Check how word embedding and hidden state are loaded to sentiment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or this https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-10-422d87c3340c\n",
    "# https://nlp.fast.ai/\n",
    "# watch https://www.youtube.com/watch?v=vnOpEwmtFJ8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## prepare text clas datablock and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# bs=64\n",
    "# bs=24\n",
    "bs=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df.loc[pd.isna(train_df.comment),'comment']='NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_000000</td>\n",
       "      <td>Dung dc sp tot cam on \\nshop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_000001</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_000002</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_000003</td>\n",
       "      <td>:(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_000004</td>\n",
       "      <td>Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý :((</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  \\\n",
       "0  train_000000   \n",
       "1  train_000001   \n",
       "2  train_000002   \n",
       "3  train_000003   \n",
       "4  train_000004   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  comment  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                       Dung dc sp tot cam on \\nshop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                       Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                 Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất   \n",
       "3  :(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                  Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý :((   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.576863\n",
       "1    0.423137\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sen_db = DataBlock(blocks=(TextBlock.from_df('comment', seq_len=72, vocab=dls_sen.vocab), CategoryBlock),\n",
    "                      get_x=ColReader('text'), # fixed value\n",
    "                      get_y=ColReader('label'),\n",
    "                      splitter=RandomSplitter(valid_pct=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting-up type transforms pipelines\n",
      "Collecting items from                  id  \\\n",
      "0      train_000000   \n",
      "1      train_000001   \n",
      "2      train_000002   \n",
      "3      train_000003   \n",
      "4      train_000004   \n",
      "...             ...   \n",
      "16082  train_016082   \n",
      "16083  train_016083   \n",
      "16084  train_016084   \n",
      "16085  train_016085   \n",
      "16086  train_016086   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       comment  \\\n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Dung dc sp tot cam on \\nshop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời   \n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh   \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất   \n",
      "3                                                                                                                       :(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...   \n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý :((   \n",
      "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ...   \n",
      "16082                                                                                                                                                                                                                                                                                                                                                                                                       Chẳng biết là Shop có biết đọc hay không mua ốp có mỗi 3 mầu xanh - đen - đỏ. Ngta đã inbox hỏi rõ là còn hàng không kêu có mà đặt 2 cái 1 đen 1 xanh ghi chú rõ xong gửi 1 đỏ 1 xanh chán đời - về học lại chữ đi   \n",
      "16083  Cuốn này mỏng. Đọc một buổi sáng là hết. Thú thật nó làm tôi hơi thất vọng có thể vì tôi đã kì vọng hơi cao vào tác phẩm Hàn Quốc đầu tiên trong đời. Nhưng thôi tôi sẽ cố gắng nhận xét khách quan nhất có thể.\\nTuy đặt vào tình huống đau buồn - sau sự ra đi của một cậu học sinh mới mười sáu tuổi - nhưng Tôi đã chết vào một ngày nào đó không quá u ám nặng nề. Thay vì khai thác tột cùng nỗi đau và mất mát, tác giả cố gắng xoa dịu nó, hàn gắn nó bằng những kí ức tươi đẹp, những suy tư giản dị, gần gũi và những tình cảm chân thành. Truyện kể theo lời nhân vật Yoo Mi - bạn thân nhất của cậu bé đ...   \n",
      "16084                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Mang êm chân. Đẹp    \n",
      "16085                                                 Tôi đã nhận đc hàng.Sau đây là vài lời muốn nói.\\nMã code để check hàng chính hãng không tồn tại trên trang web của hãng. Mặc dù chính tôi cào nó ra. Có dấu hiệu đã bị mở hộp, vỏ ngoài lem lem.\\nTôi đã tin tưởng vào mã code, vì nhiều lần mua hàng của digiworl, nhưng đến hôm nay tikitrading đã làm mất hình ảnh đó.\\nMón đồ không quá đắt đỏ mua được sự gian dối của tikitrading quá là hời cho tôi.\\nNếu đây là món hàng vài chục triệu thì sao ?\\nTất nhiên tôi sẽ làm sáng toả mọi chuyện trên các diễn đàn công nghệ.\\nOK xem như tôi đặt niềm tin nhầm chỗ.   \n",
      "16086                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Hình vậy mà túi xấu qá kém chất lg qá   \n",
      "\n",
      "       label  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          1  \n",
      "4          1  \n",
      "...      ...  \n",
      "16082      1  \n",
      "16083      1  \n",
      "16084      0  \n",
      "16085      1  \n",
      "16086      1  \n",
      "\n",
      "[16087 rows x 3 columns]\n",
      "Found 16087 items\n",
      "2 datasets of sizes 14479,1608\n",
      "Setting up Pipeline: ColReader -- {'cols': 'text', 'pref': '', 'suff': '', 'label_delim': None} -> Tokenizer -> Numericalize\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Pipeline: ColReader -- {'cols': 'label', 'pref': '', 'suff': '', 'label_delim': None} -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
      "\n",
      "Building one sample\n",
      "  Pipeline: ColReader -- {'cols': 'text', 'pref': '', 'suff': '', 'label_delim': None} -> Tokenizer -> Numericalize\n",
      "    starting from\n",
      "      id                                                                                                                                   train_011400\n",
      "label                                                                                                                                           1\n",
      "text           [xxbos, đồng, hồ, cứ, đến, 23h, mỗi, ngày, lại, bị, chết, sáng, dậy, phải, chỉnh, lại, ., xxmaj, chất, lượng, sản, phẩm, rất, kém]\n",
      "text_length                                                                                                                                    24\n",
      "Name: 11400, dtype: object\n",
      "    applying ColReader -- {'cols': 'text', 'pref': '', 'suff': '', 'label_delim': None} gives\n",
      "      ['xxbos', 'đồng', 'hồ', 'cứ', 'đến', '23h', 'mỗi', 'ngày', 'lại', 'bị', 'chết', 'sáng', 'dậy', 'phải', 'chỉnh', 'lại', '.', 'xxmaj', 'chất', 'lượng', 'sản', 'phẩm', 'rất', 'kém']\n",
      "    applying Tokenizer gives\n",
      "      ['xxbos', 'đồng', 'hồ', 'cứ', 'đến', '23h', 'mỗi', 'ngày', 'lại', 'bị', 'chết', 'sáng', 'dậy', 'phải', 'chỉnh', 'lại', '.', 'xxmaj', 'chất', 'lượng', 'sản', 'phẩm', 'rất', 'kém']\n",
      "    applying Numericalize gives\n",
      "      TensorText of size 24\n",
      "  Pipeline: ColReader -- {'cols': 'label', 'pref': '', 'suff': '', 'label_delim': None} -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
      "    starting from\n",
      "      id                                                                                                                                   train_011400\n",
      "label                                                                                                                                           1\n",
      "text           [xxbos, đồng, hồ, cứ, đến, 23h, mỗi, ngày, lại, bị, chết, sáng, dậy, phải, chỉnh, lại, ., xxmaj, chất, lượng, sản, phẩm, rất, kém]\n",
      "text_length                                                                                                                                    24\n",
      "Name: 11400, dtype: object\n",
      "    applying ColReader -- {'cols': 'label', 'pref': '', 'suff': '', 'label_delim': None} gives\n",
      "      1\n",
      "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
      "      TensorCategory(1)\n",
      "\n",
      "Final sample: (TensorText([   2,  193,  248,  308,  159,    0,  325,  131,   53,   43,  776,  313,\n",
      "        1606,   85,  704,   53,    9,    8,   15,   16,   12,   11,   10,   47]), TensorCategory(1))\n",
      "\n",
      "\n",
      "Collecting items from                  id  \\\n",
      "0      train_000000   \n",
      "1      train_000001   \n",
      "2      train_000002   \n",
      "3      train_000003   \n",
      "4      train_000004   \n",
      "...             ...   \n",
      "16082  train_016082   \n",
      "16083  train_016083   \n",
      "16084  train_016084   \n",
      "16085  train_016085   \n",
      "16086  train_016086   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       comment  \\\n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Dung dc sp tot cam on \\nshop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời   \n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh   \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất   \n",
      "3                                                                                                                       :(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...   \n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý :((   \n",
      "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ...   \n",
      "16082                                                                                                                                                                                                                                                                                                                                                                                                       Chẳng biết là Shop có biết đọc hay không mua ốp có mỗi 3 mầu xanh - đen - đỏ. Ngta đã inbox hỏi rõ là còn hàng không kêu có mà đặt 2 cái 1 đen 1 xanh ghi chú rõ xong gửi 1 đỏ 1 xanh chán đời - về học lại chữ đi   \n",
      "16083  Cuốn này mỏng. Đọc một buổi sáng là hết. Thú thật nó làm tôi hơi thất vọng có thể vì tôi đã kì vọng hơi cao vào tác phẩm Hàn Quốc đầu tiên trong đời. Nhưng thôi tôi sẽ cố gắng nhận xét khách quan nhất có thể.\\nTuy đặt vào tình huống đau buồn - sau sự ra đi của một cậu học sinh mới mười sáu tuổi - nhưng Tôi đã chết vào một ngày nào đó không quá u ám nặng nề. Thay vì khai thác tột cùng nỗi đau và mất mát, tác giả cố gắng xoa dịu nó, hàn gắn nó bằng những kí ức tươi đẹp, những suy tư giản dị, gần gũi và những tình cảm chân thành. Truyện kể theo lời nhân vật Yoo Mi - bạn thân nhất của cậu bé đ...   \n",
      "16084                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Mang êm chân. Đẹp    \n",
      "16085                                                 Tôi đã nhận đc hàng.Sau đây là vài lời muốn nói.\\nMã code để check hàng chính hãng không tồn tại trên trang web của hãng. Mặc dù chính tôi cào nó ra. Có dấu hiệu đã bị mở hộp, vỏ ngoài lem lem.\\nTôi đã tin tưởng vào mã code, vì nhiều lần mua hàng của digiworl, nhưng đến hôm nay tikitrading đã làm mất hình ảnh đó.\\nMón đồ không quá đắt đỏ mua được sự gian dối của tikitrading quá là hời cho tôi.\\nNếu đây là món hàng vài chục triệu thì sao ?\\nTất nhiên tôi sẽ làm sáng toả mọi chuyện trên các diễn đàn công nghệ.\\nOK xem như tôi đặt niềm tin nhầm chỗ.   \n",
      "16086                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Hình vậy mà túi xấu qá kém chất lg qá   \n",
      "\n",
      "       label  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          1  \n",
      "4          1  \n",
      "...      ...  \n",
      "16082      1  \n",
      "16083      1  \n",
      "16084      0  \n",
      "16085      1  \n",
      "16086      1  \n",
      "\n",
      "[16087 rows x 3 columns]\n",
      "Found 16087 items\n",
      "2 datasets of sizes 14479,1608\n",
      "Setting up Pipeline: ColReader -- {'cols': 'text', 'pref': '', 'suff': '', 'label_delim': None} -> Tokenizer -> Numericalize\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Pipeline: ColReader -- {'cols': 'label', 'pref': '', 'suff': '', 'label_delim': None} -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
      "Setting up after_item: Pipeline: ToTensor\n",
      "Setting up before_batch: Pipeline: Pad_Chunk -- {'pad_idx': 1, 'pad_first': True, 'seq_len': 72}\n",
      "Setting up after_batch: Pipeline: \n",
      "\n",
      "Building one batch\n",
      "Applying item_tfms to the first sample:\n",
      "  Pipeline: ToTensor\n",
      "    starting from\n",
      "      (TensorText of size 24, TensorCategory(1))\n",
      "    applying ToTensor gives\n",
      "      (TensorText of size 24, TensorCategory(1))\n",
      "\n",
      "Adding the next 1 samples\n",
      "\n",
      "Applying before_batch to the list of samples\n",
      "  Pipeline: Pad_Chunk -- {'pad_idx': 1, 'pad_first': True, 'seq_len': 72}\n",
      "    starting from\n",
      "      [(TensorText of size 24, TensorCategory(1)), (TensorText of size 22, TensorCategory(0))]\n",
      "    applying Pad_Chunk -- {'pad_idx': 1, 'pad_first': True, 'seq_len': 72} gives\n",
      "      ((TensorText of size 24, TensorCategory(1)), (TensorText of size 24, TensorCategory(0)))\n",
      "\n",
      "Collating items in a batch\n",
      "\n",
      "No batch_tfms to apply\n"
     ]
    }
   ],
   "source": [
    "sen_db.summary(train_df,bs=2)\n",
    "# note: there is before_batch (pad_chunk) that probably does the padding and make sure \n",
    "# tensor size is equal among batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Setting up Pipeline: ColReader -- {'cols': 'text', 'pref': '', 'suff': '', 'label_delim': None} -> Tokenizer -> Numericalize\n",
    "#   return array(a, dtype, copy=False, order=order)\n",
    "# Setting up Pipeline: ColReader -- {'cols': 'label', 'pref': '', 'suff': '', 'label_delim': None} -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
    "# Setting up after_item: Pipeline: ToTensor\n",
    "# Setting up before_batch: Pipeline: Pad_Chunk -- {'pad_idx': 1, 'pad_first': True, 'seq_len': 72}\n",
    "# Setting up after_batch: Pipeline: \n",
    "\n",
    "# Building one batch\n",
    "# Applying item_tfms to the first sample:\n",
    "#   Pipeline: ToTensor\n",
    "#     starting from\n",
    "#       (TensorText of size 24, TensorCategory(1))\n",
    "#     applying ToTensor gives\n",
    "#       (TensorText of size 24, TensorCategory(1))\n",
    "\n",
    "# Adding the next 1 samples\n",
    "\n",
    "# Applying before_batch to the list of samples\n",
    "#   Pipeline: Pad_Chunk -- {'pad_idx': 1, 'pad_first': True, 'seq_len': 72}\n",
    "#     starting from\n",
    "#       [(TensorText of size 24, TensorCategory(1)), (TensorText of size 22, TensorCategory(0))]\n",
    "#     applying Pad_Chunk -- {'pad_idx': 1, 'pad_first': True, 'seq_len': 72} gives\n",
    "#       ((TensorText of size 24, TensorCategory(1)), (TensorText of size 24, TensorCategory(0)))\n",
    "\n",
    "# Collating items in a batch\n",
    "\n",
    "# No batch_tfms to apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "dls_clas = sen_db.dataloaders(train_df, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: Pad_Chunk -- {'pad_idx': 1, 'pad_first': True, 'seq_len': 72}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls_clas.before_batch # maybe in text dataloader definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dls_clas = TextDataLoaders.from_df(train_df, path=path, text_col='comment', \n",
    "#                                    text_vocab = dls_sen.vocab,\n",
    "#                                    label_col='label',\n",
    "#                                   valid_pct=0.1,\n",
    "#                                   seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj cuốn này mỏng . đọc một buổi sáng là hết . xxmaj thú thật nó làm tôi hơi thất vọng có thể vì tôi đã kì vọng hơi cao vào tác phẩm xxmaj hàn xxmaj quốc đầu tiên trong đời . xxmaj nhưng thôi tôi sẽ cố gắng nhận xét khách quan nhất có thể . \\n xxmaj tuy đặt vào tình huống đau buồn - sau sự ra đi của một cậu học sinh mới mười sáu tuổi - nhưng xxmaj tôi đã chết vào một ngày nào đó không quá u ám nặng nề . xxmaj thay vì khai thác tột cùng nỗi đau và mất mát , tác giả cố gắng xxunk dịu nó , hàn gắn nó bằng những kí ức tươi đẹp , những suy tư giản dị , gần gũi và những tình cảm chân thành . xxmaj truyện kể theo lời</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxbos xxmaj cuốn sách này của xxup tờ xxmaj pi mình không mua mà đọc được nó khi một người bạn giới thiệu và cho mượn .khi đọc xong cuốn sách này thì mình cảm thấy một điều là chưa đủ . \\n xxmaj tác giả chưa đủ trải , câu chuyện chưa đủ ngấm . xxmaj các bạn trẻ khi đọc vào có thể cảm thấy , ừ tác phẩm này rất đời , rất thực ấy chứ . xxmaj nhưng với mình như thế vẫn là chưa đủ cho một tác phẩm mang tính phản ánh xã hội . xxmaj khi mà tác giả mượn những câu chuyện thường ngày , mượn những điều gần gũi , chân thực với mỗi chúng ta để xxunk lộ , cắt lát nhiều khía cạnh cuộc sống thì mình thấy tác giả phải đủ trải hay ít nhất là đủ hiểu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxbos xxmaj mình đặt mua xxmaj tạm biệt em ổn hộ một người bạn . xxup nó siêu thích chị xxup tờ xxmaj pi vì có theo dõi facebook chị ý nó bảo chị ý cá tính status nhiều câu hay và đúng xxunk về , mình có tò mò đọc thử , trước đó mình chưa từng đọc gì liên quan đến chị xxup tờ xxmaj pi cả . \\n xxmaj với quan điểm cá nhân của mình , thì mình không ưng cuốn sách ở lối viết . xxup vì mình hoài cổ lắm , mình thích văn học nhẹ nhàng , bay bổng , mà chị xxup tờ xxmaj pi viết thì trần trụi quá , đúng kiểu văn thô mới là văn thật . \\n xxmaj trong xxmaj tạm biệt , em ổn là những câu chuyện rất thật , rất đời . xxmaj tuy không</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_clas.show_batch(max_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## study dataloaders and tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " 'xxup',\n",
       " 'xxmaj',\n",
       " '.']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls_clas.vocab[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls_clas.vocab[1] # y labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp_i = iter(dls_clas.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y = next(temp_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 741), (128,))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorText([[   2,    8,  262,  ..., 1022,   44,    9],\n",
       "        [   1,    1,    1,  ...,  707,   76,    9],\n",
       "        [   1,    1,    1,  ...,    1,    1,    1],\n",
       "        ...,\n",
       "        [   1,    1,    1,  ...,    1,    1,    1],\n",
       "        [   1,    1,    1,  ...,    1,    1,    1],\n",
       "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note: how padding works: https://docs.fast.ai/text.data.html#Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj cuốn này mỏng . đọc một buổi sáng là hết . xxmaj thú thật nó làm tôi hơi thất vọng có thể vì tôi đã kì vọng hơi cao vào tác phẩm xxmaj hàn xxmaj quốc đầu tiên trong đời . xxmaj nhưng thôi tôi sẽ cố gắng nhận xét khách quan nhất có thể . \\n xxmaj tuy đặt vào tình huống đau buồn - sau sự ra đi của một cậu học sinh mới mười sáu tuổi - nhưng xxmaj tôi đã chết vào một ngày nào đó không quá u ám nặng nề . xxmaj thay vì khai thác tột cùng nỗi đau và mất mát , tác giả cố gắng xxunk dịu nó , hàn gắn nó bằng những kí ức tươi đẹp , những suy tư giản dị , gần gũi và những tình cảm chân thành . xxmaj truyện kể theo lời nhân vật xxmaj yoo xxmaj mi - bạn thân nhất của cậu bé đã chết - nên từng kí ức lại càng xxunk xxunk , từng tiếng cười lại càng giòn tan đến nao lòng . \\n đúng như lời giới thiệu , truyện mở đầu bằng bi kịch nhưng không kết thúc trong đau thương , mà ngược lại gieo vào lòng ta những hi vọng . xxmaj cái chết mang lại cho ta nhiều hơn những gì ta tưởng . xxmaj ta biết yêu cuộc sống hơn . xxmaj ta biết trân trọng những người xung quanh ta hơn . xxmaj ta nhận ra sự tồn tại của ta không hề vô nghĩa . xxup và ta cũng thấy được thế giới này có ý nghĩa lớn lao với ta thế nào . \\n xxmaj bởi vì , chẳng phải cậu xxmaj jae xxmaj joon đã từng giả chết để được sống tốt hơn đó sao ? \\n\\n đọc truyện , đôi lúc tôi thấy giật mình bởi những chi tiết mà có lẽ chính tác giả khi viết còn chẳng buồn để ý đến . xxmaj jae xxmaj joon đã học lớp tám rồi mà vẫn trong sáng đến kì xxunk . xxup cô giáo chủ nhiệm lớp tám sa sả những lời chẳng ra gì vào mặt xxmaj yoo xxmaj mi . xxmaj yoo xxmaj mi lớn lên cách biệt , mặc cảm , nổi loạn vì cha mẹ ly dị , và rằng xung quanh cô bé chẳng có ai phải trải qua điều đó cả . xxmaj hay mẹ của xxmaj jae xxmaj joon dễ dàng phát bệnh mỗi khi cậu làm bài kiểm tra không tốt … xxmaj tôi chưa từng thực sự tiếp xúc với con người xxmaj hàn xxmaj quốc bao giờ , nên không thể hiểu được họ . xxmaj xxunk xxmaj xxunk \" \" nâng cấp \" \" những chi tiết đó thì không nói làm gì , nhưng nếu tất cả đều là thực tế ở quốc gia đông á kia ? xxmaj phải chăng tôi đã thoáng thấy một đất nước có kinh tế phát triển quá nhanh , nhanh đến mức xã hội không xxunk theo nổi , và hệ xxunk là sinh ra những con người cô đơn , yếu đuối trở nên bi quan một cách dễ dàng , vẫn mang đầy những tư tưởng định kiến ? đáng nói hơn , những điều đó được viết ra bằng một giọng văn xxunk nhiên như thể tất cả đều rất bình thường , là chuyện đương nhiên , trong hoàn cảnh như vậy lẽ tất yếu con người phải cư xử như vậy , không bàn cãi … xxup và tôi tự hỏi , đó là bước tiến hay bước lùi trong việc bảo vệ con người ? \\n\\n xxup có hai điểm khiến tôi chưa hài lòng về cuốn sách này . \\n xxmaj thứ nhất là , xây dựng nhân vật thiên về kể lể nhiều hơn là để nhân vật tự xxunk lộ bản thân , nên cảm giác các nhân vật cứ nhàn nhạt , không tạo ấn tượng sâu sắc . \\n xxmaj thứ hai là , truyện không bắt được người đọc phải suy ngẫm , gấp cuốn sách lại nội dung truyện cứ thế trôi xxunk tuột , không đọng lại gì nhiều . \\n xxmaj nhưng đối với một tác phẩm dành cho thiếu niên như vậy cũng đủ để nhận những lời khen xứng đáng .'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([dls_clas.vocab[0][i] for i in x[0].cpu().data.numpy()]) # no padding here at 1st item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxbos xxmaj mình cho cuốn sách này 1 sao vì hai lý do sau xxunk xxup về nội dung : \" \" rạp xiếc đêm \" \" tưởng chừng là một câu chuyện vô cùng hứa hẹn và đáng đọc , nhưng đối với mình nó chỉ đem đến sự thất vọng từ đầu đến cuối . ý tưởng ban đầu của tác giả rất sáng tạo : 2 ảo thuật gia được chọn tham gia vào một cuộc đấu mà không ai biết trước đối thủ của mình . xxmaj rồi bên cạnh đó còn có rạp xiếc kỳ ảo chỉ xuất hiện vào ban đêm , những người hâm mộ - được gọi kẻ mộng mơ theo chân rạp xiếc đến mọi nơi , những màn trình diễn đẹp mắt . xxmaj nhưng tác giả hoàn toàn hủy xxunk ý tưởng đó bởi việc không xây dựng được một cốt truyện chặt chẽ , có diễn biến hấp dẫn hơn . xxmaj hơn xxunk trang sách không có nhiều sự kiện xảy ra , những tình tiết chẳng đi đến đâu , cứ lưng chừng mơ hồ chẳng mang đến cảm xúc gì rõ nét . xxmaj cuộc đấu của hai ảo thuật gia thực sự không diễn ra , mặc dù được nhắc lại nhiều lần những vẫn chẳng thấy có thi đấu gì hết . xxmaj yếu tố lãng mạn , kỳ ảo lặp đi lặp lại càng làm câu chuyện nhàm chán và xxunk nhạt hơn . xxmaj khi đọc xong cuốn sách mình không thấy đọng lại được điều gì cả . \\n - xxup về hình thức chất lượng : giấy in lần này rất tệ bản của mình giấy rất mỏng đẹp thì đẹp nhưng có một vài trang bị những vết rách ngang dọc . xxmaj thực chất là không ảnh hưởng đến nội dung lắm nhưng làm người đọc mất hứng và thấy số tiền mình bỏ ra không xứng đáng . điều tệ nhất đây không phải lần đầu tiên sách của xxup nxb xxmaj trẻ mình mua có hiện tượng này đã mấy lần như vậy rồi . xxmaj hy vọng xxup nxb xxmaj trẻ có thể đọc được và kiểm tra kỹ càng khâu in ấn hơn .'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([dls_clas.vocab[0][i] for i in x[1].cpu().data.numpy()]) # padding starts at 2nd item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxbos xxmaj tiểu thuyết của xxup cố xxmaj mạn có thể xem như chiếc thuyền đang lênh xxunk không cố định trên biển lớn . xxmaj tuy vây chiếc thuyền đi một cánh êm xxunk không sóng gió không vật cản … xxup cứ vậy rồi cập bến một cánh êm đep đã làm mất đi cái hay của tiểu thuyết ngôn tình . xxup có lẽ bạn cũng nghỉ như tôi tình yêu đẹp xâu sắc bề chặt cần phải đi qua xxunk lớn và xxunk qua sóng gió . xxmaj tôi cũng là độc giả của xxup cố xxmaj mạn nhưng đây là xxunk trừ cho những tác phẩm của xxunk khác xxmaj yêu xxmaj em xxup từ xxmaj cái xxmaj nhìn đầu xxmaj tiên , xxmaj bên xxmaj nhau xxmaj trọn đời … xxmaj bưa xxmaj trưa xxmaj tinh xxmaj yêu là một cuốn tiểu thuyết ít sóng gió , tác giả chú trọng vào thể loại hài hước , cốt truyện khá quen thuộc . xxup kể về đai xxup boss xxmaj phong đằng , lạnh lùng , nhà giàu , đẹp trai , làm tổng giám đốc của xxmaj tiết xxmaj sam xxmaj sam . xxmaj tiết xxmaj sam xxmaj sam , ngây thơ hồn nhiên , bị đại xxup boss bắt nạt , rồi cũng lại đinh xxunk tình cờ 2 người tình cờ gặp nhau , đại xxup boss chỉ vì những câu nói hồn nhiên của xxmaj tiết xxmaj sam xxmaj sam ‘ bọn tư bản quả nhiên là quỷ hút máu ’ mà bị ‘ cảm nắng ’ hơi bị đối lập với vẻ lạnh lùng cứ vậy rồi họ yêu nhau không có sóng gió dương như đã làm mất đi phần hay của tác phẩm ( xxunk % ) . xxmaj tác giả xây đựng nhân vật nữ quá hồn nhiên , ngây thơ . xxup có thể nói là quá xxup ngốc , nhưng theo xu hướng đọc truyện ngày nay thì người đọc lại thích kiểu nhân vật nữ mạnh mẽ \\n xxmaj bữa trưa tình yêu có lẽ rất phù hợp vớ những cô gái sướt mướt xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([dls_clas.vocab[0][i] for i in x[2].cpu().data.numpy()]) # padding starts at 2nd item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 17)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(temp_i)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj chất lượng sản phẩm tuyệt vời rẻ tiện ko biết bao h phải thay ga'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([dls_clas.vocab[0][i] for i in x[0].cpu().data.numpy()]) # no padding here at 1st item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj giày giống hình nhưng đi rất đau chân .. xxmaj phần da giày rất cứng'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([dls_clas.vocab[0][i] for i in x[-4].cpu().data.numpy()]) # items of this batch have similar bptt size now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SortedDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.text.data.SortedDL"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dls_clas.train) #inherit TfmdDL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A DataLoader that goes throught the item in the order given by sort_func\n",
    "\n",
    "res is the result of sort_func applied on all elements of the dataset. You can pass it if available to make the init faster by avoiding an initial pass over the whole dataset. If shuffle is True, this will shuffle a bit the results of the sort **to have items of roughly the same size in batches**, but not in the exact sorted order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: Pad_Chunk -- {'pad_idx': 1, 'pad_first': True, 'seq_len': 72}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls_clas.before_batch # this is pad_input_chunk function\n",
    "\n",
    "# 'before_batch': partial(pad_input_chunk, seq_len=seq_len)\n",
    "# https://docs.fast.ai/text.data.html#SortedDL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## datablock tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.data.block.DataBlock"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vnmese_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sen_db = DataBlock(blocks=(TextBlock.from_df('comment', seq_len=72, vocab=dls_sen.vocab), CategoryBlock),\n",
    "#                       get_x=ColReader('text'), # fixed value\n",
    "#                       get_y=ColReader('label'),\n",
    "#                       splitter=RandomSplitter(valid_pct=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sen_db.type_tfms) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Tokenizer:\n",
       "encodes: (Path,object) -> encodes\n",
       "(str,object) -> encodes\n",
       "decodes: (object,object) -> decodes\n",
       ",Numericalize:\n",
       "encodes: (object,object) -> encodes\n",
       "decodes: (object,object) -> decodes\n",
       "]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_db.type_tfms[0] # tokenizer and numericalize tfms for X pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [Categorize -- {'vocab': None, 'sort': True, 'add_na': False}:\n",
       "encodes: (object,object) -> encodes\n",
       "decodes: (object,object) -> decodes\n",
       "]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_db.type_tfms[1] # categorize for y pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [ToTensor:\n",
       "encodes: decodes: ]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_db.default_item_tfms #default item tfm (for dataloaders' after_item pipeline) for PILBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#0) []"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_db.default_batch_tfms #default batch item tfm (for dataloaders' after_batch pipeline\n",
    "# normall it will be IntToFloatTensor, but token should be int so nothing is here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#1) [ToTensor:\n",
       "encodes: decodes: ], (#0) [])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_db.item_tfms,sen_db.batch_tfms \n",
    "# nothing different from default_item_tfms and default_batch_tfms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## datasets and its tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1608, 14479)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls_clas.valid.dataset),len(dls_clas.train.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dsets = dls_clas.train.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, 2)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dsets[0]),len(dsets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35,)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_ds = dls_clas.train_ds\n",
    "\n",
    "val_ds = dls_clas.valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, fastai.data.core.TfmdLists, fastai.data.core.TfmdLists)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds.tls),type(train_ds.tls[0]),type(train_ds.tls[1]) # 2 tfmdlist, 1 for X train, 1 for y train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Pipeline: ColReader -- {'cols': 'text', 'pref': '', 'suff': '', 'label_delim': None} -> Tokenizer -> Numericalize,\n",
       " Pipeline: ColReader -- {'cols': 'text', 'pref': '', 'suff': '', 'label_delim': None} -> Tokenizer -> Numericalize)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0].tfms,val_ds.tls[0].tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Pipeline: ColReader -- {'cols': 'label', 'pref': '', 'suff': '', 'label_delim': None} -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False},\n",
       " Pipeline: ColReader -- {'cols': 'label', 'pref': '', 'suff': '', 'label_delim': None} -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False})"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[1].tfms,val_ds.tls[1].tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7939</th>\n",
       "      <td>train_007939</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, xxmaj, hàng, giao, rất, nhanh, ., đặt, hàng, lúc, 9h, sáng, 12h30, đã, nhận, được, hàng, ., xxup, ví, đẹp, cấm, vừa, tay, truyện, hay, nhiều, cảm, xúc, và, bài, học, cuộc, sống, .]</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4753</th>\n",
       "      <td>train_004753</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, xxmaj, sản, phẩm, đúng, với, hình, ảnh, ., xxmaj, shop, phục, vụ, rất, tốt, lúc, đầu, cứ, lo, shop, sẽ, gửi, không, đúng, mẫu, mình, thích, nhưng, note, lại, shop, gửi, mẫu, chuẩn]</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6668</th>\n",
       "      <td>train_006668</td>\n",
       "      <td>1</td>\n",
       "      <td>[xxbos, xxmaj, chất, lượng, sp, tốt, ., xxmaj, giao, hàng, nhanh, ., xxmaj, nhưng, vừa, chia, tay, ny, nên, vote, 2, sao, 😞]</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13496</th>\n",
       "      <td>train_013496</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, xxmaj, chất, lượng, sản, phẩm, tuyệt, vời, \\n▁, đóng, gói, sản, phẩm, rất, đẹp, và, chắc, chắn, \\n, xxmaj, anh, shipper, dễ, thương, :3, 5, sao, xxmaj, chất, lượng, sản, phẩm, tuyệt, vời, đóng, gói, sản, phẩm, rất, đẹp, và, chắc, chắn]</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8560</th>\n",
       "      <td>train_008560</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, xxmaj, chất, lượng, sản, phẩm, tuyệt, vời.giày, đẹp, chuẩn, 5sao]</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15095</th>\n",
       "      <td>train_015095</td>\n",
       "      <td>1</td>\n",
       "      <td>[xxbos, xxmaj, chất, lượng, sản, phẩm, rất, kém, ., ảnh, và, quảng, cáo, video, là, hình, ảnh, rất, đẹp, nhưng, khi, nhận, chất, cực, chán, cực, kém, chất, lượng]</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7145</th>\n",
       "      <td>train_007145</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, xxmaj, shop, nay, lam, an, ki, lam, ., xxmaj, ko, cho, đôi, hang, ., xxmaj, mọi, nh, suy, nghi, ki, hay, mua, nhé]</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12141</th>\n",
       "      <td>train_012141</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, xxmaj, shop, rất, uy, tín, ., xxmaj, lần, sau, mua, hàng, mình, sẽ, tiếp, tục, ủng, hộ, shop]</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10654</th>\n",
       "      <td>train_010654</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, xxmaj, chất, lượng, xấu, k, đáng, tiền]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5523</th>\n",
       "      <td>train_005523</td>\n",
       "      <td>0</td>\n",
       "      <td>[xxbos, xxmaj, chất, lượng, sản, phẩm, tuyệt, vời, lên, màu, cực, chuẩn, xxrep, 5, 👍]</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14479 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  label  \\\n",
       "7939   train_007939      0   \n",
       "4753   train_004753      0   \n",
       "6668   train_006668      1   \n",
       "13496  train_013496      0   \n",
       "8560   train_008560      0   \n",
       "...             ...    ...   \n",
       "15095  train_015095      1   \n",
       "7145   train_007145      0   \n",
       "12141  train_012141      0   \n",
       "10654  train_010654      0   \n",
       "5523   train_005523      0   \n",
       "\n",
       "                                                                                                                                                                                                                                                      text  \\\n",
       "7939                                                          [xxbos, xxmaj, hàng, giao, rất, nhanh, ., đặt, hàng, lúc, 9h, sáng, 12h30, đã, nhận, được, hàng, ., xxup, ví, đẹp, cấm, vừa, tay, truyện, hay, nhiều, cảm, xúc, và, bài, học, cuộc, sống, .]   \n",
       "4753                                                          [xxbos, xxmaj, sản, phẩm, đúng, với, hình, ảnh, ., xxmaj, shop, phục, vụ, rất, tốt, lúc, đầu, cứ, lo, shop, sẽ, gửi, không, đúng, mẫu, mình, thích, nhưng, note, lại, shop, gửi, mẫu, chuẩn]   \n",
       "6668                                                                                                                          [xxbos, xxmaj, chất, lượng, sp, tốt, ., xxmaj, giao, hàng, nhanh, ., xxmaj, nhưng, vừa, chia, tay, ny, nên, vote, 2, sao, 😞]   \n",
       "13496  [xxbos, xxmaj, chất, lượng, sản, phẩm, tuyệt, vời, \\n▁, đóng, gói, sản, phẩm, rất, đẹp, và, chắc, chắn, \\n, xxmaj, anh, shipper, dễ, thương, :3, 5, sao, xxmaj, chất, lượng, sản, phẩm, tuyệt, vời, đóng, gói, sản, phẩm, rất, đẹp, và, chắc, chắn]   \n",
       "8560                                                                                                                                                                             [xxbos, xxmaj, chất, lượng, sản, phẩm, tuyệt, vời.giày, đẹp, chuẩn, 5sao]   \n",
       "...                                                                                                                                                                                                                                                    ...   \n",
       "15095                                                                                   [xxbos, xxmaj, chất, lượng, sản, phẩm, rất, kém, ., ảnh, và, quảng, cáo, video, là, hình, ảnh, rất, đẹp, nhưng, khi, nhận, chất, cực, chán, cực, kém, chất, lượng]   \n",
       "7145                                                                                                                            [xxbos, xxmaj, shop, nay, lam, an, ki, lam, ., xxmaj, ko, cho, đôi, hang, ., xxmaj, mọi, nh, suy, nghi, ki, hay, mua, nhé]   \n",
       "12141                                                                                                                                                [xxbos, xxmaj, shop, rất, uy, tín, ., xxmaj, lần, sau, mua, hàng, mình, sẽ, tiếp, tục, ủng, hộ, shop]   \n",
       "10654                                                                                                                                                                                                      [xxbos, xxmaj, chất, lượng, xấu, k, đáng, tiền]   \n",
       "5523                                                                                                                                                                 [xxbos, xxmaj, chất, lượng, sản, phẩm, tuyệt, vời, lên, màu, cực, chuẩn, xxrep, 5, 👍]   \n",
       "\n",
       "       text_length  \n",
       "7939            35  \n",
       "4753            34  \n",
       "6668            23  \n",
       "13496           43  \n",
       "8560            11  \n",
       "...            ...  \n",
       "15095           29  \n",
       "7145            24  \n",
       "12141           19  \n",
       "10654            8  \n",
       "5523            15  \n",
       "\n",
       "[14479 rows x 4 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0].items \n",
    "# no transform applied yet, but note that texts have already been 'ColReader' and 'Tokenizer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorText([   2,    8,   13,   17,   10,   30,    9,   92,   13,  181, 4226,  313,\n",
       "            0,   54,   67,   38,   13,    9,    7, 1411,   18, 2628,  138,  227,\n",
       "          365,  139,   87,  105,  903,   19,  934,  560,  772,  879,    9]),\n",
       " 35)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tls[0][0],len(train_ds.tls[0][0]) # when indexed, tfms are applied (last one: Numericalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxbos',\n",
       " 'xxmaj',\n",
       " 'hàng',\n",
       " 'giao',\n",
       " 'rất',\n",
       " 'nhanh',\n",
       " '.',\n",
       " 'đặt',\n",
       " 'hàng',\n",
       " 'lúc',\n",
       " '9h',\n",
       " 'sáng',\n",
       " 'xxunk',\n",
       " 'đã',\n",
       " 'nhận',\n",
       " 'được',\n",
       " 'hàng',\n",
       " '.',\n",
       " 'xxup',\n",
       " 'ví',\n",
       " 'đẹp',\n",
       " 'cấm',\n",
       " 'vừa',\n",
       " 'tay',\n",
       " 'truyện',\n",
       " 'hay',\n",
       " 'nhiều',\n",
       " 'cảm',\n",
       " 'xúc',\n",
       " 'và',\n",
       " 'bài',\n",
       " 'học',\n",
       " 'cuộc',\n",
       " 'sống',\n",
       " '.']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[train_ds.vocab[0][i] for i in train_ds.tls[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define sentiment clas learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.5, \n",
    "                                     metrics=[accuracy,F1Score()],\n",
    "                                    seq_len=72,\n",
    "                                    path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/quan/.fastai/data/viwiki')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_clas.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas = learn_clas.load_encoder('finetuned_sen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05333333333333333"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=2e-2\n",
    "lr *= bs/48\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(fastai.text.learner.TextLearner, fastai.text.models.core.SequentialRNN, 2)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(learn_clas),type(learn_clas.model),len(learn_clas.model) # no more LMLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceEncoder(\n",
       "  (module): AWD_LSTM(\n",
       "    (encoder): Embedding(5128, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(5128, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_clas.model[0] # same as LMLearner finetuning\n",
    "\n",
    "# The model uses a SentenceEncoder, \n",
    "# which means the texts are passed seq_len tokens at a time, \n",
    "# and WILL ONLY COMPUTE THE GRADIENTS on the last max_len steps (default to 1440)\n",
    "\n",
    "# This will take care of the question: some reviews are long, how to know we have \n",
    "# fetched an entire review before gradient can be computed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoolingLinearClassifier(\n",
       "  (layers): Sequential(\n",
       "    (0): LinBnDrop(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): LinBnDrop(\n",
       "      (0): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=50, out_features=2, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_clas.model[1] # not linear decoder\n",
    "# 1200 is 400*3, or (the size of hidden state activation of last LSTM) * 3\n",
    "# which includes: [last_hidden, max_pool, avg_pool]\n",
    "# learn how that is calculated: https://docs.fast.ai/text.models.core#masked_concat_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### param groups and weight shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn_clas.opt.param_lists) # 5 layers total for discriminative fine tuning\n",
    "# since no longer doing 'tie_weight': the word embedding weight is now separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5128"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls_clas.vocab[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5128, 400])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_clas.opt.param_lists[0][0].shape # the word embedding weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['torch.Size([5128, 400]): False',\n",
       " 'torch.Size([4608, 1152]): False',\n",
       " 'torch.Size([4608, 400]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([4608, 1152]): False',\n",
       " 'torch.Size([4608, 1152]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([4608]): False',\n",
       " 'torch.Size([1600, 400]): False',\n",
       " 'torch.Size([1600, 1152]): False',\n",
       " 'torch.Size([1600]): False',\n",
       " 'torch.Size([1600]): False',\n",
       " 'torch.Size([1200]): True',\n",
       " 'torch.Size([1200]): True',\n",
       " 'torch.Size([50, 1200]): True',\n",
       " 'torch.Size([50]): True',\n",
       " 'torch.Size([50]): True',\n",
       " 'torch.Size([2, 50]): True']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"{getattr(i,'shape')}: {i.requires_grad}\" for l in learn_clas.opt.param_lists for i in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn_clas.model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.module.encoder.weight: torch.Size([5128, 400])',\n",
       " '0.module.encoder_dp.emb.weight: torch.Size([5128, 400])',\n",
       " '0.module.rnns.0.weight_hh_l0_raw: torch.Size([4608, 1152])',\n",
       " '0.module.rnns.0.module.weight_ih_l0: torch.Size([4608, 400])',\n",
       " '0.module.rnns.0.module.bias_ih_l0: torch.Size([4608])',\n",
       " '0.module.rnns.0.module.bias_hh_l0: torch.Size([4608])',\n",
       " '0.module.rnns.1.weight_hh_l0_raw: torch.Size([4608, 1152])',\n",
       " '0.module.rnns.1.module.weight_ih_l0: torch.Size([4608, 1152])',\n",
       " '0.module.rnns.1.module.bias_ih_l0: torch.Size([4608])',\n",
       " '0.module.rnns.1.module.bias_hh_l0: torch.Size([4608])',\n",
       " '0.module.rnns.2.weight_hh_l0_raw: torch.Size([1600, 400])',\n",
       " '0.module.rnns.2.module.weight_ih_l0: torch.Size([1600, 1152])',\n",
       " '0.module.rnns.2.module.bias_ih_l0: torch.Size([1600])',\n",
       " '0.module.rnns.2.module.bias_hh_l0: torch.Size([1600])',\n",
       " '1.layers.0.0.weight: torch.Size([1200])',\n",
       " '1.layers.0.0.bias: torch.Size([1200])',\n",
       " '1.layers.0.0.running_mean: torch.Size([1200])',\n",
       " '1.layers.0.0.running_var: torch.Size([1200])',\n",
       " '1.layers.0.0.num_batches_tracked: torch.Size([])',\n",
       " '1.layers.0.2.weight: torch.Size([50, 1200])',\n",
       " '1.layers.1.0.weight: torch.Size([50])',\n",
       " '1.layers.1.0.bias: torch.Size([50])',\n",
       " '1.layers.1.0.running_mean: torch.Size([50])',\n",
       " '1.layers.1.0.running_var: torch.Size([50])',\n",
       " '1.layers.1.0.num_batches_tracked: torch.Size([])',\n",
       " '1.layers.1.2.weight: torch.Size([2, 50])']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{k}: {v.shape}' for k,v in learn_clas.model.state_dict().items()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.389166</td>\n",
       "      <td>0.272311</td>\n",
       "      <td>0.876244</td>\n",
       "      <td>0.867067</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.361879</td>\n",
       "      <td>0.259818</td>\n",
       "      <td>0.891169</td>\n",
       "      <td>0.881195</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.373139</td>\n",
       "      <td>0.248702</td>\n",
       "      <td>0.896144</td>\n",
       "      <td>0.883947</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.fit_one_cycle(3, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.save(f'vi_clas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.332855</td>\n",
       "      <td>0.263983</td>\n",
       "      <td>0.878731</td>\n",
       "      <td>0.852608</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.236296</td>\n",
       "      <td>0.214972</td>\n",
       "      <td>0.909826</td>\n",
       "      <td>0.896650</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.freeze_to(-2)\n",
    "learn_clas.fit_one_cycle(2, slice(lr/(2.6**4),lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.259469</td>\n",
       "      <td>0.235889</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.900690</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.201866</td>\n",
       "      <td>0.244321</td>\n",
       "      <td>0.913557</td>\n",
       "      <td>0.903001</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.freeze_to(-3)\n",
    "learn_clas.fit_one_cycle(2, slice(lr/2/(2.6**4),lr/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.save(f'vi_clas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.161196</td>\n",
       "      <td>0.448453</td>\n",
       "      <td>0.907960</td>\n",
       "      <td>0.896648</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.unfreeze()\n",
    "learn_clas.fit_one_cycle(1, slice(lr/10/(2.6**4),lr/10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
